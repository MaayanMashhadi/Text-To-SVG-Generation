{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **LoRA_Inferance_and_GridSearch**"
      ],
      "metadata": {
        "id": "18i5aRAkXVgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup**"
      ],
      "metadata": {
        "id": "8805kwuYAzUm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anXXYeVpAat4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Stable Diffusion with LoRA Weights for SVG-Optimized Image Generation**"
      ],
      "metadata": {
        "id": "TElvpNvYA6-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    # device=\"cuda\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "# replace the path with the path containing the LoRA weights\n",
        "pipe.load_lora_weights(\"/content/drive/MyDrive/Loras/StableDiffusionForSVGableImagesGeneration/output/StableDiffusionForSVGableImagesGeneration-03.safetensors\")\n"
      ],
      "metadata": {
        "id": "sB1qu4ljBJq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating and Saving an Image with Stable Diffusion**"
      ],
      "metadata": {
        "id": "V2nMHlezCFuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.disable_lora()\n",
        "prompt = \"A black siluhette of a man with white background\"\n",
        "image = pipe(\n",
        "    prompt, num_inference_steps=30, cross_attention_kwargs={\"scale\": 1.5}, generator=torch.manual_seed(1)\n",
        ").images[0]\n",
        "image\n",
        "\n",
        "# Save the image\n",
        "image_path = \"/content/drive/MyDrive/images/silhouette_man_with_hat.png\"  # Specify the file name\n",
        "image.save(image_path)\n",
        "\n",
        "print(f\"Image saved to {image_path}\")"
      ],
      "metadata": {
        "id": "_SJkt5ZlCQz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating and Presenting an Image with Stable Diffusion**"
      ],
      "metadata": {
        "id": "WCc7cKhZCpLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.enable_lora()\n",
        "prompt = \"A simple black painting of a cat, solid white backd white siground\"\n",
        "image = pipe(\n",
        "    prompt, num_inference_steps=30, cross_attention_kwargs={\"scale\": 1.2}, generator=torch.manual_seed(1)\n",
        ").images[0]\n",
        "image"
      ],
      "metadata": {
        "id": "_c1umO8_Cren"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Background of an Image**"
      ],
      "metadata": {
        "id": "vFW731OgDfPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "image_path = \"/content/drive/MyDrive/images/image_tree.png\"\n",
        "grayscale_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "gray_threshold_low = 20\n",
        "gray_threshold_high = 200\n",
        "background_mask = cv2.inRange(grayscale_image, gray_threshold_low, gray_threshold_high)\n",
        "grayscale_image[background_mask > 0] = 255\n",
        "\n",
        "_, binary_image = cv2.threshold(grayscale_image, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary_image, connectivity=8)\n",
        "\n",
        "min_size = 50  # Minimum size of components to keep\n",
        "filtered_image = np.zeros_like(binary_image)\n",
        "\n",
        "for i in range(1, num_labels):\n",
        "    if stats[i, cv2.CC_STAT_AREA] >= min_size:\n",
        "        filtered_image[labels == i] = 255\n",
        "\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "\n",
        "closed_image = cv2.morphologyEx(filtered_image, cv2.MORPH_CLOSE, kernel)  # Fill small holes\n",
        "smoothed_image = cv2.morphologyEx(closed_image, cv2.MORPH_OPEN, kernel)  # Remove noise\n",
        "\n",
        "cv2.imwrite(\"/content/drive/MyDrive/images/smoothed_image_tree.png\", smoothed_image)\n",
        "# cv2.imshow(\"Smoothed Image\", smoothed_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "E5v9bnJmDlgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Full Pipeline**"
      ],
      "metadata": {
        "id": "Ddtzfn0dDoAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installations**"
      ],
      "metadata": {
        "id": "KqKt9sKxD6rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install potrace\n",
        "!pip install potracer[cli]\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "Q96EPbtqDtIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utils Functions**"
      ],
      "metadata": {
        "id": "WC5BgV6IWLCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "jUb7IMytXBG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import subprocess"
      ],
      "metadata": {
        "id": "uct715kjXDk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove Background Function"
      ],
      "metadata": {
        "id": "u69tO0b3LxUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_background(image_path):\n",
        "    \"\"\"\n",
        "    Removes the background of an image, isolates significant components, and smooths the result.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input grayscale image.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Processed image with background removed and components smoothed.\n",
        "    \"\"\"\n",
        "    grayscale_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if grayscale_image is None:\n",
        "        raise ValueError(f\"Image not found at path: {image_path}\")\n",
        "\n",
        "    gray_threshold_low = 20\n",
        "    gray_threshold_high = 200\n",
        "    background_mask = cv2.inRange(grayscale_image, gray_threshold_low, gray_threshold_high)\n",
        "    grayscale_image[background_mask > 0] = 255\n",
        "\n",
        "    _, binary_image = cv2.threshold(grayscale_image, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary_image, connectivity=8)\n",
        "\n",
        "    min_size = 50\n",
        "    filtered_image = np.zeros_like(binary_image)\n",
        "\n",
        "    for i in range(1, num_labels):\n",
        "        if stats[i, cv2.CC_STAT_AREA] >= min_size:\n",
        "            filtered_image[labels == i] = 255\n",
        "\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "\n",
        "    closed_image = cv2.morphologyEx(filtered_image, cv2.MORPH_CLOSE, kernel)\n",
        "    smoothed_image = cv2.morphologyEx(closed_image, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    return smoothed_image\n"
      ],
      "metadata": {
        "id": "lx1mo7JIL3Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Image to SVG Function"
      ],
      "metadata": {
        "id": "5cZDL-jIMDx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_svg(image_path, svg_output_dir):\n",
        "    \"\"\"\n",
        "    Converts an image to SVG format using the following steps:\n",
        "    1. Resizes the image to 500x500 pixels.\n",
        "    2. Converts the resized image to grayscale.\n",
        "    3. Saves the grayscale image as a BMP file.\n",
        "    4. Converts the BMP file to SVG using Potrace.\n",
        "\n",
        "    Parameters:\n",
        "        image_path (str): Path to the input image file.\n",
        "        svg_output_dir (str): Path to the directory where the SVG file will be saved.\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the saved SVG file.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If any step in the process fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        os.makedirs(svg_output_dir, exist_ok=True)\n",
        "\n",
        "        img = Image.open(image_path)\n",
        "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "        img_resized = img.resize((500, 500), Image.LANCZOS)\n",
        "\n",
        "        img_gray = img_resized.convert('L')\n",
        "\n",
        "        bmp_path = os.path.join(svg_output_dir, f'{base_name}.bmp')\n",
        "        img_gray.save(bmp_path)\n",
        "\n",
        "        svg_path = os.path.join(svg_output_dir, f'{base_name}.svg')\n",
        "        subprocess.run(['potrace', bmp_path, '-s', '-o', svg_path], check=True)\n",
        "\n",
        "        print(f'SVG file saved to {svg_path}')\n",
        "        return svg_path\n",
        "\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"An error occurred while processing {image_path}: {e}\")\n"
      ],
      "metadata": {
        "id": "oR4uCjwnMIl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grid Search Pipeline:**"
      ],
      "metadata": {
        "id": "zOAwJzCkF4aY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and Defnitions"
      ],
      "metadata": {
        "id": "c5oIxlMqLbZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from itertools import product\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import tiktoken\n",
        "\n",
        "# Hyperparameters and prompts\n",
        "prompts = [\n",
        "    \"A minimalistic black silhouette of a {object} on a plain white background, with clean lines and no additional details.\",\n",
        "    \"A simple black outline of a {object}, completely filled in, positioned on a white background for a sharp contrast.\",\n",
        "    \"A sleek black silhouette of a {object}, centered on a white background, designed to emphasize the shape of the object.\",\n",
        "    \"A bold, black silhouette representation of a {object}, isolated on a plain white background for clarity.\",\n",
        "    \"A clean, vector-style black silhouette of a {object} against a pure white background, with no extraneous details.\",\n",
        "    \"A minimalistic black shadow image of a {object}, rendered against a bright white background.\",\n",
        "    \"A sharp-edged black silhouette of a {object}, perfectly centered and framed by a simple white backdrop.\",\n",
        "]\n",
        "\n",
        "objects = [\"tree\", \"cat\", \"bicycle\", \"airplane\", \"chair\", \"teapot\", \"guitar\", \"candle\", \"elephant\", \"lighthouse\"]\n",
        "num_inference_steps_range = [20, 30, 40]\n",
        "scale_range = [1.0, 1.2, 1.5]\n",
        "seeds = [1, 42, 99]\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/StableDiffusion-v1.5-outputs/train/images\"\n",
        "svg_output_dir = \"/content/drive/MyDrive/StableDiffusion-v1.5-outputs/train/svgs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(svg_output_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "WltmbXKeF9kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Tokens Function"
      ],
      "metadata": {
        "id": "TFTLt-3yNCYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tokens(svg_content):\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "    return len(encoding.encode(svg_content))\n"
      ],
      "metadata": {
        "id": "tO2MtXkENGuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline Execution"
      ],
      "metadata": {
        "id": "3eGUIqsONr2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for prompt_template, num_inference_steps, scale, seed in product(prompts, num_inference_steps_range, scale_range, seeds):\n",
        "    generator = torch.manual_seed(seed)\n",
        "    pos_count = 0\n",
        "    for obj in objects:\n",
        "      prompt = prompt_template.format(object=obj)\n",
        "      try:\n",
        "        image = pipe(prompt, num_inference_steps=num_inference_steps, cross_attention_kwargs={\"scale\": scale}, generator=generator).images[0]\n",
        "        image_filename = f\"{obj}_steps_{num_inference_steps}_scale_{scale}_seed_{seed}.png\"\n",
        "        image_path = os.path.join(output_dir, image_filename)\n",
        "        image.save(image_path)\n",
        "\n",
        "        smoothed_image = remove_background(image_path)\n",
        "        processed_image_path = image_path.replace(\".png\", \"_processed.png\")\n",
        "        cv2.imwrite(processed_image_path, smoothed_image)\n",
        "\n",
        "        svg_path = convert_to_svg(processed_image_path, svg_output_dir)\n",
        "\n",
        "        with open(svg_path, \"r\") as svg_file:\n",
        "            svg_content = svg_file.read()\n",
        "        token_count = count_tokens(svg_content)\n",
        "\n",
        "        if token_count <= 8000:\n",
        "            pos_count += 1\n",
        "\n",
        "      except Exception as e:\n",
        "        print(f\"An error occurred for {obj} with seed {seed}: {e}\")\n",
        "\n",
        "    num_objects = len(objects)\n",
        "    positive_rate = pos_count / num_objects\n",
        "\n",
        "    results.append({\n",
        "        \"Prompt\": prompt_template,\n",
        "        \"Inference Steps\": num_inference_steps,\n",
        "        \"Scale\": scale,\n",
        "        \"Seed\": seed,\n",
        "        \"Positives Rate\": positive_rate,\n",
        "    })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # Save the results to an Excel file\n",
        "    excel_file_path = \"/content/drive/MyDrive/StableDiffusion-v1.5-outputs/train/results.xlsx\"\n",
        "    df.to_excel(excel_file_path, index=False)\n",
        "\n",
        "    print(f\"Results saved to {excel_file_path}\")"
      ],
      "metadata": {
        "id": "froggNrlL4qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Images Generation Pipeline:**"
      ],
      "metadata": {
        "id": "snSh6WLTSp12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and Definitions"
      ],
      "metadata": {
        "id": "rfA_4gH7U5ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import cv2\n",
        "import subprocess\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "output_images_dir = \"/content/drive/mydrive/LargeDataset/Images\"\n",
        "output_svgs_dir = \"/content/drive/mydrive/LargeDataset/SVG\"\n",
        "os.makedirs(output_images_dir, exist_ok=True)\n",
        "os.makedirs(output_svgs_dir, exist_ok=True)\n",
        "\n",
        "num_inference_steps = 30\n",
        "scale = 1.5\n",
        "seed = 1\n",
        "\n",
        "prompts = [\n",
        "    \"A black silhouette of a man with a white background\",\n",
        "    \"A simple black outline of a dog against a plain white background\",\n",
        "    \"A minimalistic black figure of a tree, standing on a white canvas\",\n",
        "    \"A black figure of a cat with a white background\",\n",
        "    \"A simple silhouette of a car on a white background\",\n",
        "    \"A minimalistic black bicycle silhouette on a white background\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "2OXE8fK7Sq1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Image and Process Function"
      ],
      "metadata": {
        "id": "fu2NsK3UVGYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image_and_process(prompt, num_inference_steps, scale, seed):\n",
        "    \"\"\"\n",
        "    Generate image, process background, and save to respective directories.\n",
        "    \"\"\"\n",
        "    generator = torch.manual_seed(seed)\n",
        "\n",
        "    try:\n",
        "        # Generate image\n",
        "        image = pipe(prompt, num_inference_steps=num_inference_steps, cross_attention_kwargs={\"scale\": scale}, generator=generator).images[0]\n",
        "\n",
        "        # Save generated image initially (before background removal)\n",
        "        temp_image_path = \"/tmp/temp_image.png\"\n",
        "        image.save(temp_image_path)\n",
        "\n",
        "        # Remove background from image\n",
        "        smoothed_image = remove_background(temp_image_path)\n",
        "\n",
        "        # Save processed image after background removal\n",
        "        processed_image_path = os.path.join(output_images_dir, f\"{prompt.replace(' ', '_')}_steps_{num_inference_steps}_scale_{scale}_seed_{seed}_processed.png\")\n",
        "        cv2.imwrite(processed_image_path, smoothed_image)\n",
        "\n",
        "        # Convert the processed image to SVG\n",
        "        svg_path = convert_to_svg(processed_image_path, output_svgs_dir)\n",
        "\n",
        "        print(f\"Processed image saved as {processed_image_path} and SVG as {os.path.basename(svg_path)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing prompt '{prompt}' with seed {seed}: {e}\")\n"
      ],
      "metadata": {
        "id": "AkUxi_4hVKRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Loop to generate and process images based on the list of prompts"
      ],
      "metadata": {
        "id": "cioZaruaV-si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "    generate_image_and_process(prompt, num_inference_steps, scale, seed)\n",
        "\n",
        "print(f\"Finished processing images.\")"
      ],
      "metadata": {
        "id": "WnLU4-aiWDWj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}