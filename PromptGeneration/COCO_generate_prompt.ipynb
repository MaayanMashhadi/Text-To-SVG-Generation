{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a0565135fab4e84af6030ed12a7db78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_988ef22f06b246a387336549c55c0f4e",
              "IPY_MODEL_142e67cb1dba44e4be7dc7a18deed5c6",
              "IPY_MODEL_bb17527a193546659b7abe0862ed211d"
            ],
            "layout": "IPY_MODEL_0cc60a07369b416cab99c0c5b7a825a8"
          }
        },
        "988ef22f06b246a387336549c55c0f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_118a5085bd7248df879fa758a752ac38",
            "placeholder": "​",
            "style": "IPY_MODEL_eb3e152ddb414b1bb15ded538e5576bb",
            "value": "(…)-00011-of-00182-f499a31d286235db.parquet: 100%"
          }
        },
        "142e67cb1dba44e4be7dc7a18deed5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_425ead6937c7492f947e852e2c7a3e10",
            "max": 113692478,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c2b99eda009417d9f3af1d4272322bc",
            "value": 113692478
          }
        },
        "bb17527a193546659b7abe0862ed211d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b3dfd788df44aedbefe1dc2a2ff8edc",
            "placeholder": "​",
            "style": "IPY_MODEL_3ecb3e28b72f454292886b908567b986",
            "value": " 114M/114M [00:02&lt;00:00, 53.2MB/s]"
          }
        },
        "0cc60a07369b416cab99c0c5b7a825a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "118a5085bd7248df879fa758a752ac38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb3e152ddb414b1bb15ded538e5576bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "425ead6937c7492f947e852e2c7a3e10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c2b99eda009417d9f3af1d4272322bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b3dfd788df44aedbefe1dc2a2ff8edc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ecb3e28b72f454292886b908567b986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "864a0c7104b6457f9a474c9243bb315c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdbf7cc7cdf04632a630f8b70ef5d3d6",
              "IPY_MODEL_2ed9e5cd607040938ab39b0bd08b8b47",
              "IPY_MODEL_364e764117d84e57bdfd9b305684f0e7"
            ],
            "layout": "IPY_MODEL_f5787d1118ca48cab0626c0b69a42f44"
          }
        },
        "bdbf7cc7cdf04632a630f8b70ef5d3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80d5618712764fc4826f35302b3672e8",
            "placeholder": "​",
            "style": "IPY_MODEL_f64c888f10ca482091d3c0f423cee3e4",
            "value": "Generating train split: "
          }
        },
        "2ed9e5cd607040938ab39b0bd08b8b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e51dc300932414ab253f0a01f95ee7e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd08c384c144419091660ff73c28b630",
            "value": 1
          }
        },
        "364e764117d84e57bdfd9b305684f0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd7a406136ca43c2bc2969a119cb2611",
            "placeholder": "​",
            "style": "IPY_MODEL_9eb930e4950b4f34affaf1cf1f68b720",
            "value": " 3114/0 [00:06&lt;00:00, 1059.08 examples/s]"
          }
        },
        "f5787d1118ca48cab0626c0b69a42f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d5618712764fc4826f35302b3672e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f64c888f10ca482091d3c0f423cee3e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e51dc300932414ab253f0a01f95ee7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bd08c384c144419091660ff73c28b630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd7a406136ca43c2bc2969a119cb2611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb930e4950b4f34affaf1cf1f68b720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7RHIAFjIp9G",
        "outputId": "afe13fb0-7dc3-4f41-a32a-5232c74f9c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pqGkkcx8Htk",
        "outputId": "caa16358-13e9-42bd-ba9b-75132502bca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env OPENAI_API_KEY=''"
      ],
      "metadata": {
        "id": "kr1MJluy8dnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "11GCqt5S8Yn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeNp0rxI9Otn",
        "outputId": "06738069-0eee-405b-94e5-3bd6c51bac23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "Eb9g1HZB9dCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "ds = load_dataset(\"parquet\",\n",
        "                  data_files=[\"hf://datasets/jxie/coco_captions@a2ed90d49b61dd13dd71f399c70f5feb897f8bec/data/train-00011-of-00182-f499a31d286235db.parquet\",])\n",
        "# df = load_dataset(\"jxie/coco_captions\", split=\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "2a0565135fab4e84af6030ed12a7db78",
            "988ef22f06b246a387336549c55c0f4e",
            "142e67cb1dba44e4be7dc7a18deed5c6",
            "bb17527a193546659b7abe0862ed211d",
            "0cc60a07369b416cab99c0c5b7a825a8",
            "118a5085bd7248df879fa758a752ac38",
            "eb3e152ddb414b1bb15ded538e5576bb",
            "425ead6937c7492f947e852e2c7a3e10",
            "9c2b99eda009417d9f3af1d4272322bc",
            "3b3dfd788df44aedbefe1dc2a2ff8edc",
            "3ecb3e28b72f454292886b908567b986",
            "864a0c7104b6457f9a474c9243bb315c",
            "bdbf7cc7cdf04632a630f8b70ef5d3d6",
            "2ed9e5cd607040938ab39b0bd08b8b47",
            "364e764117d84e57bdfd9b305684f0e7",
            "f5787d1118ca48cab0626c0b69a42f44",
            "80d5618712764fc4826f35302b3672e8",
            "f64c888f10ca482091d3c0f423cee3e4",
            "2e51dc300932414ab253f0a01f95ee7e",
            "bd08c384c144419091660ff73c28b630",
            "fd7a406136ca43c2bc2969a119cb2611",
            "9eb930e4950b4f34affaf1cf1f68b720"
          ]
        },
        "id": "UpFcMLQa9N6Z",
        "outputId": "9deb8245-5348-4dc6-e1f4-aeee5f99a07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00011-of-00182-f499a31d286235db.parquet:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a0565135fab4e84af6030ed12a7db78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "864a0c7104b6457f9a474c9243bb315c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"I have a caption and I want to make it slightly simpler (w.r.t background and colors) and specific, and turn it a caption that describes the same thing\n",
        "If the caption is not appropriate to be converted, respond with “NO”. For example:\n",
        "\n",
        "1. \"A dog rolling in the snow at sunset\" → \"A dog rolling in the snow\"\n",
        "2. \"pink photo of Tokyo\" → \"buildings in Tokyo\"\n",
        "3. \"Anti-fracking protest rocks NY governor's state of the state address\" → \"group of people protesting in front of a house\"\n",
        "4. \"st peter's square: St Peters Square in Rome Italy\" → \"a square with the colosseum in the background\"\n",
        "5. \"A Queen Elizabeth II Prince Andrew On The Balcony Of Buckingham Palace After Trooping The Colour Ceremony. 1962.\" → \"A Queen on a balcony\"\n",
        "6. \"Two little Chihuahua puppies for sale\" → \"Two little Chihuahua puppies\"\n",
        "7. \"Evaluate and Adjust Your Safeguards Evaluate and adjust safeguards and practices in light of results of: System testing and monitoring. Material chang\" → \"NO\"\n",
        "8. \"how-to-watch-the-kitten-bowl\" → \"A kitten drinking out of a bowl\"\n",
        "9. \"Voters head to polls for municipal elections across Ontario\" → \"A person walking and there is a sign that says vote here\"\n",
        "10. \"44 Romantic Barn Wedding Lights Ideas\" → \"A man and woman dancing at a wedding\"\n",
        "11. \"martini drink isolated on white flat vector image\" → \"A martini drink on white background\"\n",
        "12. \"Selway High-Back Executive Chair\" → \"A high-back chair\"\n",
        "13. \"Nickelodeon Paw Patrol'Calling All Pups' Soft Potty Seat\" → \"NO\"\n",
        "14. \"Young people skateboarding on city streets\" → \"Young skateboarders with a building in the background\"\n",
        "15. \"Alternate view of the Sterling Silver Chihuahua Bead Charm by The Black Bow Jewelry Co.\" → \"NO\"\n",
        "16. \"A woman cutting a large white sheet cake\" → \"A woman cutting a large cake.\"\n",
        "\n",
        "\n",
        "\n",
        "do this for the following caption: \"{context}\".\n",
        "\n",
        "Format your response as\n",
        "```\n",
        "Step 1: <simplified>\n",
        "```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "x0sksxYZGmb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(ds[\"train\"][\"caption\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmVM3ub6GW6W",
        "outputId": "6b166742-a7ff-4461-e7b6-34064548254e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3114"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds['train']['filename'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hll1_Zfjgg9C",
        "outputId": "408ba14b-51af-43e1-9785-e3d044a9faa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['COCO_val2014_000000326564.jpg', 'COCO_val2014_000000326564.jpg', 'COCO_val2014_000000326564.jpg', 'COCO_val2014_000000326564.jpg', 'COCO_val2014_000000187286.jpg', 'COCO_val2014_000000187286.jpg', 'COCO_val2014_000000187286.jpg', 'COCO_val2014_000000187286.jpg', 'COCO_val2014_000000187286.jpg', 'COCO_val2014_000000032760.jpg', 'COCO_val2014_000000032760.jpg', 'COCO_val2014_000000032760.jpg', 'COCO_val2014_000000032760.jpg', 'COCO_val2014_000000032760.jpg', 'COCO_val2014_000000156754.jpg', 'COCO_val2014_000000156754.jpg', 'COCO_val2014_000000156754.jpg', 'COCO_val2014_000000156754.jpg', 'COCO_val2014_000000156754.jpg', 'COCO_val2014_000000089556.jpg', 'COCO_val2014_000000089556.jpg', 'COCO_val2014_000000089556.jpg', 'COCO_val2014_000000089556.jpg', 'COCO_val2014_000000089556.jpg', 'COCO_val2014_000000301634.jpg', 'COCO_val2014_000000301634.jpg', 'COCO_val2014_000000301634.jpg', 'COCO_val2014_000000301634.jpg', 'COCO_val2014_000000301634.jpg', 'COCO_val2014_000000266206.jpg', 'COCO_val2014_000000266206.jpg', 'COCO_val2014_000000266206.jpg', 'COCO_val2014_000000266206.jpg', 'COCO_val2014_000000266206.jpg', 'COCO_val2014_000000179187.jpg', 'COCO_val2014_000000179187.jpg', 'COCO_val2014_000000179187.jpg', 'COCO_val2014_000000179187.jpg', 'COCO_val2014_000000179187.jpg', 'COCO_val2014_000000185773.jpg', 'COCO_val2014_000000185773.jpg', 'COCO_val2014_000000185773.jpg', 'COCO_val2014_000000185773.jpg', 'COCO_val2014_000000185773.jpg', 'COCO_val2014_000000189939.jpg', 'COCO_val2014_000000189939.jpg', 'COCO_val2014_000000189939.jpg', 'COCO_val2014_000000189939.jpg', 'COCO_val2014_000000189939.jpg', 'COCO_val2014_000000016977.jpg', 'COCO_val2014_000000016977.jpg', 'COCO_val2014_000000016977.jpg', 'COCO_val2014_000000016977.jpg', 'COCO_val2014_000000016977.jpg', 'COCO_val2014_000000508602.jpg', 'COCO_val2014_000000508602.jpg', 'COCO_val2014_000000508602.jpg', 'COCO_val2014_000000508602.jpg', 'COCO_val2014_000000508602.jpg', 'COCO_val2014_000000489687.jpg', 'COCO_val2014_000000489687.jpg', 'COCO_val2014_000000489687.jpg', 'COCO_val2014_000000489687.jpg', 'COCO_val2014_000000489687.jpg', 'COCO_val2014_000000010363.jpg', 'COCO_val2014_000000010363.jpg', 'COCO_val2014_000000010363.jpg', 'COCO_val2014_000000010363.jpg', 'COCO_val2014_000000010363.jpg', 'COCO_val2014_000000407286.jpg', 'COCO_val2014_000000407286.jpg', 'COCO_val2014_000000407286.jpg', 'COCO_val2014_000000407286.jpg', 'COCO_val2014_000000407286.jpg', 'COCO_val2014_000000507975.jpg', 'COCO_val2014_000000507975.jpg', 'COCO_val2014_000000507975.jpg', 'COCO_val2014_000000507975.jpg', 'COCO_val2014_000000507975.jpg', 'COCO_val2014_000000242673.jpg', 'COCO_val2014_000000242673.jpg', 'COCO_val2014_000000242673.jpg', 'COCO_val2014_000000242673.jpg', 'COCO_val2014_000000242673.jpg', 'COCO_val2014_000000195510.jpg', 'COCO_val2014_000000195510.jpg', 'COCO_val2014_000000195510.jpg', 'COCO_val2014_000000195510.jpg', 'COCO_val2014_000000195510.jpg', 'COCO_val2014_000000175570.jpg', 'COCO_val2014_000000175570.jpg', 'COCO_val2014_000000175570.jpg', 'COCO_val2014_000000175570.jpg', 'COCO_val2014_000000175570.jpg', 'COCO_val2014_000000330455.jpg', 'COCO_val2014_000000330455.jpg', 'COCO_val2014_000000330455.jpg', 'COCO_val2014_000000330455.jpg', 'COCO_val2014_000000330455.jpg', 'COCO_val2014_000000202658.jpg', 'COCO_val2014_000000202658.jpg', 'COCO_val2014_000000202658.jpg', 'COCO_val2014_000000202658.jpg', 'COCO_val2014_000000202658.jpg', 'COCO_val2014_000000147576.jpg', 'COCO_val2014_000000147576.jpg', 'COCO_val2014_000000147576.jpg', 'COCO_val2014_000000147576.jpg', 'COCO_val2014_000000147576.jpg', 'COCO_val2014_000000529968.jpg', 'COCO_val2014_000000529968.jpg', 'COCO_val2014_000000529968.jpg', 'COCO_val2014_000000529968.jpg', 'COCO_val2014_000000529968.jpg', 'COCO_val2014_000000532426.jpg', 'COCO_val2014_000000532426.jpg', 'COCO_val2014_000000532426.jpg', 'COCO_val2014_000000532426.jpg', 'COCO_val2014_000000532426.jpg', 'COCO_val2014_000000210883.jpg', 'COCO_val2014_000000210883.jpg', 'COCO_val2014_000000210883.jpg', 'COCO_val2014_000000210883.jpg', 'COCO_val2014_000000210883.jpg', 'COCO_val2014_000000463066.jpg', 'COCO_val2014_000000463066.jpg', 'COCO_val2014_000000463066.jpg', 'COCO_val2014_000000463066.jpg', 'COCO_val2014_000000463066.jpg', 'COCO_val2014_000000537395.jpg', 'COCO_val2014_000000537395.jpg', 'COCO_val2014_000000537395.jpg', 'COCO_val2014_000000537395.jpg', 'COCO_val2014_000000537395.jpg', 'COCO_val2014_000000487192.jpg', 'COCO_val2014_000000487192.jpg', 'COCO_val2014_000000487192.jpg', 'COCO_val2014_000000487192.jpg', 'COCO_val2014_000000487192.jpg', 'COCO_val2014_000000303549.jpg', 'COCO_val2014_000000303549.jpg', 'COCO_val2014_000000303549.jpg', 'COCO_val2014_000000303549.jpg', 'COCO_val2014_000000303549.jpg', 'COCO_val2014_000000464534.jpg', 'COCO_val2014_000000464534.jpg', 'COCO_val2014_000000464534.jpg', 'COCO_val2014_000000464534.jpg', 'COCO_val2014_000000464534.jpg', 'COCO_val2014_000000232511.jpg', 'COCO_val2014_000000232511.jpg', 'COCO_val2014_000000232511.jpg', 'COCO_val2014_000000232511.jpg', 'COCO_val2014_000000232511.jpg', 'COCO_val2014_000000020788.jpg', 'COCO_val2014_000000020788.jpg', 'COCO_val2014_000000020788.jpg', 'COCO_val2014_000000020788.jpg', 'COCO_val2014_000000020788.jpg', 'COCO_val2014_000000377401.jpg', 'COCO_val2014_000000377401.jpg', 'COCO_val2014_000000377401.jpg', 'COCO_val2014_000000377401.jpg', 'COCO_val2014_000000377401.jpg', 'COCO_val2014_000000379869.jpg', 'COCO_val2014_000000379869.jpg', 'COCO_val2014_000000379869.jpg', 'COCO_val2014_000000379869.jpg', 'COCO_val2014_000000379869.jpg', 'COCO_val2014_000000050637.jpg', 'COCO_val2014_000000050637.jpg', 'COCO_val2014_000000050637.jpg', 'COCO_val2014_000000050637.jpg', 'COCO_val2014_000000050637.jpg', 'COCO_val2014_000000226360.jpg', 'COCO_val2014_000000226360.jpg', 'COCO_val2014_000000226360.jpg', 'COCO_val2014_000000226360.jpg', 'COCO_val2014_000000226360.jpg', 'COCO_val2014_000000314177.jpg', 'COCO_val2014_000000314177.jpg', 'COCO_val2014_000000314177.jpg', 'COCO_val2014_000000314177.jpg', 'COCO_val2014_000000314177.jpg', 'COCO_val2014_000000315790.jpg', 'COCO_val2014_000000315790.jpg', 'COCO_val2014_000000315790.jpg', 'COCO_val2014_000000315790.jpg', 'COCO_val2014_000000315790.jpg', 'COCO_val2014_000000117380.jpg', 'COCO_val2014_000000117380.jpg', 'COCO_val2014_000000117380.jpg', 'COCO_val2014_000000117380.jpg', 'COCO_val2014_000000117380.jpg', 'COCO_val2014_000000036761.jpg', 'COCO_val2014_000000036761.jpg', 'COCO_val2014_000000036761.jpg', 'COCO_val2014_000000036761.jpg', 'COCO_val2014_000000036761.jpg', 'COCO_val2014_000000155142.jpg', 'COCO_val2014_000000155142.jpg', 'COCO_val2014_000000155142.jpg', 'COCO_val2014_000000155142.jpg', 'COCO_val2014_000000155142.jpg', 'COCO_val2014_000000359310.jpg', 'COCO_val2014_000000359310.jpg', 'COCO_val2014_000000359310.jpg', 'COCO_val2014_000000359310.jpg', 'COCO_val2014_000000359310.jpg', 'COCO_val2014_000000504297.jpg', 'COCO_val2014_000000504297.jpg', 'COCO_val2014_000000504297.jpg', 'COCO_val2014_000000504297.jpg', 'COCO_val2014_000000504297.jpg', 'COCO_val2014_000000412693.jpg', 'COCO_val2014_000000412693.jpg', 'COCO_val2014_000000412693.jpg', 'COCO_val2014_000000412693.jpg', 'COCO_val2014_000000412693.jpg', 'COCO_val2014_000000207179.jpg', 'COCO_val2014_000000207179.jpg', 'COCO_val2014_000000207179.jpg', 'COCO_val2014_000000207179.jpg', 'COCO_val2014_000000207179.jpg', 'COCO_val2014_000000228506.jpg', 'COCO_val2014_000000228506.jpg', 'COCO_val2014_000000228506.jpg', 'COCO_val2014_000000228506.jpg', 'COCO_val2014_000000228506.jpg', 'COCO_val2014_000000149406.jpg', 'COCO_val2014_000000149406.jpg', 'COCO_val2014_000000149406.jpg', 'COCO_val2014_000000149406.jpg', 'COCO_val2014_000000149406.jpg', 'COCO_val2014_000000532463.jpg', 'COCO_val2014_000000532463.jpg', 'COCO_val2014_000000532463.jpg', 'COCO_val2014_000000532463.jpg', 'COCO_val2014_000000532463.jpg', 'COCO_val2014_000000169347.jpg', 'COCO_val2014_000000169347.jpg', 'COCO_val2014_000000169347.jpg', 'COCO_val2014_000000169347.jpg', 'COCO_val2014_000000169347.jpg', 'COCO_val2014_000000342515.jpg', 'COCO_val2014_000000342515.jpg', 'COCO_val2014_000000342515.jpg', 'COCO_val2014_000000342515.jpg', 'COCO_val2014_000000342515.jpg', 'COCO_val2014_000000011703.jpg', 'COCO_val2014_000000011703.jpg', 'COCO_val2014_000000011703.jpg', 'COCO_val2014_000000011703.jpg', 'COCO_val2014_000000011703.jpg', 'COCO_val2014_000000180383.jpg', 'COCO_val2014_000000180383.jpg', 'COCO_val2014_000000180383.jpg', 'COCO_val2014_000000180383.jpg', 'COCO_val2014_000000180383.jpg', 'COCO_val2014_000000402433.jpg', 'COCO_val2014_000000402433.jpg', 'COCO_val2014_000000402433.jpg', 'COCO_val2014_000000402433.jpg', 'COCO_val2014_000000402433.jpg', 'COCO_val2014_000000149974.jpg', 'COCO_val2014_000000149974.jpg', 'COCO_val2014_000000149974.jpg', 'COCO_val2014_000000149974.jpg', 'COCO_val2014_000000149974.jpg', 'COCO_val2014_000000285607.jpg', 'COCO_val2014_000000285607.jpg', 'COCO_val2014_000000285607.jpg', 'COCO_val2014_000000285607.jpg', 'COCO_val2014_000000285607.jpg', 'COCO_val2014_000000449996.jpg', 'COCO_val2014_000000449996.jpg', 'COCO_val2014_000000449996.jpg', 'COCO_val2014_000000449996.jpg', 'COCO_val2014_000000449996.jpg', 'COCO_val2014_000000168619.jpg', 'COCO_val2014_000000168619.jpg', 'COCO_val2014_000000168619.jpg', 'COCO_val2014_000000168619.jpg', 'COCO_val2014_000000168619.jpg', 'COCO_val2014_000000209613.jpg', 'COCO_val2014_000000209613.jpg', 'COCO_val2014_000000209613.jpg', 'COCO_val2014_000000209613.jpg', 'COCO_val2014_000000209613.jpg', 'COCO_val2014_000000103548.jpg', 'COCO_val2014_000000103548.jpg', 'COCO_val2014_000000103548.jpg', 'COCO_val2014_000000103548.jpg', 'COCO_val2014_000000103548.jpg', 'COCO_val2014_000000086615.jpg', 'COCO_val2014_000000086615.jpg', 'COCO_val2014_000000086615.jpg', 'COCO_val2014_000000086615.jpg', 'COCO_val2014_000000086615.jpg', 'COCO_val2014_000000578591.jpg', 'COCO_val2014_000000578591.jpg', 'COCO_val2014_000000578591.jpg', 'COCO_val2014_000000578591.jpg', 'COCO_val2014_000000578591.jpg', 'COCO_val2014_000000234291.jpg', 'COCO_val2014_000000234291.jpg', 'COCO_val2014_000000234291.jpg', 'COCO_val2014_000000234291.jpg', 'COCO_val2014_000000234291.jpg', 'COCO_val2014_000000540694.jpg', 'COCO_val2014_000000540694.jpg', 'COCO_val2014_000000540694.jpg', 'COCO_val2014_000000540694.jpg', 'COCO_val2014_000000540694.jpg', 'COCO_val2014_000000356394.jpg', 'COCO_val2014_000000356394.jpg', 'COCO_val2014_000000356394.jpg', 'COCO_val2014_000000356394.jpg', 'COCO_val2014_000000356394.jpg', 'COCO_val2014_000000347422.jpg', 'COCO_val2014_000000347422.jpg', 'COCO_val2014_000000347422.jpg', 'COCO_val2014_000000347422.jpg', 'COCO_val2014_000000347422.jpg', 'COCO_val2014_000000131493.jpg', 'COCO_val2014_000000131493.jpg', 'COCO_val2014_000000131493.jpg', 'COCO_val2014_000000131493.jpg', 'COCO_val2014_000000131493.jpg', 'COCO_val2014_000000094663.jpg', 'COCO_val2014_000000094663.jpg', 'COCO_val2014_000000094663.jpg', 'COCO_val2014_000000094663.jpg', 'COCO_val2014_000000094663.jpg', 'COCO_val2014_000000249404.jpg', 'COCO_val2014_000000249404.jpg', 'COCO_val2014_000000249404.jpg', 'COCO_val2014_000000249404.jpg', 'COCO_val2014_000000249404.jpg', 'COCO_val2014_000000490991.jpg', 'COCO_val2014_000000490991.jpg', 'COCO_val2014_000000490991.jpg', 'COCO_val2014_000000490991.jpg', 'COCO_val2014_000000490991.jpg', 'COCO_val2014_000000120412.jpg', 'COCO_val2014_000000120412.jpg', 'COCO_val2014_000000120412.jpg', 'COCO_val2014_000000120412.jpg', 'COCO_val2014_000000120412.jpg', 'COCO_val2014_000000262505.jpg', 'COCO_val2014_000000262505.jpg', 'COCO_val2014_000000262505.jpg', 'COCO_val2014_000000262505.jpg', 'COCO_val2014_000000262505.jpg', 'COCO_val2014_000000506401.jpg', 'COCO_val2014_000000506401.jpg', 'COCO_val2014_000000506401.jpg', 'COCO_val2014_000000506401.jpg', 'COCO_val2014_000000506401.jpg', 'COCO_val2014_000000157891.jpg', 'COCO_val2014_000000157891.jpg', 'COCO_val2014_000000157891.jpg', 'COCO_val2014_000000157891.jpg', 'COCO_val2014_000000157891.jpg', 'COCO_val2014_000000552395.jpg', 'COCO_val2014_000000552395.jpg', 'COCO_val2014_000000552395.jpg', 'COCO_val2014_000000552395.jpg', 'COCO_val2014_000000552395.jpg', 'COCO_val2014_000000137156.jpg', 'COCO_val2014_000000137156.jpg', 'COCO_val2014_000000137156.jpg', 'COCO_val2014_000000137156.jpg', 'COCO_val2014_000000137156.jpg', 'COCO_val2014_000000381721.jpg', 'COCO_val2014_000000381721.jpg', 'COCO_val2014_000000381721.jpg', 'COCO_val2014_000000381721.jpg', 'COCO_val2014_000000381721.jpg', 'COCO_val2014_000000330408.jpg', 'COCO_val2014_000000330408.jpg', 'COCO_val2014_000000330408.jpg', 'COCO_val2014_000000330408.jpg', 'COCO_val2014_000000330408.jpg', 'COCO_val2014_000000207967.jpg', 'COCO_val2014_000000207967.jpg', 'COCO_val2014_000000207967.jpg', 'COCO_val2014_000000207967.jpg', 'COCO_val2014_000000207967.jpg', 'COCO_val2014_000000215693.jpg', 'COCO_val2014_000000215693.jpg', 'COCO_val2014_000000215693.jpg', 'COCO_val2014_000000215693.jpg', 'COCO_val2014_000000215693.jpg', 'COCO_val2014_000000003134.jpg', 'COCO_val2014_000000003134.jpg', 'COCO_val2014_000000003134.jpg', 'COCO_val2014_000000003134.jpg', 'COCO_val2014_000000003134.jpg', 'COCO_val2014_000000280238.jpg', 'COCO_val2014_000000280238.jpg', 'COCO_val2014_000000280238.jpg', 'COCO_val2014_000000280238.jpg', 'COCO_val2014_000000280238.jpg', 'COCO_val2014_000000012014.jpg', 'COCO_val2014_000000012014.jpg', 'COCO_val2014_000000012014.jpg', 'COCO_val2014_000000012014.jpg', 'COCO_val2014_000000012014.jpg', 'COCO_val2014_000000416385.jpg', 'COCO_val2014_000000416385.jpg', 'COCO_val2014_000000416385.jpg', 'COCO_val2014_000000416385.jpg', 'COCO_val2014_000000416385.jpg', 'COCO_val2014_000000396496.jpg', 'COCO_val2014_000000396496.jpg', 'COCO_val2014_000000396496.jpg', 'COCO_val2014_000000396496.jpg', 'COCO_val2014_000000396496.jpg', 'COCO_val2014_000000076249.jpg', 'COCO_val2014_000000076249.jpg', 'COCO_val2014_000000076249.jpg', 'COCO_val2014_000000076249.jpg', 'COCO_val2014_000000076249.jpg', 'COCO_val2014_000000370266.jpg', 'COCO_val2014_000000370266.jpg', 'COCO_val2014_000000370266.jpg', 'COCO_val2014_000000370266.jpg', 'COCO_val2014_000000370266.jpg', 'COCO_val2014_000000327919.jpg', 'COCO_val2014_000000327919.jpg', 'COCO_val2014_000000327919.jpg', 'COCO_val2014_000000327919.jpg', 'COCO_val2014_000000327919.jpg', 'COCO_val2014_000000512564.jpg', 'COCO_val2014_000000512564.jpg', 'COCO_val2014_000000512564.jpg', 'COCO_val2014_000000512564.jpg', 'COCO_val2014_000000512564.jpg', 'COCO_val2014_000000365177.jpg', 'COCO_val2014_000000365177.jpg', 'COCO_val2014_000000365177.jpg', 'COCO_val2014_000000365177.jpg', 'COCO_val2014_000000365177.jpg', 'COCO_val2014_000000385781.jpg', 'COCO_val2014_000000385781.jpg', 'COCO_val2014_000000385781.jpg', 'COCO_val2014_000000385781.jpg', 'COCO_val2014_000000385781.jpg', 'COCO_val2014_000000336658.jpg', 'COCO_val2014_000000336658.jpg', 'COCO_val2014_000000336658.jpg', 'COCO_val2014_000000336658.jpg', 'COCO_val2014_000000336658.jpg', 'COCO_val2014_000000053580.jpg', 'COCO_val2014_000000053580.jpg', 'COCO_val2014_000000053580.jpg', 'COCO_val2014_000000053580.jpg', 'COCO_val2014_000000053580.jpg', 'COCO_val2014_000000282871.jpg', 'COCO_val2014_000000282871.jpg', 'COCO_val2014_000000282871.jpg', 'COCO_val2014_000000282871.jpg', 'COCO_val2014_000000282871.jpg', 'COCO_val2014_000000557907.jpg', 'COCO_val2014_000000557907.jpg', 'COCO_val2014_000000557907.jpg', 'COCO_val2014_000000557907.jpg', 'COCO_val2014_000000557907.jpg', 'COCO_val2014_000000200541.jpg', 'COCO_val2014_000000200541.jpg', 'COCO_val2014_000000200541.jpg', 'COCO_val2014_000000200541.jpg', 'COCO_val2014_000000200541.jpg', 'COCO_val2014_000000214255.jpg', 'COCO_val2014_000000214255.jpg', 'COCO_val2014_000000214255.jpg', 'COCO_val2014_000000214255.jpg', 'COCO_val2014_000000214255.jpg', 'COCO_val2014_000000568439.jpg', 'COCO_val2014_000000568439.jpg', 'COCO_val2014_000000568439.jpg', 'COCO_val2014_000000568439.jpg', 'COCO_val2014_000000568439.jpg', 'COCO_val2014_000000372317.jpg', 'COCO_val2014_000000372317.jpg', 'COCO_val2014_000000372317.jpg', 'COCO_val2014_000000372317.jpg', 'COCO_val2014_000000372317.jpg', 'COCO_val2014_000000367205.jpg', 'COCO_val2014_000000367205.jpg', 'COCO_val2014_000000367205.jpg', 'COCO_val2014_000000367205.jpg', 'COCO_val2014_000000367205.jpg', 'COCO_val2014_000000398148.jpg', 'COCO_val2014_000000398148.jpg', 'COCO_val2014_000000398148.jpg', 'COCO_val2014_000000398148.jpg', 'COCO_val2014_000000398148.jpg', 'COCO_val2014_000000025134.jpg', 'COCO_val2014_000000025134.jpg', 'COCO_val2014_000000025134.jpg', 'COCO_val2014_000000025134.jpg', 'COCO_val2014_000000025134.jpg', 'COCO_val2014_000000476704.jpg', 'COCO_val2014_000000476704.jpg', 'COCO_val2014_000000476704.jpg', 'COCO_val2014_000000476704.jpg', 'COCO_val2014_000000476704.jpg', 'COCO_val2014_000000260266.jpg', 'COCO_val2014_000000260266.jpg', 'COCO_val2014_000000260266.jpg', 'COCO_val2014_000000260266.jpg', 'COCO_val2014_000000260266.jpg', 'COCO_val2014_000000524216.jpg', 'COCO_val2014_000000524216.jpg', 'COCO_val2014_000000524216.jpg', 'COCO_val2014_000000524216.jpg', 'COCO_val2014_000000524216.jpg', 'COCO_val2014_000000302137.jpg', 'COCO_val2014_000000302137.jpg', 'COCO_val2014_000000302137.jpg', 'COCO_val2014_000000302137.jpg', 'COCO_val2014_000000302137.jpg', 'COCO_val2014_000000177893.jpg', 'COCO_val2014_000000177893.jpg', 'COCO_val2014_000000177893.jpg', 'COCO_val2014_000000177893.jpg', 'COCO_val2014_000000177893.jpg', 'COCO_val2014_000000036012.jpg', 'COCO_val2014_000000036012.jpg', 'COCO_val2014_000000036012.jpg', 'COCO_val2014_000000036012.jpg', 'COCO_val2014_000000036012.jpg', 'COCO_val2014_000000320893.jpg', 'COCO_val2014_000000320893.jpg', 'COCO_val2014_000000320893.jpg', 'COCO_val2014_000000320893.jpg', 'COCO_val2014_000000320893.jpg', 'COCO_val2014_000000120831.jpg', 'COCO_val2014_000000120831.jpg', 'COCO_val2014_000000120831.jpg', 'COCO_val2014_000000120831.jpg', 'COCO_val2014_000000120831.jpg', 'COCO_val2014_000000229478.jpg', 'COCO_val2014_000000229478.jpg', 'COCO_val2014_000000229478.jpg', 'COCO_val2014_000000229478.jpg', 'COCO_val2014_000000229478.jpg', 'COCO_val2014_000000562708.jpg', 'COCO_val2014_000000562708.jpg', 'COCO_val2014_000000562708.jpg', 'COCO_val2014_000000562708.jpg', 'COCO_val2014_000000562708.jpg', 'COCO_val2014_000000071965.jpg', 'COCO_val2014_000000071965.jpg', 'COCO_val2014_000000071965.jpg', 'COCO_val2014_000000071965.jpg', 'COCO_val2014_000000071965.jpg', 'COCO_val2014_000000399091.jpg', 'COCO_val2014_000000399091.jpg', 'COCO_val2014_000000399091.jpg', 'COCO_val2014_000000399091.jpg', 'COCO_val2014_000000399091.jpg', 'COCO_val2014_000000479099.jpg', 'COCO_val2014_000000479099.jpg', 'COCO_val2014_000000479099.jpg', 'COCO_val2014_000000479099.jpg', 'COCO_val2014_000000479099.jpg', 'COCO_val2014_000000000641.jpg', 'COCO_val2014_000000000641.jpg', 'COCO_val2014_000000000641.jpg', 'COCO_val2014_000000000641.jpg', 'COCO_val2014_000000000641.jpg', 'COCO_val2014_000000289073.jpg', 'COCO_val2014_000000289073.jpg', 'COCO_val2014_000000289073.jpg', 'COCO_val2014_000000289073.jpg', 'COCO_val2014_000000289073.jpg', 'COCO_val2014_000000579036.jpg', 'COCO_val2014_000000579036.jpg', 'COCO_val2014_000000579036.jpg', 'COCO_val2014_000000579036.jpg', 'COCO_val2014_000000579036.jpg', 'COCO_val2014_000000180541.jpg', 'COCO_val2014_000000180541.jpg', 'COCO_val2014_000000180541.jpg', 'COCO_val2014_000000180541.jpg', 'COCO_val2014_000000180541.jpg', 'COCO_val2014_000000269196.jpg', 'COCO_val2014_000000269196.jpg', 'COCO_val2014_000000269196.jpg', 'COCO_val2014_000000269196.jpg', 'COCO_val2014_000000269196.jpg', 'COCO_val2014_000000279154.jpg', 'COCO_val2014_000000279154.jpg', 'COCO_val2014_000000279154.jpg', 'COCO_val2014_000000279154.jpg', 'COCO_val2014_000000279154.jpg', 'COCO_val2014_000000189245.jpg', 'COCO_val2014_000000189245.jpg', 'COCO_val2014_000000189245.jpg', 'COCO_val2014_000000189245.jpg', 'COCO_val2014_000000189245.jpg', 'COCO_val2014_000000315450.jpg', 'COCO_val2014_000000315450.jpg', 'COCO_val2014_000000315450.jpg', 'COCO_val2014_000000315450.jpg', 'COCO_val2014_000000315450.jpg', 'COCO_val2014_000000463783.jpg', 'COCO_val2014_000000463783.jpg', 'COCO_val2014_000000463783.jpg', 'COCO_val2014_000000463783.jpg', 'COCO_val2014_000000463783.jpg', 'COCO_val2014_000000254001.jpg', 'COCO_val2014_000000254001.jpg', 'COCO_val2014_000000254001.jpg', 'COCO_val2014_000000254001.jpg', 'COCO_val2014_000000254001.jpg', 'COCO_val2014_000000139549.jpg', 'COCO_val2014_000000139549.jpg', 'COCO_val2014_000000139549.jpg', 'COCO_val2014_000000139549.jpg', 'COCO_val2014_000000139549.jpg', 'COCO_val2014_000000414249.jpg', 'COCO_val2014_000000414249.jpg', 'COCO_val2014_000000414249.jpg', 'COCO_val2014_000000414249.jpg', 'COCO_val2014_000000414249.jpg', 'COCO_val2014_000000475529.jpg', 'COCO_val2014_000000475529.jpg', 'COCO_val2014_000000475529.jpg', 'COCO_val2014_000000475529.jpg', 'COCO_val2014_000000475529.jpg', 'COCO_val2014_000000243867.jpg', 'COCO_val2014_000000243867.jpg', 'COCO_val2014_000000243867.jpg', 'COCO_val2014_000000243867.jpg', 'COCO_val2014_000000243867.jpg', 'COCO_val2014_000000398628.jpg', 'COCO_val2014_000000398628.jpg', 'COCO_val2014_000000398628.jpg', 'COCO_val2014_000000398628.jpg', 'COCO_val2014_000000398628.jpg', 'COCO_val2014_000000295336.jpg', 'COCO_val2014_000000295336.jpg', 'COCO_val2014_000000295336.jpg', 'COCO_val2014_000000295336.jpg', 'COCO_val2014_000000295336.jpg', 'COCO_val2014_000000435703.jpg', 'COCO_val2014_000000435703.jpg', 'COCO_val2014_000000435703.jpg', 'COCO_val2014_000000435703.jpg', 'COCO_val2014_000000435703.jpg', 'COCO_val2014_000000078023.jpg', 'COCO_val2014_000000078023.jpg', 'COCO_val2014_000000078023.jpg', 'COCO_val2014_000000078023.jpg', 'COCO_val2014_000000078023.jpg', 'COCO_val2014_000000118956.jpg', 'COCO_val2014_000000118956.jpg', 'COCO_val2014_000000118956.jpg', 'COCO_val2014_000000118956.jpg', 'COCO_val2014_000000118956.jpg', 'COCO_val2014_000000187876.jpg', 'COCO_val2014_000000187876.jpg', 'COCO_val2014_000000187876.jpg', 'COCO_val2014_000000187876.jpg', 'COCO_val2014_000000187876.jpg', 'COCO_val2014_000000405047.jpg', 'COCO_val2014_000000405047.jpg', 'COCO_val2014_000000405047.jpg', 'COCO_val2014_000000405047.jpg', 'COCO_val2014_000000405047.jpg', 'COCO_val2014_000000478665.jpg', 'COCO_val2014_000000478665.jpg', 'COCO_val2014_000000478665.jpg', 'COCO_val2014_000000478665.jpg', 'COCO_val2014_000000478665.jpg', 'COCO_val2014_000000090442.jpg', 'COCO_val2014_000000090442.jpg', 'COCO_val2014_000000090442.jpg', 'COCO_val2014_000000090442.jpg', 'COCO_val2014_000000090442.jpg', 'COCO_val2014_000000263594.jpg', 'COCO_val2014_000000263594.jpg', 'COCO_val2014_000000263594.jpg', 'COCO_val2014_000000263594.jpg', 'COCO_val2014_000000263594.jpg', 'COCO_val2014_000000024195.jpg', 'COCO_val2014_000000024195.jpg', 'COCO_val2014_000000024195.jpg', 'COCO_val2014_000000024195.jpg', 'COCO_val2014_000000024195.jpg', 'COCO_val2014_000000525542.jpg', 'COCO_val2014_000000525542.jpg', 'COCO_val2014_000000525542.jpg', 'COCO_val2014_000000525542.jpg', 'COCO_val2014_000000525542.jpg', 'COCO_val2014_000000508165.jpg', 'COCO_val2014_000000508165.jpg', 'COCO_val2014_000000508165.jpg', 'COCO_val2014_000000508165.jpg', 'COCO_val2014_000000508165.jpg', 'COCO_val2014_000000409138.jpg', 'COCO_val2014_000000409138.jpg', 'COCO_val2014_000000409138.jpg', 'COCO_val2014_000000409138.jpg', 'COCO_val2014_000000409138.jpg', 'COCO_val2014_000000061959.jpg', 'COCO_val2014_000000061959.jpg', 'COCO_val2014_000000061959.jpg', 'COCO_val2014_000000061959.jpg', 'COCO_val2014_000000061959.jpg', 'COCO_val2014_000000088432.jpg', 'COCO_val2014_000000088432.jpg', 'COCO_val2014_000000088432.jpg', 'COCO_val2014_000000088432.jpg', 'COCO_val2014_000000088432.jpg', 'COCO_val2014_000000057390.jpg', 'COCO_val2014_000000057390.jpg', 'COCO_val2014_000000057390.jpg', 'COCO_val2014_000000057390.jpg', 'COCO_val2014_000000057390.jpg', 'COCO_val2014_000000268044.jpg', 'COCO_val2014_000000268044.jpg', 'COCO_val2014_000000268044.jpg', 'COCO_val2014_000000268044.jpg', 'COCO_val2014_000000268044.jpg', 'COCO_val2014_000000282366.jpg', 'COCO_val2014_000000282366.jpg', 'COCO_val2014_000000282366.jpg', 'COCO_val2014_000000282366.jpg', 'COCO_val2014_000000282366.jpg', 'COCO_val2014_000000005437.jpg', 'COCO_val2014_000000005437.jpg', 'COCO_val2014_000000005437.jpg', 'COCO_val2014_000000005437.jpg', 'COCO_val2014_000000005437.jpg', 'COCO_val2014_000000107840.jpg', 'COCO_val2014_000000107840.jpg', 'COCO_val2014_000000107840.jpg', 'COCO_val2014_000000107840.jpg', 'COCO_val2014_000000107840.jpg', 'COCO_val2014_000000272364.jpg', 'COCO_val2014_000000272364.jpg', 'COCO_val2014_000000272364.jpg', 'COCO_val2014_000000272364.jpg', 'COCO_val2014_000000272364.jpg', 'COCO_val2014_000000088084.jpg', 'COCO_val2014_000000088084.jpg', 'COCO_val2014_000000088084.jpg', 'COCO_val2014_000000088084.jpg', 'COCO_val2014_000000088084.jpg', 'COCO_val2014_000000559416.jpg', 'COCO_val2014_000000559416.jpg', 'COCO_val2014_000000559416.jpg', 'COCO_val2014_000000559416.jpg', 'COCO_val2014_000000559416.jpg', 'COCO_val2014_000000464390.jpg', 'COCO_val2014_000000464390.jpg', 'COCO_val2014_000000464390.jpg', 'COCO_val2014_000000464390.jpg', 'COCO_val2014_000000464390.jpg', 'COCO_val2014_000000568956.jpg', 'COCO_val2014_000000568956.jpg', 'COCO_val2014_000000568956.jpg', 'COCO_val2014_000000568956.jpg', 'COCO_val2014_000000568956.jpg', 'COCO_val2014_000000299442.jpg', 'COCO_val2014_000000299442.jpg', 'COCO_val2014_000000299442.jpg', 'COCO_val2014_000000299442.jpg', 'COCO_val2014_000000299442.jpg', 'COCO_val2014_000000417115.jpg', 'COCO_val2014_000000417115.jpg', 'COCO_val2014_000000417115.jpg', 'COCO_val2014_000000417115.jpg', 'COCO_val2014_000000417115.jpg', 'COCO_val2014_000000232550.jpg', 'COCO_val2014_000000232550.jpg', 'COCO_val2014_000000232550.jpg', 'COCO_val2014_000000232550.jpg', 'COCO_val2014_000000232550.jpg', 'COCO_val2014_000000457348.jpg', 'COCO_val2014_000000457348.jpg', 'COCO_val2014_000000457348.jpg', 'COCO_val2014_000000457348.jpg', 'COCO_val2014_000000457348.jpg', 'COCO_val2014_000000154168.jpg', 'COCO_val2014_000000154168.jpg', 'COCO_val2014_000000154168.jpg', 'COCO_val2014_000000154168.jpg', 'COCO_val2014_000000154168.jpg', 'COCO_val2014_000000019624.jpg', 'COCO_val2014_000000019624.jpg', 'COCO_val2014_000000019624.jpg', 'COCO_val2014_000000019624.jpg', 'COCO_val2014_000000019624.jpg', 'COCO_val2014_000000212507.jpg', 'COCO_val2014_000000212507.jpg', 'COCO_val2014_000000212507.jpg', 'COCO_val2014_000000212507.jpg', 'COCO_val2014_000000212507.jpg', 'COCO_val2014_000000431152.jpg', 'COCO_val2014_000000431152.jpg', 'COCO_val2014_000000431152.jpg', 'COCO_val2014_000000431152.jpg', 'COCO_val2014_000000431152.jpg', 'COCO_val2014_000000519491.jpg', 'COCO_val2014_000000519491.jpg', 'COCO_val2014_000000519491.jpg', 'COCO_val2014_000000519491.jpg', 'COCO_val2014_000000519491.jpg', 'COCO_val2014_000000500468.jpg', 'COCO_val2014_000000500468.jpg', 'COCO_val2014_000000500468.jpg', 'COCO_val2014_000000500468.jpg', 'COCO_val2014_000000500468.jpg', 'COCO_val2014_000000100283.jpg', 'COCO_val2014_000000100283.jpg', 'COCO_val2014_000000100283.jpg', 'COCO_val2014_000000100283.jpg', 'COCO_val2014_000000100283.jpg', 'COCO_val2014_000000563653.jpg', 'COCO_val2014_000000563653.jpg', 'COCO_val2014_000000563653.jpg', 'COCO_val2014_000000563653.jpg', 'COCO_val2014_000000563653.jpg', 'COCO_val2014_000000343821.jpg', 'COCO_val2014_000000343821.jpg', 'COCO_val2014_000000343821.jpg', 'COCO_val2014_000000343821.jpg', 'COCO_val2014_000000343821.jpg', 'COCO_val2014_000000543492.jpg', 'COCO_val2014_000000543492.jpg', 'COCO_val2014_000000543492.jpg', 'COCO_val2014_000000543492.jpg', 'COCO_val2014_000000543492.jpg', 'COCO_val2014_000000276971.jpg', 'COCO_val2014_000000276971.jpg', 'COCO_val2014_000000276971.jpg', 'COCO_val2014_000000276971.jpg', 'COCO_val2014_000000276971.jpg', 'COCO_val2014_000000324670.jpg', 'COCO_val2014_000000324670.jpg', 'COCO_val2014_000000324670.jpg', 'COCO_val2014_000000324670.jpg', 'COCO_val2014_000000324670.jpg', 'COCO_val2014_000000224916.jpg', 'COCO_val2014_000000224916.jpg', 'COCO_val2014_000000224916.jpg', 'COCO_val2014_000000224916.jpg', 'COCO_val2014_000000224916.jpg', 'COCO_val2014_000000345361.jpg', 'COCO_val2014_000000345361.jpg', 'COCO_val2014_000000345361.jpg', 'COCO_val2014_000000345361.jpg', 'COCO_val2014_000000345361.jpg', 'COCO_val2014_000000068715.jpg', 'COCO_val2014_000000068715.jpg', 'COCO_val2014_000000068715.jpg', 'COCO_val2014_000000068715.jpg', 'COCO_val2014_000000068715.jpg', 'COCO_val2014_000000113051.jpg', 'COCO_val2014_000000113051.jpg', 'COCO_val2014_000000113051.jpg', 'COCO_val2014_000000113051.jpg', 'COCO_val2014_000000113051.jpg', 'COCO_val2014_000000502317.jpg', 'COCO_val2014_000000502317.jpg', 'COCO_val2014_000000502317.jpg', 'COCO_val2014_000000502317.jpg', 'COCO_val2014_000000502317.jpg', 'COCO_val2014_000000286708.jpg', 'COCO_val2014_000000286708.jpg', 'COCO_val2014_000000286708.jpg', 'COCO_val2014_000000286708.jpg', 'COCO_val2014_000000286708.jpg', 'COCO_val2014_000000137185.jpg', 'COCO_val2014_000000137185.jpg', 'COCO_val2014_000000137185.jpg', 'COCO_val2014_000000137185.jpg', 'COCO_val2014_000000137185.jpg', 'COCO_val2014_000000030478.jpg', 'COCO_val2014_000000030478.jpg', 'COCO_val2014_000000030478.jpg', 'COCO_val2014_000000030478.jpg', 'COCO_val2014_000000030478.jpg', 'COCO_val2014_000000007952.jpg', 'COCO_val2014_000000007952.jpg', 'COCO_val2014_000000007952.jpg', 'COCO_val2014_000000007952.jpg', 'COCO_val2014_000000007952.jpg', 'COCO_val2014_000000339738.jpg', 'COCO_val2014_000000339738.jpg', 'COCO_val2014_000000339738.jpg', 'COCO_val2014_000000339738.jpg', 'COCO_val2014_000000339738.jpg', 'COCO_val2014_000000229387.jpg', 'COCO_val2014_000000229387.jpg', 'COCO_val2014_000000229387.jpg', 'COCO_val2014_000000229387.jpg', 'COCO_val2014_000000229387.jpg', 'COCO_val2014_000000108244.jpg', 'COCO_val2014_000000108244.jpg', 'COCO_val2014_000000108244.jpg', 'COCO_val2014_000000108244.jpg', 'COCO_val2014_000000108244.jpg', 'COCO_val2014_000000121153.jpg', 'COCO_val2014_000000121153.jpg', 'COCO_val2014_000000121153.jpg', 'COCO_val2014_000000121153.jpg', 'COCO_val2014_000000121153.jpg', 'COCO_val2014_000000023230.jpg', 'COCO_val2014_000000023230.jpg', 'COCO_val2014_000000023230.jpg', 'COCO_val2014_000000023230.jpg', 'COCO_val2014_000000023230.jpg', 'COCO_val2014_000000460972.jpg', 'COCO_val2014_000000460972.jpg', 'COCO_val2014_000000460972.jpg', 'COCO_val2014_000000460972.jpg', 'COCO_val2014_000000460972.jpg', 'COCO_val2014_000000358795.jpg', 'COCO_val2014_000000358795.jpg', 'COCO_val2014_000000358795.jpg', 'COCO_val2014_000000358795.jpg', 'COCO_val2014_000000358795.jpg', 'COCO_val2014_000000337035.jpg', 'COCO_val2014_000000337035.jpg', 'COCO_val2014_000000337035.jpg', 'COCO_val2014_000000337035.jpg', 'COCO_val2014_000000337035.jpg', 'COCO_val2014_000000473214.jpg', 'COCO_val2014_000000473214.jpg', 'COCO_val2014_000000473214.jpg', 'COCO_val2014_000000473214.jpg', 'COCO_val2014_000000473214.jpg', 'COCO_val2014_000000054007.jpg', 'COCO_val2014_000000054007.jpg', 'COCO_val2014_000000054007.jpg', 'COCO_val2014_000000054007.jpg', 'COCO_val2014_000000054007.jpg', 'COCO_val2014_000000209274.jpg', 'COCO_val2014_000000209274.jpg', 'COCO_val2014_000000209274.jpg', 'COCO_val2014_000000209274.jpg', 'COCO_val2014_000000209274.jpg', 'COCO_val2014_000000421976.jpg', 'COCO_val2014_000000421976.jpg', 'COCO_val2014_000000421976.jpg', 'COCO_val2014_000000421976.jpg', 'COCO_val2014_000000421976.jpg', 'COCO_val2014_000000114710.jpg', 'COCO_val2014_000000114710.jpg', 'COCO_val2014_000000114710.jpg', 'COCO_val2014_000000114710.jpg', 'COCO_val2014_000000114710.jpg', 'COCO_val2014_000000114710.jpg', 'COCO_val2014_000000377949.jpg', 'COCO_val2014_000000377949.jpg', 'COCO_val2014_000000377949.jpg', 'COCO_val2014_000000377949.jpg', 'COCO_val2014_000000377949.jpg', 'COCO_val2014_000000070870.jpg', 'COCO_val2014_000000070870.jpg', 'COCO_val2014_000000070870.jpg', 'COCO_val2014_000000070870.jpg', 'COCO_val2014_000000070870.jpg', 'COCO_val2014_000000145562.jpg', 'COCO_val2014_000000145562.jpg', 'COCO_val2014_000000145562.jpg', 'COCO_val2014_000000145562.jpg', 'COCO_val2014_000000145562.jpg', 'COCO_val2014_000000170129.jpg', 'COCO_val2014_000000170129.jpg', 'COCO_val2014_000000170129.jpg', 'COCO_val2014_000000170129.jpg', 'COCO_val2014_000000170129.jpg', 'COCO_val2014_000000078865.jpg', 'COCO_val2014_000000078865.jpg', 'COCO_val2014_000000078865.jpg', 'COCO_val2014_000000078865.jpg', 'COCO_val2014_000000078865.jpg', 'COCO_val2014_000000150893.jpg', 'COCO_val2014_000000150893.jpg', 'COCO_val2014_000000150893.jpg', 'COCO_val2014_000000150893.jpg', 'COCO_val2014_000000150893.jpg', 'COCO_val2014_000000559955.jpg', 'COCO_val2014_000000559955.jpg', 'COCO_val2014_000000559955.jpg', 'COCO_val2014_000000559955.jpg', 'COCO_val2014_000000559955.jpg', 'COCO_val2014_000000468499.jpg', 'COCO_val2014_000000468499.jpg', 'COCO_val2014_000000468499.jpg', 'COCO_val2014_000000468499.jpg', 'COCO_val2014_000000468499.jpg', 'COCO_val2014_000000296388.jpg', 'COCO_val2014_000000296388.jpg', 'COCO_val2014_000000296388.jpg', 'COCO_val2014_000000296388.jpg', 'COCO_val2014_000000296388.jpg', 'COCO_val2014_000000381842.jpg', 'COCO_val2014_000000381842.jpg', 'COCO_val2014_000000381842.jpg', 'COCO_val2014_000000381842.jpg', 'COCO_val2014_000000381842.jpg', 'COCO_val2014_000000035436.jpg', 'COCO_val2014_000000035436.jpg', 'COCO_val2014_000000035436.jpg', 'COCO_val2014_000000035436.jpg', 'COCO_val2014_000000035436.jpg', 'COCO_val2014_000000147577.jpg', 'COCO_val2014_000000147577.jpg', 'COCO_val2014_000000147577.jpg', 'COCO_val2014_000000147577.jpg', 'COCO_val2014_000000147577.jpg', 'COCO_val2014_000000104880.jpg', 'COCO_val2014_000000104880.jpg', 'COCO_val2014_000000104880.jpg', 'COCO_val2014_000000104880.jpg', 'COCO_val2014_000000104880.jpg', 'COCO_val2014_000000210766.jpg', 'COCO_val2014_000000210766.jpg', 'COCO_val2014_000000210766.jpg', 'COCO_val2014_000000210766.jpg', 'COCO_val2014_000000210766.jpg', 'COCO_val2014_000000056932.jpg', 'COCO_val2014_000000056932.jpg', 'COCO_val2014_000000056932.jpg', 'COCO_val2014_000000056932.jpg', 'COCO_val2014_000000056932.jpg', 'COCO_val2014_000000522959.jpg', 'COCO_val2014_000000522959.jpg', 'COCO_val2014_000000522959.jpg', 'COCO_val2014_000000522959.jpg', 'COCO_val2014_000000522959.jpg', 'COCO_val2014_000000505933.jpg', 'COCO_val2014_000000505933.jpg', 'COCO_val2014_000000505933.jpg', 'COCO_val2014_000000505933.jpg', 'COCO_val2014_000000505933.jpg', 'COCO_val2014_000000353977.jpg', 'COCO_val2014_000000353977.jpg', 'COCO_val2014_000000353977.jpg', 'COCO_val2014_000000353977.jpg', 'COCO_val2014_000000353977.jpg', 'COCO_val2014_000000353977.jpg', 'COCO_val2014_000000375409.jpg', 'COCO_val2014_000000375409.jpg', 'COCO_val2014_000000375409.jpg', 'COCO_val2014_000000375409.jpg', 'COCO_val2014_000000375409.jpg', 'COCO_val2014_000000253940.jpg', 'COCO_val2014_000000253940.jpg', 'COCO_val2014_000000253940.jpg', 'COCO_val2014_000000253940.jpg', 'COCO_val2014_000000253940.jpg', 'COCO_val2014_000000187450.jpg', 'COCO_val2014_000000187450.jpg', 'COCO_val2014_000000187450.jpg', 'COCO_val2014_000000187450.jpg', 'COCO_val2014_000000187450.jpg', 'COCO_val2014_000000403481.jpg', 'COCO_val2014_000000403481.jpg', 'COCO_val2014_000000403481.jpg', 'COCO_val2014_000000403481.jpg', 'COCO_val2014_000000403481.jpg', 'COCO_val2014_000000225093.jpg', 'COCO_val2014_000000225093.jpg', 'COCO_val2014_000000225093.jpg', 'COCO_val2014_000000225093.jpg', 'COCO_val2014_000000225093.jpg', 'COCO_val2014_000000174198.jpg', 'COCO_val2014_000000174198.jpg', 'COCO_val2014_000000174198.jpg', 'COCO_val2014_000000174198.jpg', 'COCO_val2014_000000174198.jpg', 'COCO_val2014_000000390368.jpg', 'COCO_val2014_000000390368.jpg', 'COCO_val2014_000000390368.jpg', 'COCO_val2014_000000390368.jpg', 'COCO_val2014_000000390368.jpg', 'COCO_val2014_000000521141.jpg', 'COCO_val2014_000000521141.jpg', 'COCO_val2014_000000521141.jpg', 'COCO_val2014_000000521141.jpg', 'COCO_val2014_000000521141.jpg', 'COCO_val2014_000000415840.jpg', 'COCO_val2014_000000415840.jpg', 'COCO_val2014_000000415840.jpg', 'COCO_val2014_000000415840.jpg', 'COCO_val2014_000000415840.jpg', 'COCO_val2014_000000193069.jpg', 'COCO_val2014_000000193069.jpg', 'COCO_val2014_000000193069.jpg', 'COCO_val2014_000000193069.jpg', 'COCO_val2014_000000193069.jpg', 'COCO_val2014_000000289870.jpg', 'COCO_val2014_000000289870.jpg', 'COCO_val2014_000000289870.jpg', 'COCO_val2014_000000289870.jpg', 'COCO_val2014_000000289870.jpg', 'COCO_val2014_000000006789.jpg', 'COCO_val2014_000000006789.jpg', 'COCO_val2014_000000006789.jpg', 'COCO_val2014_000000006789.jpg', 'COCO_val2014_000000006789.jpg', 'COCO_val2014_000000061268.jpg', 'COCO_val2014_000000061268.jpg', 'COCO_val2014_000000061268.jpg', 'COCO_val2014_000000061268.jpg', 'COCO_val2014_000000061268.jpg', 'COCO_val2014_000000037709.jpg', 'COCO_val2014_000000037709.jpg', 'COCO_val2014_000000037709.jpg', 'COCO_val2014_000000037709.jpg', 'COCO_val2014_000000037709.jpg', 'COCO_val2014_000000393093.jpg', 'COCO_val2014_000000393093.jpg', 'COCO_val2014_000000393093.jpg', 'COCO_val2014_000000393093.jpg', 'COCO_val2014_000000393093.jpg', 'COCO_val2014_000000565971.jpg', 'COCO_val2014_000000565971.jpg', 'COCO_val2014_000000565971.jpg', 'COCO_val2014_000000565971.jpg', 'COCO_val2014_000000565971.jpg', 'COCO_val2014_000000013965.jpg', 'COCO_val2014_000000013965.jpg', 'COCO_val2014_000000013965.jpg', 'COCO_val2014_000000013965.jpg', 'COCO_val2014_000000013965.jpg', 'COCO_val2014_000000418092.jpg', 'COCO_val2014_000000418092.jpg', 'COCO_val2014_000000418092.jpg', 'COCO_val2014_000000418092.jpg', 'COCO_val2014_000000418092.jpg', 'COCO_val2014_000000024629.jpg', 'COCO_val2014_000000024629.jpg', 'COCO_val2014_000000024629.jpg', 'COCO_val2014_000000024629.jpg', 'COCO_val2014_000000024629.jpg', 'COCO_val2014_000000522406.jpg', 'COCO_val2014_000000522406.jpg', 'COCO_val2014_000000522406.jpg', 'COCO_val2014_000000522406.jpg', 'COCO_val2014_000000522406.jpg', 'COCO_val2014_000000075046.jpg', 'COCO_val2014_000000075046.jpg', 'COCO_val2014_000000075046.jpg', 'COCO_val2014_000000075046.jpg', 'COCO_val2014_000000075046.jpg', 'COCO_val2014_000000055545.jpg', 'COCO_val2014_000000055545.jpg', 'COCO_val2014_000000055545.jpg', 'COCO_val2014_000000055545.jpg', 'COCO_val2014_000000055545.jpg', 'COCO_val2014_000000061715.jpg', 'COCO_val2014_000000061715.jpg', 'COCO_val2014_000000061715.jpg', 'COCO_val2014_000000061715.jpg', 'COCO_val2014_000000061715.jpg', 'COCO_val2014_000000257940.jpg', 'COCO_val2014_000000257940.jpg', 'COCO_val2014_000000257940.jpg', 'COCO_val2014_000000257940.jpg', 'COCO_val2014_000000257940.jpg', 'COCO_val2014_000000227134.jpg', 'COCO_val2014_000000227134.jpg', 'COCO_val2014_000000227134.jpg', 'COCO_val2014_000000227134.jpg', 'COCO_val2014_000000227134.jpg', 'COCO_val2014_000000160394.jpg', 'COCO_val2014_000000160394.jpg', 'COCO_val2014_000000160394.jpg', 'COCO_val2014_000000160394.jpg', 'COCO_val2014_000000160394.jpg', 'COCO_val2014_000000151135.jpg', 'COCO_val2014_000000151135.jpg', 'COCO_val2014_000000151135.jpg', 'COCO_val2014_000000151135.jpg', 'COCO_val2014_000000151135.jpg', 'COCO_val2014_000000011122.jpg', 'COCO_val2014_000000011122.jpg', 'COCO_val2014_000000011122.jpg', 'COCO_val2014_000000011122.jpg', 'COCO_val2014_000000011122.jpg', 'COCO_val2014_000000013127.jpg', 'COCO_val2014_000000013127.jpg', 'COCO_val2014_000000013127.jpg', 'COCO_val2014_000000013127.jpg', 'COCO_val2014_000000013127.jpg', 'COCO_val2014_000000198510.jpg', 'COCO_val2014_000000198510.jpg', 'COCO_val2014_000000198510.jpg', 'COCO_val2014_000000198510.jpg', 'COCO_val2014_000000198510.jpg', 'COCO_val2014_000000126592.jpg', 'COCO_val2014_000000126592.jpg', 'COCO_val2014_000000126592.jpg', 'COCO_val2014_000000126592.jpg', 'COCO_val2014_000000126592.jpg', 'COCO_val2014_000000461973.jpg', 'COCO_val2014_000000461973.jpg', 'COCO_val2014_000000461973.jpg', 'COCO_val2014_000000461973.jpg', 'COCO_val2014_000000461973.jpg', 'COCO_val2014_000000276437.jpg', 'COCO_val2014_000000276437.jpg', 'COCO_val2014_000000276437.jpg', 'COCO_val2014_000000276437.jpg', 'COCO_val2014_000000276437.jpg', 'COCO_val2014_000000535242.jpg', 'COCO_val2014_000000535242.jpg', 'COCO_val2014_000000535242.jpg', 'COCO_val2014_000000535242.jpg', 'COCO_val2014_000000535242.jpg', 'COCO_val2014_000000242869.jpg', 'COCO_val2014_000000242869.jpg', 'COCO_val2014_000000242869.jpg', 'COCO_val2014_000000242869.jpg', 'COCO_val2014_000000242869.jpg', 'COCO_val2014_000000095227.jpg', 'COCO_val2014_000000095227.jpg', 'COCO_val2014_000000095227.jpg', 'COCO_val2014_000000095227.jpg', 'COCO_val2014_000000095227.jpg', 'COCO_val2014_000000386581.jpg', 'COCO_val2014_000000386581.jpg', 'COCO_val2014_000000386581.jpg', 'COCO_val2014_000000386581.jpg', 'COCO_val2014_000000386581.jpg', 'COCO_val2014_000000573622.jpg', 'COCO_val2014_000000573622.jpg', 'COCO_val2014_000000573622.jpg', 'COCO_val2014_000000573622.jpg', 'COCO_val2014_000000573622.jpg', 'COCO_val2014_000000416269.jpg', 'COCO_val2014_000000416269.jpg', 'COCO_val2014_000000416269.jpg', 'COCO_val2014_000000416269.jpg', 'COCO_val2014_000000416269.jpg', 'COCO_val2014_000000491764.jpg', 'COCO_val2014_000000491764.jpg', 'COCO_val2014_000000491764.jpg', 'COCO_val2014_000000491764.jpg', 'COCO_val2014_000000491764.jpg', 'COCO_val2014_000000172924.jpg', 'COCO_val2014_000000172924.jpg', 'COCO_val2014_000000172924.jpg', 'COCO_val2014_000000172924.jpg', 'COCO_val2014_000000172924.jpg', 'COCO_val2014_000000242570.jpg', 'COCO_val2014_000000242570.jpg', 'COCO_val2014_000000242570.jpg', 'COCO_val2014_000000242570.jpg', 'COCO_val2014_000000242570.jpg', 'COCO_val2014_000000188522.jpg', 'COCO_val2014_000000188522.jpg', 'COCO_val2014_000000188522.jpg', 'COCO_val2014_000000188522.jpg', 'COCO_val2014_000000188522.jpg', 'COCO_val2014_000000148280.jpg', 'COCO_val2014_000000148280.jpg', 'COCO_val2014_000000148280.jpg', 'COCO_val2014_000000148280.jpg', 'COCO_val2014_000000148280.jpg', 'COCO_val2014_000000521052.jpg', 'COCO_val2014_000000521052.jpg', 'COCO_val2014_000000521052.jpg', 'COCO_val2014_000000521052.jpg', 'COCO_val2014_000000521052.jpg', 'COCO_val2014_000000507384.jpg', 'COCO_val2014_000000507384.jpg', 'COCO_val2014_000000507384.jpg', 'COCO_val2014_000000507384.jpg', 'COCO_val2014_000000507384.jpg', 'COCO_val2014_000000293027.jpg', 'COCO_val2014_000000293027.jpg', 'COCO_val2014_000000293027.jpg', 'COCO_val2014_000000293027.jpg', 'COCO_val2014_000000293027.jpg', 'COCO_val2014_000000546896.jpg', 'COCO_val2014_000000546896.jpg', 'COCO_val2014_000000546896.jpg', 'COCO_val2014_000000546896.jpg', 'COCO_val2014_000000546896.jpg', 'COCO_val2014_000000102421.jpg', 'COCO_val2014_000000102421.jpg', 'COCO_val2014_000000102421.jpg', 'COCO_val2014_000000102421.jpg', 'COCO_val2014_000000102421.jpg', 'COCO_val2014_000000186296.jpg', 'COCO_val2014_000000186296.jpg', 'COCO_val2014_000000186296.jpg', 'COCO_val2014_000000186296.jpg', 'COCO_val2014_000000186296.jpg', 'COCO_val2014_000000129957.jpg', 'COCO_val2014_000000129957.jpg', 'COCO_val2014_000000129957.jpg', 'COCO_val2014_000000129957.jpg', 'COCO_val2014_000000129957.jpg', 'COCO_val2014_000000268412.jpg', 'COCO_val2014_000000268412.jpg', 'COCO_val2014_000000268412.jpg', 'COCO_val2014_000000268412.jpg', 'COCO_val2014_000000268412.jpg', 'COCO_val2014_000000571835.jpg', 'COCO_val2014_000000571835.jpg', 'COCO_val2014_000000571835.jpg', 'COCO_val2014_000000571835.jpg', 'COCO_val2014_000000571835.jpg', 'COCO_val2014_000000161195.jpg', 'COCO_val2014_000000161195.jpg', 'COCO_val2014_000000161195.jpg', 'COCO_val2014_000000161195.jpg', 'COCO_val2014_000000161195.jpg', 'COCO_val2014_000000100539.jpg', 'COCO_val2014_000000100539.jpg', 'COCO_val2014_000000100539.jpg', 'COCO_val2014_000000100539.jpg', 'COCO_val2014_000000100539.jpg', 'COCO_val2014_000000020947.jpg', 'COCO_val2014_000000020947.jpg', 'COCO_val2014_000000020947.jpg', 'COCO_val2014_000000020947.jpg', 'COCO_val2014_000000020947.jpg', 'COCO_val2014_000000385204.jpg', 'COCO_val2014_000000385204.jpg', 'COCO_val2014_000000385204.jpg', 'COCO_val2014_000000385204.jpg', 'COCO_val2014_000000385204.jpg', 'COCO_val2014_000000262758.jpg', 'COCO_val2014_000000262758.jpg', 'COCO_val2014_000000262758.jpg', 'COCO_val2014_000000262758.jpg', 'COCO_val2014_000000262758.jpg', 'COCO_val2014_000000526962.jpg', 'COCO_val2014_000000526962.jpg', 'COCO_val2014_000000526962.jpg', 'COCO_val2014_000000526962.jpg', 'COCO_val2014_000000526962.jpg', 'COCO_val2014_000000502275.jpg', 'COCO_val2014_000000502275.jpg', 'COCO_val2014_000000502275.jpg', 'COCO_val2014_000000502275.jpg', 'COCO_val2014_000000502275.jpg', 'COCO_val2014_000000279919.jpg', 'COCO_val2014_000000279919.jpg', 'COCO_val2014_000000279919.jpg', 'COCO_val2014_000000279919.jpg', 'COCO_val2014_000000279919.jpg', 'COCO_val2014_000000223757.jpg', 'COCO_val2014_000000223757.jpg', 'COCO_val2014_000000223757.jpg', 'COCO_val2014_000000223757.jpg', 'COCO_val2014_000000223757.jpg', 'COCO_val2014_000000215949.jpg', 'COCO_val2014_000000215949.jpg', 'COCO_val2014_000000215949.jpg', 'COCO_val2014_000000215949.jpg', 'COCO_val2014_000000215949.jpg', 'COCO_val2014_000000553761.jpg', 'COCO_val2014_000000553761.jpg', 'COCO_val2014_000000553761.jpg', 'COCO_val2014_000000553761.jpg', 'COCO_val2014_000000553761.jpg', 'COCO_val2014_000000322057.jpg', 'COCO_val2014_000000322057.jpg', 'COCO_val2014_000000322057.jpg', 'COCO_val2014_000000322057.jpg', 'COCO_val2014_000000322057.jpg', 'COCO_val2014_000000335579.jpg', 'COCO_val2014_000000335579.jpg', 'COCO_val2014_000000335579.jpg', 'COCO_val2014_000000335579.jpg', 'COCO_val2014_000000335579.jpg', 'COCO_val2014_000000415990.jpg', 'COCO_val2014_000000415990.jpg', 'COCO_val2014_000000415990.jpg', 'COCO_val2014_000000415990.jpg', 'COCO_val2014_000000415990.jpg', 'COCO_val2014_000000187236.jpg', 'COCO_val2014_000000187236.jpg', 'COCO_val2014_000000187236.jpg', 'COCO_val2014_000000187236.jpg', 'COCO_val2014_000000187236.jpg', 'COCO_val2014_000000423336.jpg', 'COCO_val2014_000000423336.jpg', 'COCO_val2014_000000423336.jpg', 'COCO_val2014_000000423336.jpg', 'COCO_val2014_000000423336.jpg', 'COCO_val2014_000000460147.jpg', 'COCO_val2014_000000460147.jpg', 'COCO_val2014_000000460147.jpg', 'COCO_val2014_000000460147.jpg', 'COCO_val2014_000000460147.jpg', 'COCO_val2014_000000200667.jpg', 'COCO_val2014_000000200667.jpg', 'COCO_val2014_000000200667.jpg', 'COCO_val2014_000000200667.jpg', 'COCO_val2014_000000200667.jpg', 'COCO_val2014_000000443499.jpg', 'COCO_val2014_000000443499.jpg', 'COCO_val2014_000000443499.jpg', 'COCO_val2014_000000443499.jpg', 'COCO_val2014_000000443499.jpg', 'COCO_val2014_000000024403.jpg', 'COCO_val2014_000000024403.jpg', 'COCO_val2014_000000024403.jpg', 'COCO_val2014_000000024403.jpg', 'COCO_val2014_000000024403.jpg', 'COCO_val2014_000000278463.jpg', 'COCO_val2014_000000278463.jpg', 'COCO_val2014_000000278463.jpg', 'COCO_val2014_000000278463.jpg', 'COCO_val2014_000000278463.jpg', 'COCO_val2014_000000239387.jpg', 'COCO_val2014_000000239387.jpg', 'COCO_val2014_000000239387.jpg', 'COCO_val2014_000000239387.jpg', 'COCO_val2014_000000239387.jpg', 'COCO_val2014_000000082338.jpg', 'COCO_val2014_000000082338.jpg', 'COCO_val2014_000000082338.jpg', 'COCO_val2014_000000082338.jpg', 'COCO_val2014_000000082338.jpg', 'COCO_val2014_000000314188.jpg', 'COCO_val2014_000000314188.jpg', 'COCO_val2014_000000314188.jpg', 'COCO_val2014_000000314188.jpg', 'COCO_val2014_000000314188.jpg', 'COCO_val2014_000000190140.jpg', 'COCO_val2014_000000190140.jpg', 'COCO_val2014_000000190140.jpg', 'COCO_val2014_000000190140.jpg', 'COCO_val2014_000000190140.jpg', 'COCO_val2014_000000423065.jpg', 'COCO_val2014_000000423065.jpg', 'COCO_val2014_000000423065.jpg', 'COCO_val2014_000000423065.jpg', 'COCO_val2014_000000423065.jpg', 'COCO_val2014_000000174679.jpg', 'COCO_val2014_000000174679.jpg', 'COCO_val2014_000000174679.jpg', 'COCO_val2014_000000174679.jpg', 'COCO_val2014_000000174679.jpg', 'COCO_val2014_000000052853.jpg', 'COCO_val2014_000000052853.jpg', 'COCO_val2014_000000052853.jpg', 'COCO_val2014_000000052853.jpg', 'COCO_val2014_000000052853.jpg', 'COCO_val2014_000000135158.jpg', 'COCO_val2014_000000135158.jpg', 'COCO_val2014_000000135158.jpg', 'COCO_val2014_000000135158.jpg', 'COCO_val2014_000000135158.jpg', 'COCO_val2014_000000476810.jpg', 'COCO_val2014_000000476810.jpg', 'COCO_val2014_000000476810.jpg', 'COCO_val2014_000000476810.jpg', 'COCO_val2014_000000476810.jpg', 'COCO_val2014_000000377080.jpg', 'COCO_val2014_000000377080.jpg', 'COCO_val2014_000000377080.jpg', 'COCO_val2014_000000377080.jpg', 'COCO_val2014_000000377080.jpg', 'COCO_val2014_000000038179.jpg', 'COCO_val2014_000000038179.jpg', 'COCO_val2014_000000038179.jpg', 'COCO_val2014_000000038179.jpg', 'COCO_val2014_000000038179.jpg', 'COCO_val2014_000000244160.jpg', 'COCO_val2014_000000244160.jpg', 'COCO_val2014_000000244160.jpg', 'COCO_val2014_000000244160.jpg', 'COCO_val2014_000000244160.jpg', 'COCO_val2014_000000493932.jpg', 'COCO_val2014_000000493932.jpg', 'COCO_val2014_000000493932.jpg', 'COCO_val2014_000000493932.jpg', 'COCO_val2014_000000493932.jpg', 'COCO_val2014_000000122839.jpg', 'COCO_val2014_000000122839.jpg', 'COCO_val2014_000000122839.jpg', 'COCO_val2014_000000122839.jpg', 'COCO_val2014_000000122839.jpg', 'COCO_val2014_000000344741.jpg', 'COCO_val2014_000000344741.jpg', 'COCO_val2014_000000344741.jpg', 'COCO_val2014_000000344741.jpg', 'COCO_val2014_000000344741.jpg', 'COCO_val2014_000000482080.jpg', 'COCO_val2014_000000482080.jpg', 'COCO_val2014_000000482080.jpg', 'COCO_val2014_000000482080.jpg', 'COCO_val2014_000000482080.jpg', 'COCO_val2014_000000206433.jpg', 'COCO_val2014_000000206433.jpg', 'COCO_val2014_000000206433.jpg', 'COCO_val2014_000000206433.jpg', 'COCO_val2014_000000206433.jpg', 'COCO_val2014_000000342273.jpg', 'COCO_val2014_000000342273.jpg', 'COCO_val2014_000000342273.jpg', 'COCO_val2014_000000342273.jpg', 'COCO_val2014_000000342273.jpg', 'COCO_val2014_000000125051.jpg', 'COCO_val2014_000000125051.jpg', 'COCO_val2014_000000125051.jpg', 'COCO_val2014_000000125051.jpg', 'COCO_val2014_000000125051.jpg', 'COCO_val2014_000000123410.jpg', 'COCO_val2014_000000123410.jpg', 'COCO_val2014_000000123410.jpg', 'COCO_val2014_000000123410.jpg', 'COCO_val2014_000000123410.jpg', 'COCO_val2014_000000159979.jpg', 'COCO_val2014_000000159979.jpg', 'COCO_val2014_000000159979.jpg', 'COCO_val2014_000000159979.jpg', 'COCO_val2014_000000159979.jpg', 'COCO_val2014_000000258085.jpg', 'COCO_val2014_000000258085.jpg', 'COCO_val2014_000000258085.jpg', 'COCO_val2014_000000258085.jpg', 'COCO_val2014_000000258085.jpg', 'COCO_val2014_000000301993.jpg', 'COCO_val2014_000000301993.jpg', 'COCO_val2014_000000301993.jpg', 'COCO_val2014_000000301993.jpg', 'COCO_val2014_000000301993.jpg', 'COCO_val2014_000000289967.jpg', 'COCO_val2014_000000289967.jpg', 'COCO_val2014_000000289967.jpg', 'COCO_val2014_000000289967.jpg', 'COCO_val2014_000000289967.jpg', 'COCO_val2014_000000511159.jpg', 'COCO_val2014_000000511159.jpg', 'COCO_val2014_000000511159.jpg', 'COCO_val2014_000000511159.jpg', 'COCO_val2014_000000511159.jpg', 'COCO_val2014_000000082263.jpg', 'COCO_val2014_000000082263.jpg', 'COCO_val2014_000000082263.jpg', 'COCO_val2014_000000082263.jpg', 'COCO_val2014_000000082263.jpg', 'COCO_val2014_000000267411.jpg', 'COCO_val2014_000000267411.jpg', 'COCO_val2014_000000267411.jpg', 'COCO_val2014_000000267411.jpg', 'COCO_val2014_000000267411.jpg', 'COCO_val2014_000000421457.jpg', 'COCO_val2014_000000421457.jpg', 'COCO_val2014_000000421457.jpg', 'COCO_val2014_000000421457.jpg', 'COCO_val2014_000000421457.jpg', 'COCO_val2014_000000407960.jpg', 'COCO_val2014_000000407960.jpg', 'COCO_val2014_000000407960.jpg', 'COCO_val2014_000000407960.jpg', 'COCO_val2014_000000407960.jpg', 'COCO_val2014_000000229631.jpg', 'COCO_val2014_000000229631.jpg', 'COCO_val2014_000000229631.jpg', 'COCO_val2014_000000229631.jpg', 'COCO_val2014_000000229631.jpg', 'COCO_val2014_000000391642.jpg', 'COCO_val2014_000000391642.jpg', 'COCO_val2014_000000391642.jpg', 'COCO_val2014_000000391642.jpg', 'COCO_val2014_000000391642.jpg', 'COCO_val2014_000000342271.jpg', 'COCO_val2014_000000342271.jpg', 'COCO_val2014_000000342271.jpg', 'COCO_val2014_000000342271.jpg', 'COCO_val2014_000000342271.jpg', 'COCO_val2014_000000517946.jpg', 'COCO_val2014_000000517946.jpg', 'COCO_val2014_000000517946.jpg', 'COCO_val2014_000000517946.jpg', 'COCO_val2014_000000517946.jpg', 'COCO_val2014_000000219848.jpg', 'COCO_val2014_000000219848.jpg', 'COCO_val2014_000000219848.jpg', 'COCO_val2014_000000219848.jpg', 'COCO_val2014_000000219848.jpg', 'COCO_val2014_000000296014.jpg', 'COCO_val2014_000000296014.jpg', 'COCO_val2014_000000296014.jpg', 'COCO_val2014_000000296014.jpg', 'COCO_val2014_000000296014.jpg', 'COCO_val2014_000000135846.jpg', 'COCO_val2014_000000135846.jpg', 'COCO_val2014_000000135846.jpg', 'COCO_val2014_000000135846.jpg', 'COCO_val2014_000000135846.jpg', 'COCO_val2014_000000137362.jpg', 'COCO_val2014_000000137362.jpg', 'COCO_val2014_000000137362.jpg', 'COCO_val2014_000000137362.jpg', 'COCO_val2014_000000137362.jpg', 'COCO_val2014_000000139192.jpg', 'COCO_val2014_000000139192.jpg', 'COCO_val2014_000000139192.jpg', 'COCO_val2014_000000139192.jpg', 'COCO_val2014_000000139192.jpg', 'COCO_val2014_000000340305.jpg', 'COCO_val2014_000000340305.jpg', 'COCO_val2014_000000340305.jpg', 'COCO_val2014_000000340305.jpg', 'COCO_val2014_000000340305.jpg', 'COCO_val2014_000000372227.jpg', 'COCO_val2014_000000372227.jpg', 'COCO_val2014_000000372227.jpg', 'COCO_val2014_000000372227.jpg', 'COCO_val2014_000000372227.jpg', 'COCO_val2014_000000359546.jpg', 'COCO_val2014_000000359546.jpg', 'COCO_val2014_000000359546.jpg', 'COCO_val2014_000000359546.jpg', 'COCO_val2014_000000359546.jpg', 'COCO_val2014_000000288860.jpg', 'COCO_val2014_000000288860.jpg', 'COCO_val2014_000000288860.jpg', 'COCO_val2014_000000288860.jpg', 'COCO_val2014_000000288860.jpg', 'COCO_val2014_000000027662.jpg', 'COCO_val2014_000000027662.jpg', 'COCO_val2014_000000027662.jpg', 'COCO_val2014_000000027662.jpg', 'COCO_val2014_000000027662.jpg', 'COCO_val2014_000000198079.jpg', 'COCO_val2014_000000198079.jpg', 'COCO_val2014_000000198079.jpg', 'COCO_val2014_000000198079.jpg', 'COCO_val2014_000000198079.jpg', 'COCO_val2014_000000440940.jpg', 'COCO_val2014_000000440940.jpg', 'COCO_val2014_000000440940.jpg', 'COCO_val2014_000000440940.jpg', 'COCO_val2014_000000440940.jpg', 'COCO_val2014_000000084270.jpg', 'COCO_val2014_000000084270.jpg', 'COCO_val2014_000000084270.jpg', 'COCO_val2014_000000084270.jpg', 'COCO_val2014_000000084270.jpg', 'COCO_val2014_000000122994.jpg', 'COCO_val2014_000000122994.jpg', 'COCO_val2014_000000122994.jpg', 'COCO_val2014_000000122994.jpg', 'COCO_val2014_000000122994.jpg', 'COCO_val2014_000000215755.jpg', 'COCO_val2014_000000215755.jpg', 'COCO_val2014_000000215755.jpg', 'COCO_val2014_000000215755.jpg', 'COCO_val2014_000000215755.jpg', 'COCO_val2014_000000417846.jpg', 'COCO_val2014_000000417846.jpg', 'COCO_val2014_000000417846.jpg', 'COCO_val2014_000000417846.jpg', 'COCO_val2014_000000417846.jpg', 'COCO_val2014_000000267191.jpg', 'COCO_val2014_000000267191.jpg', 'COCO_val2014_000000267191.jpg', 'COCO_val2014_000000267191.jpg', 'COCO_val2014_000000267191.jpg', 'COCO_val2014_000000343401.jpg', 'COCO_val2014_000000343401.jpg', 'COCO_val2014_000000343401.jpg', 'COCO_val2014_000000343401.jpg', 'COCO_val2014_000000343401.jpg', 'COCO_val2014_000000032151.jpg', 'COCO_val2014_000000032151.jpg', 'COCO_val2014_000000032151.jpg', 'COCO_val2014_000000032151.jpg', 'COCO_val2014_000000032151.jpg', 'COCO_val2014_000000333114.jpg', 'COCO_val2014_000000333114.jpg', 'COCO_val2014_000000333114.jpg', 'COCO_val2014_000000333114.jpg', 'COCO_val2014_000000333114.jpg', 'COCO_val2014_000000195914.jpg', 'COCO_val2014_000000195914.jpg', 'COCO_val2014_000000195914.jpg', 'COCO_val2014_000000195914.jpg', 'COCO_val2014_000000195914.jpg', 'COCO_val2014_000000497960.jpg', 'COCO_val2014_000000497960.jpg', 'COCO_val2014_000000497960.jpg', 'COCO_val2014_000000497960.jpg', 'COCO_val2014_000000497960.jpg', 'COCO_val2014_000000183166.jpg', 'COCO_val2014_000000183166.jpg', 'COCO_val2014_000000183166.jpg', 'COCO_val2014_000000183166.jpg', 'COCO_val2014_000000183166.jpg', 'COCO_val2014_000000179199.jpg', 'COCO_val2014_000000179199.jpg', 'COCO_val2014_000000179199.jpg', 'COCO_val2014_000000179199.jpg', 'COCO_val2014_000000179199.jpg', 'COCO_val2014_000000422836.jpg', 'COCO_val2014_000000422836.jpg', 'COCO_val2014_000000422836.jpg', 'COCO_val2014_000000422836.jpg', 'COCO_val2014_000000422836.jpg', 'COCO_val2014_000000280709.jpg', 'COCO_val2014_000000280709.jpg', 'COCO_val2014_000000280709.jpg', 'COCO_val2014_000000280709.jpg', 'COCO_val2014_000000280709.jpg', 'COCO_val2014_000000036361.jpg', 'COCO_val2014_000000036361.jpg', 'COCO_val2014_000000036361.jpg', 'COCO_val2014_000000036361.jpg', 'COCO_val2014_000000036361.jpg', 'COCO_val2014_000000496252.jpg', 'COCO_val2014_000000496252.jpg', 'COCO_val2014_000000496252.jpg', 'COCO_val2014_000000496252.jpg', 'COCO_val2014_000000496252.jpg', 'COCO_val2014_000000022599.jpg', 'COCO_val2014_000000022599.jpg', 'COCO_val2014_000000022599.jpg', 'COCO_val2014_000000022599.jpg', 'COCO_val2014_000000022599.jpg', 'COCO_val2014_000000493613.jpg', 'COCO_val2014_000000493613.jpg', 'COCO_val2014_000000493613.jpg', 'COCO_val2014_000000493613.jpg', 'COCO_val2014_000000493613.jpg', 'COCO_val2014_000000210654.jpg', 'COCO_val2014_000000210654.jpg', 'COCO_val2014_000000210654.jpg', 'COCO_val2014_000000210654.jpg', 'COCO_val2014_000000210654.jpg', 'COCO_val2014_000000104137.jpg', 'COCO_val2014_000000104137.jpg', 'COCO_val2014_000000104137.jpg', 'COCO_val2014_000000104137.jpg', 'COCO_val2014_000000104137.jpg', 'COCO_val2014_000000448236.jpg', 'COCO_val2014_000000448236.jpg', 'COCO_val2014_000000448236.jpg', 'COCO_val2014_000000448236.jpg', 'COCO_val2014_000000448236.jpg', 'COCO_val2014_000000115721.jpg', 'COCO_val2014_000000115721.jpg', 'COCO_val2014_000000115721.jpg', 'COCO_val2014_000000115721.jpg', 'COCO_val2014_000000115721.jpg', 'COCO_val2014_000000155540.jpg', 'COCO_val2014_000000155540.jpg', 'COCO_val2014_000000155540.jpg', 'COCO_val2014_000000155540.jpg', 'COCO_val2014_000000155540.jpg', 'COCO_val2014_000000210958.jpg', 'COCO_val2014_000000210958.jpg', 'COCO_val2014_000000210958.jpg', 'COCO_val2014_000000210958.jpg', 'COCO_val2014_000000210958.jpg', 'COCO_val2014_000000543836.jpg', 'COCO_val2014_000000543836.jpg', 'COCO_val2014_000000543836.jpg', 'COCO_val2014_000000543836.jpg', 'COCO_val2014_000000543836.jpg', 'COCO_val2014_000000410781.jpg', 'COCO_val2014_000000410781.jpg', 'COCO_val2014_000000410781.jpg', 'COCO_val2014_000000410781.jpg', 'COCO_val2014_000000410781.jpg', 'COCO_val2014_000000562370.jpg', 'COCO_val2014_000000562370.jpg', 'COCO_val2014_000000562370.jpg', 'COCO_val2014_000000562370.jpg', 'COCO_val2014_000000562370.jpg', 'COCO_val2014_000000317024.jpg', 'COCO_val2014_000000317024.jpg', 'COCO_val2014_000000317024.jpg', 'COCO_val2014_000000317024.jpg', 'COCO_val2014_000000317024.jpg', 'COCO_val2014_000000098328.jpg', 'COCO_val2014_000000098328.jpg', 'COCO_val2014_000000098328.jpg', 'COCO_val2014_000000098328.jpg', 'COCO_val2014_000000098328.jpg', 'COCO_val2014_000000314396.jpg', 'COCO_val2014_000000314396.jpg', 'COCO_val2014_000000314396.jpg', 'COCO_val2014_000000314396.jpg', 'COCO_val2014_000000314396.jpg', 'COCO_val2014_000000053893.jpg', 'COCO_val2014_000000053893.jpg', 'COCO_val2014_000000053893.jpg', 'COCO_val2014_000000053893.jpg', 'COCO_val2014_000000053893.jpg', 'COCO_val2014_000000463522.jpg', 'COCO_val2014_000000463522.jpg', 'COCO_val2014_000000463522.jpg', 'COCO_val2014_000000463522.jpg', 'COCO_val2014_000000463522.jpg', 'COCO_val2014_000000453321.jpg', 'COCO_val2014_000000453321.jpg', 'COCO_val2014_000000453321.jpg', 'COCO_val2014_000000453321.jpg', 'COCO_val2014_000000453321.jpg', 'COCO_val2014_000000213547.jpg', 'COCO_val2014_000000213547.jpg', 'COCO_val2014_000000213547.jpg', 'COCO_val2014_000000213547.jpg', 'COCO_val2014_000000213547.jpg', 'COCO_val2014_000000428786.jpg', 'COCO_val2014_000000428786.jpg', 'COCO_val2014_000000428786.jpg', 'COCO_val2014_000000428786.jpg', 'COCO_val2014_000000428786.jpg', 'COCO_val2014_000000241868.jpg', 'COCO_val2014_000000241868.jpg', 'COCO_val2014_000000241868.jpg', 'COCO_val2014_000000241868.jpg', 'COCO_val2014_000000241868.jpg', 'COCO_val2014_000000523580.jpg', 'COCO_val2014_000000523580.jpg', 'COCO_val2014_000000523580.jpg', 'COCO_val2014_000000523580.jpg', 'COCO_val2014_000000523580.jpg', 'COCO_val2014_000000335610.jpg', 'COCO_val2014_000000335610.jpg', 'COCO_val2014_000000335610.jpg', 'COCO_val2014_000000335610.jpg', 'COCO_val2014_000000335610.jpg', 'COCO_val2014_000000577219.jpg', 'COCO_val2014_000000577219.jpg', 'COCO_val2014_000000577219.jpg', 'COCO_val2014_000000577219.jpg', 'COCO_val2014_000000577219.jpg', 'COCO_val2014_000000456015.jpg', 'COCO_val2014_000000456015.jpg', 'COCO_val2014_000000456015.jpg', 'COCO_val2014_000000456015.jpg', 'COCO_val2014_000000456015.jpg', 'COCO_val2014_000000396754.jpg', 'COCO_val2014_000000396754.jpg', 'COCO_val2014_000000396754.jpg', 'COCO_val2014_000000396754.jpg', 'COCO_val2014_000000396754.jpg', 'COCO_val2014_000000547886.jpg', 'COCO_val2014_000000547886.jpg', 'COCO_val2014_000000547886.jpg', 'COCO_val2014_000000547886.jpg', 'COCO_val2014_000000547886.jpg', 'COCO_val2014_000000124975.jpg', 'COCO_val2014_000000124975.jpg', 'COCO_val2014_000000124975.jpg', 'COCO_val2014_000000124975.jpg', 'COCO_val2014_000000124975.jpg', 'COCO_val2014_000000378453.jpg', 'COCO_val2014_000000378453.jpg', 'COCO_val2014_000000378453.jpg', 'COCO_val2014_000000378453.jpg', 'COCO_val2014_000000378453.jpg', 'COCO_val2014_000000487239.jpg', 'COCO_val2014_000000487239.jpg', 'COCO_val2014_000000487239.jpg', 'COCO_val2014_000000487239.jpg', 'COCO_val2014_000000487239.jpg', 'COCO_val2014_000000185366.jpg', 'COCO_val2014_000000185366.jpg', 'COCO_val2014_000000185366.jpg', 'COCO_val2014_000000185366.jpg', 'COCO_val2014_000000185366.jpg', 'COCO_val2014_000000259814.jpg', 'COCO_val2014_000000259814.jpg', 'COCO_val2014_000000259814.jpg', 'COCO_val2014_000000259814.jpg', 'COCO_val2014_000000259814.jpg', 'COCO_val2014_000000523274.jpg', 'COCO_val2014_000000523274.jpg', 'COCO_val2014_000000523274.jpg', 'COCO_val2014_000000523274.jpg', 'COCO_val2014_000000523274.jpg', 'COCO_val2014_000000412916.jpg', 'COCO_val2014_000000412916.jpg', 'COCO_val2014_000000412916.jpg', 'COCO_val2014_000000412916.jpg', 'COCO_val2014_000000412916.jpg', 'COCO_val2014_000000274708.jpg', 'COCO_val2014_000000274708.jpg', 'COCO_val2014_000000274708.jpg', 'COCO_val2014_000000274708.jpg', 'COCO_val2014_000000274708.jpg', 'COCO_val2014_000000478212.jpg', 'COCO_val2014_000000478212.jpg', 'COCO_val2014_000000478212.jpg', 'COCO_val2014_000000478212.jpg', 'COCO_val2014_000000478212.jpg', 'COCO_val2014_000000419350.jpg', 'COCO_val2014_000000419350.jpg', 'COCO_val2014_000000419350.jpg', 'COCO_val2014_000000419350.jpg', 'COCO_val2014_000000419350.jpg', 'COCO_val2014_000000138054.jpg', 'COCO_val2014_000000138054.jpg', 'COCO_val2014_000000138054.jpg', 'COCO_val2014_000000138054.jpg', 'COCO_val2014_000000138054.jpg', 'COCO_val2014_000000377113.jpg', 'COCO_val2014_000000377113.jpg', 'COCO_val2014_000000377113.jpg', 'COCO_val2014_000000377113.jpg', 'COCO_val2014_000000377113.jpg', 'COCO_val2014_000000071682.jpg', 'COCO_val2014_000000071682.jpg', 'COCO_val2014_000000071682.jpg', 'COCO_val2014_000000071682.jpg', 'COCO_val2014_000000071682.jpg', 'COCO_val2014_000000009395.jpg', 'COCO_val2014_000000009395.jpg', 'COCO_val2014_000000009395.jpg', 'COCO_val2014_000000009395.jpg', 'COCO_val2014_000000009395.jpg', 'COCO_val2014_000000462639.jpg', 'COCO_val2014_000000462639.jpg', 'COCO_val2014_000000462639.jpg', 'COCO_val2014_000000462639.jpg', 'COCO_val2014_000000462639.jpg', 'COCO_val2014_000000537297.jpg', 'COCO_val2014_000000537297.jpg', 'COCO_val2014_000000537297.jpg', 'COCO_val2014_000000537297.jpg', 'COCO_val2014_000000537297.jpg', 'COCO_val2014_000000409291.jpg', 'COCO_val2014_000000409291.jpg', 'COCO_val2014_000000409291.jpg', 'COCO_val2014_000000409291.jpg', 'COCO_val2014_000000409291.jpg', 'COCO_val2014_000000079651.jpg', 'COCO_val2014_000000079651.jpg', 'COCO_val2014_000000079651.jpg', 'COCO_val2014_000000079651.jpg', 'COCO_val2014_000000079651.jpg', 'COCO_val2014_000000334034.jpg', 'COCO_val2014_000000334034.jpg', 'COCO_val2014_000000334034.jpg', 'COCO_val2014_000000334034.jpg', 'COCO_val2014_000000334034.jpg', 'COCO_val2014_000000397729.jpg', 'COCO_val2014_000000397729.jpg', 'COCO_val2014_000000397729.jpg', 'COCO_val2014_000000397729.jpg', 'COCO_val2014_000000397729.jpg', 'COCO_val2014_000000466840.jpg', 'COCO_val2014_000000466840.jpg', 'COCO_val2014_000000466840.jpg', 'COCO_val2014_000000466840.jpg', 'COCO_val2014_000000466840.jpg', 'COCO_val2014_000000188534.jpg', 'COCO_val2014_000000188534.jpg', 'COCO_val2014_000000188534.jpg', 'COCO_val2014_000000188534.jpg', 'COCO_val2014_000000188534.jpg', 'COCO_val2014_000000104669.jpg', 'COCO_val2014_000000104669.jpg', 'COCO_val2014_000000104669.jpg', 'COCO_val2014_000000104669.jpg', 'COCO_val2014_000000104669.jpg', 'COCO_val2014_000000318754.jpg', 'COCO_val2014_000000318754.jpg', 'COCO_val2014_000000318754.jpg', 'COCO_val2014_000000318754.jpg', 'COCO_val2014_000000318754.jpg', 'COCO_val2014_000000456236.jpg', 'COCO_val2014_000000456236.jpg', 'COCO_val2014_000000456236.jpg', 'COCO_val2014_000000456236.jpg', 'COCO_val2014_000000456236.jpg', 'COCO_val2014_000000086877.jpg', 'COCO_val2014_000000086877.jpg', 'COCO_val2014_000000086877.jpg', 'COCO_val2014_000000086877.jpg', 'COCO_val2014_000000086877.jpg', 'COCO_val2014_000000383762.jpg', 'COCO_val2014_000000383762.jpg', 'COCO_val2014_000000383762.jpg', 'COCO_val2014_000000383762.jpg', 'COCO_val2014_000000383762.jpg', 'COCO_val2014_000000542933.jpg', 'COCO_val2014_000000542933.jpg', 'COCO_val2014_000000542933.jpg', 'COCO_val2014_000000542933.jpg', 'COCO_val2014_000000542933.jpg', 'COCO_val2014_000000106736.jpg', 'COCO_val2014_000000106736.jpg', 'COCO_val2014_000000106736.jpg', 'COCO_val2014_000000106736.jpg', 'COCO_val2014_000000106736.jpg', 'COCO_val2014_000000430377.jpg', 'COCO_val2014_000000430377.jpg', 'COCO_val2014_000000430377.jpg', 'COCO_val2014_000000430377.jpg', 'COCO_val2014_000000430377.jpg', 'COCO_val2014_000000456725.jpg', 'COCO_val2014_000000456725.jpg', 'COCO_val2014_000000456725.jpg', 'COCO_val2014_000000456725.jpg', 'COCO_val2014_000000456725.jpg', 'COCO_val2014_000000473215.jpg', 'COCO_val2014_000000473215.jpg', 'COCO_val2014_000000473215.jpg', 'COCO_val2014_000000473215.jpg', 'COCO_val2014_000000473215.jpg', 'COCO_val2014_000000344875.jpg', 'COCO_val2014_000000344875.jpg', 'COCO_val2014_000000344875.jpg', 'COCO_val2014_000000344875.jpg', 'COCO_val2014_000000344875.jpg', 'COCO_val2014_000000086001.jpg', 'COCO_val2014_000000086001.jpg', 'COCO_val2014_000000086001.jpg', 'COCO_val2014_000000086001.jpg', 'COCO_val2014_000000086001.jpg', 'COCO_val2014_000000265472.jpg', 'COCO_val2014_000000265472.jpg', 'COCO_val2014_000000265472.jpg', 'COCO_val2014_000000265472.jpg', 'COCO_val2014_000000265472.jpg', 'COCO_val2014_000000140151.jpg', 'COCO_val2014_000000140151.jpg', 'COCO_val2014_000000140151.jpg', 'COCO_val2014_000000140151.jpg', 'COCO_val2014_000000140151.jpg', 'COCO_val2014_000000045920.jpg', 'COCO_val2014_000000045920.jpg', 'COCO_val2014_000000045920.jpg', 'COCO_val2014_000000045920.jpg', 'COCO_val2014_000000045920.jpg', 'COCO_val2014_000000352533.jpg', 'COCO_val2014_000000352533.jpg', 'COCO_val2014_000000352533.jpg', 'COCO_val2014_000000352533.jpg', 'COCO_val2014_000000352533.jpg', 'COCO_val2014_000000196212.jpg', 'COCO_val2014_000000196212.jpg', 'COCO_val2014_000000196212.jpg', 'COCO_val2014_000000196212.jpg', 'COCO_val2014_000000196212.jpg', 'COCO_val2014_000000559483.jpg', 'COCO_val2014_000000559483.jpg', 'COCO_val2014_000000559483.jpg', 'COCO_val2014_000000559483.jpg', 'COCO_val2014_000000559483.jpg', 'COCO_val2014_000000563153.jpg', 'COCO_val2014_000000563153.jpg', 'COCO_val2014_000000563153.jpg', 'COCO_val2014_000000563153.jpg', 'COCO_val2014_000000563153.jpg', 'COCO_val2014_000000507536.jpg', 'COCO_val2014_000000507536.jpg', 'COCO_val2014_000000507536.jpg', 'COCO_val2014_000000507536.jpg', 'COCO_val2014_000000507536.jpg', 'COCO_val2014_000000038252.jpg', 'COCO_val2014_000000038252.jpg', 'COCO_val2014_000000038252.jpg', 'COCO_val2014_000000038252.jpg', 'COCO_val2014_000000038252.jpg', 'COCO_val2014_000000095155.jpg', 'COCO_val2014_000000095155.jpg', 'COCO_val2014_000000095155.jpg', 'COCO_val2014_000000095155.jpg', 'COCO_val2014_000000095155.jpg', 'COCO_val2014_000000376246.jpg', 'COCO_val2014_000000376246.jpg', 'COCO_val2014_000000376246.jpg', 'COCO_val2014_000000376246.jpg', 'COCO_val2014_000000376246.jpg', 'COCO_val2014_000000312772.jpg', 'COCO_val2014_000000312772.jpg', 'COCO_val2014_000000312772.jpg', 'COCO_val2014_000000312772.jpg', 'COCO_val2014_000000312772.jpg', 'COCO_val2014_000000262609.jpg', 'COCO_val2014_000000262609.jpg', 'COCO_val2014_000000262609.jpg', 'COCO_val2014_000000262609.jpg', 'COCO_val2014_000000262609.jpg', 'COCO_val2014_000000110769.jpg', 'COCO_val2014_000000110769.jpg', 'COCO_val2014_000000110769.jpg', 'COCO_val2014_000000110769.jpg', 'COCO_val2014_000000110769.jpg', 'COCO_val2014_000000066190.jpg', 'COCO_val2014_000000066190.jpg', 'COCO_val2014_000000066190.jpg', 'COCO_val2014_000000066190.jpg', 'COCO_val2014_000000066190.jpg', 'COCO_val2014_000000227772.jpg', 'COCO_val2014_000000227772.jpg', 'COCO_val2014_000000227772.jpg', 'COCO_val2014_000000227772.jpg', 'COCO_val2014_000000227772.jpg', 'COCO_val2014_000000177194.jpg', 'COCO_val2014_000000177194.jpg', 'COCO_val2014_000000177194.jpg', 'COCO_val2014_000000177194.jpg', 'COCO_val2014_000000177194.jpg', 'COCO_val2014_000000184978.jpg', 'COCO_val2014_000000184978.jpg', 'COCO_val2014_000000184978.jpg', 'COCO_val2014_000000184978.jpg', 'COCO_val2014_000000184978.jpg', 'COCO_val2014_000000370399.jpg', 'COCO_val2014_000000370399.jpg', 'COCO_val2014_000000370399.jpg', 'COCO_val2014_000000370399.jpg', 'COCO_val2014_000000370399.jpg', 'COCO_val2014_000000199055.jpg', 'COCO_val2014_000000199055.jpg', 'COCO_val2014_000000199055.jpg', 'COCO_val2014_000000199055.jpg', 'COCO_val2014_000000199055.jpg', 'COCO_val2014_000000010785.jpg', 'COCO_val2014_000000010785.jpg', 'COCO_val2014_000000010785.jpg', 'COCO_val2014_000000010785.jpg', 'COCO_val2014_000000010785.jpg', 'COCO_val2014_000000377359.jpg', 'COCO_val2014_000000377359.jpg', 'COCO_val2014_000000377359.jpg', 'COCO_val2014_000000377359.jpg', 'COCO_val2014_000000377359.jpg', 'COCO_val2014_000000017755.jpg', 'COCO_val2014_000000017755.jpg', 'COCO_val2014_000000017755.jpg', 'COCO_val2014_000000017755.jpg', 'COCO_val2014_000000017755.jpg', 'COCO_val2014_000000297260.jpg', 'COCO_val2014_000000297260.jpg', 'COCO_val2014_000000297260.jpg', 'COCO_val2014_000000297260.jpg', 'COCO_val2014_000000297260.jpg', 'COCO_val2014_000000431848.jpg', 'COCO_val2014_000000431848.jpg', 'COCO_val2014_000000431848.jpg', 'COCO_val2014_000000431848.jpg', 'COCO_val2014_000000431848.jpg', 'COCO_val2014_000000241880.jpg', 'COCO_val2014_000000241880.jpg', 'COCO_val2014_000000241880.jpg', 'COCO_val2014_000000241880.jpg', 'COCO_val2014_000000241880.jpg', 'COCO_val2014_000000206049.jpg', 'COCO_val2014_000000206049.jpg', 'COCO_val2014_000000206049.jpg', 'COCO_val2014_000000206049.jpg', 'COCO_val2014_000000206049.jpg', 'COCO_val2014_000000391285.jpg', 'COCO_val2014_000000391285.jpg', 'COCO_val2014_000000391285.jpg', 'COCO_val2014_000000391285.jpg', 'COCO_val2014_000000391285.jpg', 'COCO_val2014_000000496090.jpg', 'COCO_val2014_000000496090.jpg', 'COCO_val2014_000000496090.jpg', 'COCO_val2014_000000496090.jpg', 'COCO_val2014_000000496090.jpg', 'COCO_val2014_000000490701.jpg', 'COCO_val2014_000000490701.jpg', 'COCO_val2014_000000490701.jpg', 'COCO_val2014_000000490701.jpg', 'COCO_val2014_000000490701.jpg', 'COCO_val2014_000000190689.jpg', 'COCO_val2014_000000190689.jpg', 'COCO_val2014_000000190689.jpg', 'COCO_val2014_000000190689.jpg', 'COCO_val2014_000000190689.jpg', 'COCO_val2014_000000240817.jpg', 'COCO_val2014_000000240817.jpg', 'COCO_val2014_000000240817.jpg', 'COCO_val2014_000000240817.jpg', 'COCO_val2014_000000240817.jpg', 'COCO_val2014_000000098599.jpg', 'COCO_val2014_000000098599.jpg', 'COCO_val2014_000000098599.jpg', 'COCO_val2014_000000098599.jpg', 'COCO_val2014_000000098599.jpg', 'COCO_val2014_000000064974.jpg', 'COCO_val2014_000000064974.jpg', 'COCO_val2014_000000064974.jpg', 'COCO_val2014_000000064974.jpg', 'COCO_val2014_000000064974.jpg', 'COCO_val2014_000000357418.jpg', 'COCO_val2014_000000357418.jpg', 'COCO_val2014_000000357418.jpg', 'COCO_val2014_000000357418.jpg', 'COCO_val2014_000000357418.jpg', 'COCO_val2014_000000365663.jpg', 'COCO_val2014_000000365663.jpg', 'COCO_val2014_000000365663.jpg', 'COCO_val2014_000000365663.jpg', 'COCO_val2014_000000365663.jpg', 'COCO_val2014_000000128699.jpg', 'COCO_val2014_000000128699.jpg', 'COCO_val2014_000000128699.jpg', 'COCO_val2014_000000128699.jpg', 'COCO_val2014_000000128699.jpg', 'COCO_val2014_000000121591.jpg', 'COCO_val2014_000000121591.jpg', 'COCO_val2014_000000121591.jpg', 'COCO_val2014_000000121591.jpg', 'COCO_val2014_000000121591.jpg', 'COCO_val2014_000000462324.jpg', 'COCO_val2014_000000462324.jpg', 'COCO_val2014_000000462324.jpg', 'COCO_val2014_000000462324.jpg', 'COCO_val2014_000000462324.jpg', 'COCO_val2014_000000083682.jpg', 'COCO_val2014_000000083682.jpg', 'COCO_val2014_000000083682.jpg', 'COCO_val2014_000000083682.jpg', 'COCO_val2014_000000083682.jpg', 'COCO_val2014_000000213881.jpg', 'COCO_val2014_000000213881.jpg', 'COCO_val2014_000000213881.jpg', 'COCO_val2014_000000213881.jpg', 'COCO_val2014_000000213881.jpg', 'COCO_val2014_000000513292.jpg', 'COCO_val2014_000000513292.jpg', 'COCO_val2014_000000513292.jpg', 'COCO_val2014_000000513292.jpg', 'COCO_val2014_000000513292.jpg', 'COCO_val2014_000000394079.jpg', 'COCO_val2014_000000394079.jpg', 'COCO_val2014_000000394079.jpg', 'COCO_val2014_000000394079.jpg', 'COCO_val2014_000000394079.jpg', 'COCO_val2014_000000011537.jpg', 'COCO_val2014_000000011537.jpg', 'COCO_val2014_000000011537.jpg', 'COCO_val2014_000000011537.jpg', 'COCO_val2014_000000011537.jpg', 'COCO_val2014_000000215565.jpg', 'COCO_val2014_000000215565.jpg', 'COCO_val2014_000000215565.jpg', 'COCO_val2014_000000215565.jpg', 'COCO_val2014_000000215565.jpg', 'COCO_val2014_000000274240.jpg', 'COCO_val2014_000000274240.jpg', 'COCO_val2014_000000274240.jpg', 'COCO_val2014_000000274240.jpg', 'COCO_val2014_000000274240.jpg', 'COCO_val2014_000000238065.jpg', 'COCO_val2014_000000238065.jpg', 'COCO_val2014_000000238065.jpg', 'COCO_val2014_000000238065.jpg', 'COCO_val2014_000000238065.jpg', 'COCO_val2014_000000010023.jpg', 'COCO_val2014_000000010023.jpg', 'COCO_val2014_000000010023.jpg', 'COCO_val2014_000000010023.jpg', 'COCO_val2014_000000010023.jpg', 'COCO_val2014_000000091545.jpg', 'COCO_val2014_000000091545.jpg', 'COCO_val2014_000000091545.jpg', 'COCO_val2014_000000091545.jpg', 'COCO_val2014_000000091545.jpg', 'COCO_val2014_000000015826.jpg', 'COCO_val2014_000000015826.jpg', 'COCO_val2014_000000015826.jpg', 'COCO_val2014_000000015826.jpg', 'COCO_val2014_000000015826.jpg', 'COCO_val2014_000000454457.jpg', 'COCO_val2014_000000454457.jpg', 'COCO_val2014_000000454457.jpg', 'COCO_val2014_000000454457.jpg', 'COCO_val2014_000000454457.jpg', 'COCO_val2014_000000202444.jpg', 'COCO_val2014_000000202444.jpg', 'COCO_val2014_000000202444.jpg', 'COCO_val2014_000000202444.jpg', 'COCO_val2014_000000202444.jpg', 'COCO_val2014_000000519460.jpg', 'COCO_val2014_000000519460.jpg', 'COCO_val2014_000000519460.jpg', 'COCO_val2014_000000519460.jpg', 'COCO_val2014_000000519460.jpg', 'COCO_val2014_000000271215.jpg', 'COCO_val2014_000000271215.jpg', 'COCO_val2014_000000271215.jpg', 'COCO_val2014_000000271215.jpg', 'COCO_val2014_000000271215.jpg', 'COCO_val2014_000000329318.jpg', 'COCO_val2014_000000329318.jpg', 'COCO_val2014_000000329318.jpg', 'COCO_val2014_000000329318.jpg', 'COCO_val2014_000000329318.jpg', 'COCO_val2014_000000540614.jpg', 'COCO_val2014_000000540614.jpg', 'COCO_val2014_000000540614.jpg', 'COCO_val2014_000000540614.jpg', 'COCO_val2014_000000540614.jpg', 'COCO_val2014_000000424521.jpg', 'COCO_val2014_000000424521.jpg', 'COCO_val2014_000000424521.jpg', 'COCO_val2014_000000424521.jpg', 'COCO_val2014_000000424521.jpg', 'COCO_val2014_000000259087.jpg', 'COCO_val2014_000000259087.jpg', 'COCO_val2014_000000259087.jpg', 'COCO_val2014_000000259087.jpg', 'COCO_val2014_000000259087.jpg', 'COCO_val2014_000000085045.jpg', 'COCO_val2014_000000085045.jpg', 'COCO_val2014_000000085045.jpg', 'COCO_val2014_000000085045.jpg', 'COCO_val2014_000000085045.jpg', 'COCO_val2014_000000249453.jpg', 'COCO_val2014_000000249453.jpg', 'COCO_val2014_000000249453.jpg', 'COCO_val2014_000000249453.jpg', 'COCO_val2014_000000249453.jpg', 'COCO_val2014_000000566105.jpg', 'COCO_val2014_000000566105.jpg', 'COCO_val2014_000000566105.jpg', 'COCO_val2014_000000566105.jpg', 'COCO_val2014_000000566105.jpg', 'COCO_val2014_000000276841.jpg', 'COCO_val2014_000000276841.jpg', 'COCO_val2014_000000276841.jpg', 'COCO_val2014_000000276841.jpg', 'COCO_val2014_000000276841.jpg', 'COCO_val2014_000000444386.jpg', 'COCO_val2014_000000444386.jpg', 'COCO_val2014_000000444386.jpg', 'COCO_val2014_000000444386.jpg', 'COCO_val2014_000000444386.jpg', 'COCO_val2014_000000567340.jpg', 'COCO_val2014_000000567340.jpg', 'COCO_val2014_000000567340.jpg', 'COCO_val2014_000000567340.jpg', 'COCO_val2014_000000567340.jpg', 'COCO_val2014_000000390704.jpg', 'COCO_val2014_000000390704.jpg', 'COCO_val2014_000000390704.jpg', 'COCO_val2014_000000390704.jpg', 'COCO_val2014_000000390704.jpg', 'COCO_val2014_000000198464.jpg', 'COCO_val2014_000000198464.jpg', 'COCO_val2014_000000198464.jpg', 'COCO_val2014_000000198464.jpg', 'COCO_val2014_000000198464.jpg', 'COCO_val2014_000000254016.jpg', 'COCO_val2014_000000254016.jpg', 'COCO_val2014_000000254016.jpg', 'COCO_val2014_000000254016.jpg', 'COCO_val2014_000000254016.jpg', 'COCO_val2014_000000523807.jpg', 'COCO_val2014_000000523807.jpg', 'COCO_val2014_000000523807.jpg', 'COCO_val2014_000000523807.jpg', 'COCO_val2014_000000523807.jpg', 'COCO_val2014_000000296544.jpg', 'COCO_val2014_000000296544.jpg', 'COCO_val2014_000000296544.jpg', 'COCO_val2014_000000296544.jpg', 'COCO_val2014_000000296544.jpg', 'COCO_val2014_000000476722.jpg', 'COCO_val2014_000000476722.jpg', 'COCO_val2014_000000476722.jpg', 'COCO_val2014_000000476722.jpg', 'COCO_val2014_000000476722.jpg', 'COCO_val2014_000000395745.jpg', 'COCO_val2014_000000395745.jpg', 'COCO_val2014_000000395745.jpg', 'COCO_val2014_000000395745.jpg', 'COCO_val2014_000000395745.jpg', 'COCO_val2014_000000443602.jpg', 'COCO_val2014_000000443602.jpg', 'COCO_val2014_000000443602.jpg', 'COCO_val2014_000000443602.jpg', 'COCO_val2014_000000443602.jpg', 'COCO_val2014_000000357532.jpg', 'COCO_val2014_000000357532.jpg', 'COCO_val2014_000000357532.jpg', 'COCO_val2014_000000357532.jpg', 'COCO_val2014_000000357532.jpg', 'COCO_val2014_000000122413.jpg', 'COCO_val2014_000000122413.jpg', 'COCO_val2014_000000122413.jpg', 'COCO_val2014_000000122413.jpg', 'COCO_val2014_000000122413.jpg', 'COCO_val2014_000000330845.jpg', 'COCO_val2014_000000330845.jpg', 'COCO_val2014_000000330845.jpg', 'COCO_val2014_000000330845.jpg', 'COCO_val2014_000000330845.jpg', 'COCO_val2014_000000202201.jpg', 'COCO_val2014_000000202201.jpg', 'COCO_val2014_000000202201.jpg', 'COCO_val2014_000000202201.jpg', 'COCO_val2014_000000202201.jpg', 'COCO_val2014_000000375621.jpg', 'COCO_val2014_000000375621.jpg', 'COCO_val2014_000000375621.jpg', 'COCO_val2014_000000375621.jpg', 'COCO_val2014_000000375621.jpg', 'COCO_val2014_000000511407.jpg', 'COCO_val2014_000000511407.jpg', 'COCO_val2014_000000511407.jpg', 'COCO_val2014_000000511407.jpg', 'COCO_val2014_000000511407.jpg', 'COCO_val2014_000000073946.jpg', 'COCO_val2014_000000073946.jpg', 'COCO_val2014_000000073946.jpg', 'COCO_val2014_000000073946.jpg', 'COCO_val2014_000000073946.jpg', 'COCO_val2014_000000457584.jpg', 'COCO_val2014_000000457584.jpg', 'COCO_val2014_000000457584.jpg', 'COCO_val2014_000000457584.jpg', 'COCO_val2014_000000457584.jpg', 'COCO_val2014_000000250993.jpg', 'COCO_val2014_000000250993.jpg', 'COCO_val2014_000000250993.jpg', 'COCO_val2014_000000250993.jpg', 'COCO_val2014_000000250993.jpg', 'COCO_val2014_000000492378.jpg', 'COCO_val2014_000000492378.jpg', 'COCO_val2014_000000492378.jpg', 'COCO_val2014_000000492378.jpg', 'COCO_val2014_000000492378.jpg', 'COCO_val2014_000000461491.jpg', 'COCO_val2014_000000461491.jpg', 'COCO_val2014_000000461491.jpg', 'COCO_val2014_000000461491.jpg', 'COCO_val2014_000000461491.jpg', 'COCO_val2014_000000568426.jpg', 'COCO_val2014_000000568426.jpg', 'COCO_val2014_000000568426.jpg', 'COCO_val2014_000000568426.jpg', 'COCO_val2014_000000568426.jpg', 'COCO_val2014_000000364190.jpg', 'COCO_val2014_000000364190.jpg', 'COCO_val2014_000000364190.jpg', 'COCO_val2014_000000364190.jpg', 'COCO_val2014_000000364190.jpg', 'COCO_val2014_000000452218.jpg', 'COCO_val2014_000000452218.jpg', 'COCO_val2014_000000452218.jpg', 'COCO_val2014_000000452218.jpg', 'COCO_val2014_000000452218.jpg', 'COCO_val2014_000000232769.jpg', 'COCO_val2014_000000232769.jpg', 'COCO_val2014_000000232769.jpg', 'COCO_val2014_000000232769.jpg', 'COCO_val2014_000000232769.jpg', 'COCO_val2014_000000566543.jpg', 'COCO_val2014_000000566543.jpg', 'COCO_val2014_000000566543.jpg', 'COCO_val2014_000000566543.jpg', 'COCO_val2014_000000566543.jpg', 'COCO_val2014_000000256031.jpg', 'COCO_val2014_000000256031.jpg', 'COCO_val2014_000000256031.jpg', 'COCO_val2014_000000256031.jpg', 'COCO_val2014_000000256031.jpg', 'COCO_val2014_000000230819.jpg', 'COCO_val2014_000000230819.jpg', 'COCO_val2014_000000230819.jpg', 'COCO_val2014_000000230819.jpg', 'COCO_val2014_000000230819.jpg', 'COCO_val2014_000000376347.jpg', 'COCO_val2014_000000376347.jpg', 'COCO_val2014_000000376347.jpg', 'COCO_val2014_000000376347.jpg', 'COCO_val2014_000000376347.jpg', 'COCO_val2014_000000077596.jpg', 'COCO_val2014_000000077596.jpg', 'COCO_val2014_000000077596.jpg', 'COCO_val2014_000000077596.jpg', 'COCO_val2014_000000077596.jpg', 'COCO_val2014_000000266889.jpg', 'COCO_val2014_000000266889.jpg', 'COCO_val2014_000000266889.jpg', 'COCO_val2014_000000266889.jpg', 'COCO_val2014_000000266889.jpg', 'COCO_val2014_000000133596.jpg', 'COCO_val2014_000000133596.jpg', 'COCO_val2014_000000133596.jpg', 'COCO_val2014_000000133596.jpg', 'COCO_val2014_000000133596.jpg', 'COCO_val2014_000000563909.jpg', 'COCO_val2014_000000563909.jpg', 'COCO_val2014_000000563909.jpg', 'COCO_val2014_000000563909.jpg', 'COCO_val2014_000000563909.jpg', 'COCO_val2014_000000417965.jpg', 'COCO_val2014_000000417965.jpg', 'COCO_val2014_000000417965.jpg', 'COCO_val2014_000000417965.jpg', 'COCO_val2014_000000417965.jpg', 'COCO_val2014_000000320843.jpg', 'COCO_val2014_000000320843.jpg', 'COCO_val2014_000000320843.jpg', 'COCO_val2014_000000320843.jpg', 'COCO_val2014_000000320843.jpg', 'COCO_val2014_000000065883.jpg', 'COCO_val2014_000000065883.jpg', 'COCO_val2014_000000065883.jpg', 'COCO_val2014_000000065883.jpg', 'COCO_val2014_000000065883.jpg', 'COCO_val2014_000000152019.jpg', 'COCO_val2014_000000152019.jpg', 'COCO_val2014_000000152019.jpg', 'COCO_val2014_000000152019.jpg', 'COCO_val2014_000000152019.jpg', 'COCO_val2014_000000169045.jpg', 'COCO_val2014_000000169045.jpg', 'COCO_val2014_000000169045.jpg', 'COCO_val2014_000000169045.jpg', 'COCO_val2014_000000169045.jpg', 'COCO_val2014_000000383270.jpg', 'COCO_val2014_000000383270.jpg', 'COCO_val2014_000000383270.jpg', 'COCO_val2014_000000383270.jpg', 'COCO_val2014_000000383270.jpg', 'COCO_val2014_000000176935.jpg', 'COCO_val2014_000000176935.jpg', 'COCO_val2014_000000176935.jpg', 'COCO_val2014_000000176935.jpg', 'COCO_val2014_000000176935.jpg', 'COCO_val2014_000000443034.jpg', 'COCO_val2014_000000443034.jpg', 'COCO_val2014_000000443034.jpg', 'COCO_val2014_000000443034.jpg', 'COCO_val2014_000000443034.jpg', 'COCO_val2014_000000519182.jpg', 'COCO_val2014_000000519182.jpg', 'COCO_val2014_000000519182.jpg', 'COCO_val2014_000000519182.jpg', 'COCO_val2014_000000519182.jpg', 'COCO_val2014_000000350160.jpg', 'COCO_val2014_000000350160.jpg', 'COCO_val2014_000000350160.jpg', 'COCO_val2014_000000350160.jpg', 'COCO_val2014_000000350160.jpg', 'COCO_val2014_000000094501.jpg', 'COCO_val2014_000000094501.jpg', 'COCO_val2014_000000094501.jpg', 'COCO_val2014_000000094501.jpg', 'COCO_val2014_000000094501.jpg', 'COCO_val2014_000000149155.jpg', 'COCO_val2014_000000149155.jpg', 'COCO_val2014_000000149155.jpg', 'COCO_val2014_000000149155.jpg', 'COCO_val2014_000000149155.jpg', 'COCO_val2014_000000367673.jpg', 'COCO_val2014_000000367673.jpg', 'COCO_val2014_000000367673.jpg', 'COCO_val2014_000000367673.jpg', 'COCO_val2014_000000367673.jpg', 'COCO_val2014_000000372913.jpg', 'COCO_val2014_000000372913.jpg', 'COCO_val2014_000000372913.jpg', 'COCO_val2014_000000372913.jpg', 'COCO_val2014_000000372913.jpg', 'COCO_val2014_000000262229.jpg', 'COCO_val2014_000000262229.jpg', 'COCO_val2014_000000262229.jpg', 'COCO_val2014_000000262229.jpg', 'COCO_val2014_000000262229.jpg', 'COCO_val2014_000000296072.jpg', 'COCO_val2014_000000296072.jpg', 'COCO_val2014_000000296072.jpg', 'COCO_val2014_000000296072.jpg', 'COCO_val2014_000000296072.jpg', 'COCO_val2014_000000227550.jpg', 'COCO_val2014_000000227550.jpg', 'COCO_val2014_000000227550.jpg', 'COCO_val2014_000000227550.jpg', 'COCO_val2014_000000227550.jpg', 'COCO_val2014_000000488377.jpg', 'COCO_val2014_000000488377.jpg', 'COCO_val2014_000000488377.jpg', 'COCO_val2014_000000488377.jpg', 'COCO_val2014_000000488377.jpg', 'COCO_val2014_000000516116.jpg', 'COCO_val2014_000000516116.jpg', 'COCO_val2014_000000516116.jpg', 'COCO_val2014_000000516116.jpg', 'COCO_val2014_000000516116.jpg', 'COCO_val2014_000000303534.jpg', 'COCO_val2014_000000303534.jpg', 'COCO_val2014_000000303534.jpg', 'COCO_val2014_000000303534.jpg', 'COCO_val2014_000000303534.jpg', 'COCO_val2014_000000513039.jpg', 'COCO_val2014_000000513039.jpg', 'COCO_val2014_000000513039.jpg', 'COCO_val2014_000000513039.jpg', 'COCO_val2014_000000513039.jpg', 'COCO_val2014_000000082715.jpg', 'COCO_val2014_000000082715.jpg', 'COCO_val2014_000000082715.jpg', 'COCO_val2014_000000082715.jpg', 'COCO_val2014_000000082715.jpg', 'COCO_val2014_000000312078.jpg', 'COCO_val2014_000000312078.jpg', 'COCO_val2014_000000312078.jpg', 'COCO_val2014_000000312078.jpg', 'COCO_val2014_000000312078.jpg', 'COCO_val2014_000000118614.jpg', 'COCO_val2014_000000118614.jpg', 'COCO_val2014_000000118614.jpg', 'COCO_val2014_000000118614.jpg', 'COCO_val2014_000000118614.jpg', 'COCO_val2014_000000004742.jpg', 'COCO_val2014_000000004742.jpg', 'COCO_val2014_000000004742.jpg', 'COCO_val2014_000000004742.jpg', 'COCO_val2014_000000004742.jpg', 'COCO_val2014_000000144694.jpg', 'COCO_val2014_000000144694.jpg', 'COCO_val2014_000000144694.jpg', 'COCO_val2014_000000144694.jpg', 'COCO_val2014_000000144694.jpg', 'COCO_val2014_000000485564.jpg', 'COCO_val2014_000000485564.jpg', 'COCO_val2014_000000485564.jpg', 'COCO_val2014_000000485564.jpg', 'COCO_val2014_000000485564.jpg', 'COCO_val2014_000000054965.jpg', 'COCO_val2014_000000054965.jpg', 'COCO_val2014_000000054965.jpg', 'COCO_val2014_000000054965.jpg', 'COCO_val2014_000000054965.jpg', 'COCO_val2014_000000535626.jpg', 'COCO_val2014_000000535626.jpg', 'COCO_val2014_000000535626.jpg', 'COCO_val2014_000000535626.jpg', 'COCO_val2014_000000535626.jpg', 'COCO_val2014_000000367597.jpg', 'COCO_val2014_000000367597.jpg', 'COCO_val2014_000000367597.jpg', 'COCO_val2014_000000367597.jpg', 'COCO_val2014_000000367597.jpg', 'COCO_val2014_000000375211.jpg', 'COCO_val2014_000000375211.jpg', 'COCO_val2014_000000375211.jpg', 'COCO_val2014_000000375211.jpg', 'COCO_val2014_000000375211.jpg', 'COCO_val2014_000000085195.jpg', 'COCO_val2014_000000085195.jpg', 'COCO_val2014_000000085195.jpg', 'COCO_val2014_000000085195.jpg', 'COCO_val2014_000000085195.jpg', 'COCO_val2014_000000555739.jpg', 'COCO_val2014_000000555739.jpg', 'COCO_val2014_000000555739.jpg', 'COCO_val2014_000000555739.jpg', 'COCO_val2014_000000555739.jpg', 'COCO_val2014_000000099342.jpg', 'COCO_val2014_000000099342.jpg', 'COCO_val2014_000000099342.jpg', 'COCO_val2014_000000099342.jpg', 'COCO_val2014_000000099342.jpg', 'COCO_val2014_000000546649.jpg', 'COCO_val2014_000000546649.jpg', 'COCO_val2014_000000546649.jpg', 'COCO_val2014_000000546649.jpg', 'COCO_val2014_000000546649.jpg', 'COCO_val2014_000000095866.jpg', 'COCO_val2014_000000095866.jpg', 'COCO_val2014_000000095866.jpg', 'COCO_val2014_000000095866.jpg', 'COCO_val2014_000000095866.jpg', 'COCO_val2014_000000513136.jpg', 'COCO_val2014_000000513136.jpg', 'COCO_val2014_000000513136.jpg', 'COCO_val2014_000000513136.jpg', 'COCO_val2014_000000513136.jpg', 'COCO_val2014_000000106617.jpg', 'COCO_val2014_000000106617.jpg', 'COCO_val2014_000000106617.jpg', 'COCO_val2014_000000106617.jpg', 'COCO_val2014_000000106617.jpg', 'COCO_val2014_000000050828.jpg', 'COCO_val2014_000000050828.jpg', 'COCO_val2014_000000050828.jpg', 'COCO_val2014_000000050828.jpg', 'COCO_val2014_000000050828.jpg', 'COCO_val2014_000000508801.jpg', 'COCO_val2014_000000508801.jpg', 'COCO_val2014_000000508801.jpg', 'COCO_val2014_000000508801.jpg', 'COCO_val2014_000000508801.jpg', 'COCO_val2014_000000135497.jpg', 'COCO_val2014_000000135497.jpg', 'COCO_val2014_000000135497.jpg', 'COCO_val2014_000000135497.jpg', 'COCO_val2014_000000135497.jpg', 'COCO_val2014_000000277971.jpg', 'COCO_val2014_000000277971.jpg', 'COCO_val2014_000000277971.jpg', 'COCO_val2014_000000277971.jpg', 'COCO_val2014_000000277971.jpg', 'COCO_val2014_000000471004.jpg', 'COCO_val2014_000000471004.jpg', 'COCO_val2014_000000471004.jpg', 'COCO_val2014_000000471004.jpg', 'COCO_val2014_000000471004.jpg', 'COCO_val2014_000000360721.jpg', 'COCO_val2014_000000360721.jpg', 'COCO_val2014_000000360721.jpg', 'COCO_val2014_000000360721.jpg', 'COCO_val2014_000000360721.jpg', 'COCO_val2014_000000491098.jpg', 'COCO_val2014_000000491098.jpg', 'COCO_val2014_000000491098.jpg', 'COCO_val2014_000000491098.jpg', 'COCO_val2014_000000491098.jpg', 'COCO_val2014_000000134551.jpg', 'COCO_val2014_000000134551.jpg', 'COCO_val2014_000000134551.jpg', 'COCO_val2014_000000134551.jpg', 'COCO_val2014_000000134551.jpg', 'COCO_val2014_000000082554.jpg', 'COCO_val2014_000000082554.jpg', 'COCO_val2014_000000082554.jpg', 'COCO_val2014_000000082554.jpg', 'COCO_val2014_000000082554.jpg', 'COCO_val2014_000000437618.jpg', 'COCO_val2014_000000437618.jpg', 'COCO_val2014_000000437618.jpg', 'COCO_val2014_000000437618.jpg', 'COCO_val2014_000000437618.jpg', 'COCO_val2014_000000094012.jpg', 'COCO_val2014_000000094012.jpg', 'COCO_val2014_000000094012.jpg', 'COCO_val2014_000000094012.jpg', 'COCO_val2014_000000094012.jpg', 'COCO_val2014_000000570242.jpg', 'COCO_val2014_000000570242.jpg', 'COCO_val2014_000000570242.jpg', 'COCO_val2014_000000570242.jpg', 'COCO_val2014_000000570242.jpg', 'COCO_val2014_000000174091.jpg', 'COCO_val2014_000000174091.jpg', 'COCO_val2014_000000174091.jpg', 'COCO_val2014_000000174091.jpg', 'COCO_val2014_000000174091.jpg', 'COCO_val2014_000000062808.jpg', 'COCO_val2014_000000062808.jpg', 'COCO_val2014_000000062808.jpg', 'COCO_val2014_000000062808.jpg', 'COCO_val2014_000000062808.jpg', 'COCO_val2014_000000323766.jpg', 'COCO_val2014_000000323766.jpg', 'COCO_val2014_000000323766.jpg', 'COCO_val2014_000000323766.jpg', 'COCO_val2014_000000323766.jpg', 'COCO_val2014_000000378894.jpg', 'COCO_val2014_000000378894.jpg', 'COCO_val2014_000000378894.jpg', 'COCO_val2014_000000378894.jpg', 'COCO_val2014_000000378894.jpg', 'COCO_val2014_000000497344.jpg', 'COCO_val2014_000000497344.jpg', 'COCO_val2014_000000497344.jpg', 'COCO_val2014_000000497344.jpg', 'COCO_val2014_000000497344.jpg', 'COCO_val2014_000000561004.jpg', 'COCO_val2014_000000561004.jpg', 'COCO_val2014_000000561004.jpg', 'COCO_val2014_000000561004.jpg', 'COCO_val2014_000000561004.jpg', 'COCO_val2014_000000046732.jpg', 'COCO_val2014_000000046732.jpg', 'COCO_val2014_000000046732.jpg', 'COCO_val2014_000000046732.jpg', 'COCO_val2014_000000046732.jpg', 'COCO_val2014_000000045136.jpg', 'COCO_val2014_000000045136.jpg', 'COCO_val2014_000000045136.jpg', 'COCO_val2014_000000045136.jpg', 'COCO_val2014_000000045136.jpg', 'COCO_val2014_000000541123.jpg', 'COCO_val2014_000000541123.jpg', 'COCO_val2014_000000541123.jpg', 'COCO_val2014_000000541123.jpg', 'COCO_val2014_000000541123.jpg', 'COCO_val2014_000000356414.jpg', 'COCO_val2014_000000356414.jpg', 'COCO_val2014_000000356414.jpg', 'COCO_val2014_000000356414.jpg', 'COCO_val2014_000000356414.jpg', 'COCO_val2014_000000213905.jpg', 'COCO_val2014_000000213905.jpg', 'COCO_val2014_000000213905.jpg', 'COCO_val2014_000000213905.jpg', 'COCO_val2014_000000213905.jpg', 'COCO_val2014_000000153130.jpg', 'COCO_val2014_000000153130.jpg', 'COCO_val2014_000000153130.jpg', 'COCO_val2014_000000153130.jpg', 'COCO_val2014_000000153130.jpg', 'COCO_val2014_000000567276.jpg', 'COCO_val2014_000000567276.jpg', 'COCO_val2014_000000567276.jpg', 'COCO_val2014_000000567276.jpg', 'COCO_val2014_000000567276.jpg', 'COCO_val2014_000000536467.jpg', 'COCO_val2014_000000536467.jpg', 'COCO_val2014_000000536467.jpg', 'COCO_val2014_000000536467.jpg', 'COCO_val2014_000000536467.jpg', 'COCO_val2014_000000412440.jpg', 'COCO_val2014_000000412440.jpg', 'COCO_val2014_000000412440.jpg', 'COCO_val2014_000000412440.jpg', 'COCO_val2014_000000412440.jpg', 'COCO_val2014_000000295656.jpg', 'COCO_val2014_000000295656.jpg', 'COCO_val2014_000000295656.jpg', 'COCO_val2014_000000295656.jpg', 'COCO_val2014_000000295656.jpg', 'COCO_val2014_000000395665.jpg', 'COCO_val2014_000000395665.jpg', 'COCO_val2014_000000395665.jpg', 'COCO_val2014_000000395665.jpg', 'COCO_val2014_000000395665.jpg', 'COCO_val2014_000000325831.jpg', 'COCO_val2014_000000325831.jpg', 'COCO_val2014_000000325831.jpg', 'COCO_val2014_000000325831.jpg', 'COCO_val2014_000000325831.jpg', 'COCO_val2014_000000052664.jpg', 'COCO_val2014_000000052664.jpg', 'COCO_val2014_000000052664.jpg', 'COCO_val2014_000000052664.jpg', 'COCO_val2014_000000052664.jpg', 'COCO_val2014_000000249884.jpg', 'COCO_val2014_000000249884.jpg', 'COCO_val2014_000000249884.jpg', 'COCO_val2014_000000249884.jpg', 'COCO_val2014_000000249884.jpg', 'COCO_val2014_000000032039.jpg', 'COCO_val2014_000000032039.jpg', 'COCO_val2014_000000032039.jpg', 'COCO_val2014_000000032039.jpg', 'COCO_val2014_000000032039.jpg', 'COCO_val2014_000000490842.jpg', 'COCO_val2014_000000490842.jpg', 'COCO_val2014_000000490842.jpg', 'COCO_val2014_000000490842.jpg', 'COCO_val2014_000000490842.jpg', 'COCO_val2014_000000486770.jpg', 'COCO_val2014_000000486770.jpg', 'COCO_val2014_000000486770.jpg', 'COCO_val2014_000000486770.jpg', 'COCO_val2014_000000486770.jpg', 'COCO_val2014_000000155189.jpg', 'COCO_val2014_000000155189.jpg', 'COCO_val2014_000000155189.jpg', 'COCO_val2014_000000155189.jpg', 'COCO_val2014_000000155189.jpg', 'COCO_val2014_000000285844.jpg', 'COCO_val2014_000000285844.jpg', 'COCO_val2014_000000285844.jpg', 'COCO_val2014_000000285844.jpg', 'COCO_val2014_000000285844.jpg', 'COCO_val2014_000000460866.jpg', 'COCO_val2014_000000460866.jpg', 'COCO_val2014_000000460866.jpg', 'COCO_val2014_000000460866.jpg', 'COCO_val2014_000000460866.jpg', 'COCO_val2014_000000483130.jpg', 'COCO_val2014_000000483130.jpg', 'COCO_val2014_000000483130.jpg', 'COCO_val2014_000000483130.jpg', 'COCO_val2014_000000483130.jpg', 'COCO_val2014_000000410583.jpg', 'COCO_val2014_000000410583.jpg', 'COCO_val2014_000000410583.jpg', 'COCO_val2014_000000410583.jpg', 'COCO_val2014_000000410583.jpg', 'COCO_val2014_000000469202.jpg', 'COCO_val2014_000000469202.jpg', 'COCO_val2014_000000469202.jpg', 'COCO_val2014_000000469202.jpg', 'COCO_val2014_000000469202.jpg', 'COCO_val2014_000000207507.jpg', 'COCO_val2014_000000207507.jpg', 'COCO_val2014_000000207507.jpg', 'COCO_val2014_000000207507.jpg', 'COCO_val2014_000000207507.jpg', 'COCO_val2014_000000071360.jpg', 'COCO_val2014_000000071360.jpg', 'COCO_val2014_000000071360.jpg', 'COCO_val2014_000000071360.jpg', 'COCO_val2014_000000071360.jpg', 'COCO_val2014_000000547137.jpg', 'COCO_val2014_000000547137.jpg', 'COCO_val2014_000000547137.jpg', 'COCO_val2014_000000547137.jpg', 'COCO_val2014_000000547137.jpg', 'COCO_val2014_000000037660.jpg', 'COCO_val2014_000000037660.jpg', 'COCO_val2014_000000037660.jpg', 'COCO_val2014_000000037660.jpg', 'COCO_val2014_000000037660.jpg', 'COCO_val2014_000000140661.jpg', 'COCO_val2014_000000140661.jpg', 'COCO_val2014_000000140661.jpg', 'COCO_val2014_000000140661.jpg', 'COCO_val2014_000000140661.jpg', 'COCO_val2014_000000405183.jpg', 'COCO_val2014_000000405183.jpg', 'COCO_val2014_000000405183.jpg', 'COCO_val2014_000000405183.jpg', 'COCO_val2014_000000405183.jpg', 'COCO_val2014_000000490022.jpg', 'COCO_val2014_000000490022.jpg', 'COCO_val2014_000000490022.jpg', 'COCO_val2014_000000490022.jpg', 'COCO_val2014_000000490022.jpg', 'COCO_val2014_000000113397.jpg', 'COCO_val2014_000000113397.jpg', 'COCO_val2014_000000113397.jpg', 'COCO_val2014_000000113397.jpg', 'COCO_val2014_000000113397.jpg', 'COCO_val2014_000000459034.jpg', 'COCO_val2014_000000459034.jpg', 'COCO_val2014_000000459034.jpg', 'COCO_val2014_000000459034.jpg', 'COCO_val2014_000000459034.jpg', 'COCO_val2014_000000529139.jpg', 'COCO_val2014_000000529139.jpg', 'COCO_val2014_000000529139.jpg', 'COCO_val2014_000000529139.jpg', 'COCO_val2014_000000529139.jpg', 'COCO_val2014_000000494139.jpg', 'COCO_val2014_000000494139.jpg', 'COCO_val2014_000000494139.jpg', 'COCO_val2014_000000494139.jpg', 'COCO_val2014_000000494139.jpg', 'COCO_val2014_000000262738.jpg', 'COCO_val2014_000000262738.jpg', 'COCO_val2014_000000262738.jpg', 'COCO_val2014_000000262738.jpg', 'COCO_val2014_000000262738.jpg', 'COCO_val2014_000000517445.jpg', 'COCO_val2014_000000517445.jpg', 'COCO_val2014_000000517445.jpg', 'COCO_val2014_000000517445.jpg', 'COCO_val2014_000000517445.jpg', 'COCO_val2014_000000115521.jpg', 'COCO_val2014_000000115521.jpg', 'COCO_val2014_000000115521.jpg', 'COCO_val2014_000000115521.jpg', 'COCO_val2014_000000115521.jpg', 'COCO_val2014_000000109707.jpg', 'COCO_val2014_000000109707.jpg', 'COCO_val2014_000000109707.jpg', 'COCO_val2014_000000109707.jpg', 'COCO_val2014_000000109707.jpg', 'COCO_val2014_000000486114.jpg', 'COCO_val2014_000000486114.jpg', 'COCO_val2014_000000486114.jpg', 'COCO_val2014_000000486114.jpg', 'COCO_val2014_000000486114.jpg', 'COCO_val2014_000000572331.jpg', 'COCO_val2014_000000572331.jpg', 'COCO_val2014_000000572331.jpg', 'COCO_val2014_000000572331.jpg', 'COCO_val2014_000000572331.jpg', 'COCO_val2014_000000055323.jpg', 'COCO_val2014_000000055323.jpg', 'COCO_val2014_000000055323.jpg', 'COCO_val2014_000000055323.jpg', 'COCO_val2014_000000055323.jpg', 'COCO_val2014_000000058886.jpg', 'COCO_val2014_000000058886.jpg', 'COCO_val2014_000000058886.jpg', 'COCO_val2014_000000058886.jpg', 'COCO_val2014_000000058886.jpg', 'COCO_val2014_000000409630.jpg', 'COCO_val2014_000000409630.jpg', 'COCO_val2014_000000409630.jpg', 'COCO_val2014_000000409630.jpg', 'COCO_val2014_000000409630.jpg', 'COCO_val2014_000000475995.jpg', 'COCO_val2014_000000475995.jpg', 'COCO_val2014_000000475995.jpg', 'COCO_val2014_000000475995.jpg', 'COCO_val2014_000000475995.jpg', 'COCO_val2014_000000182647.jpg', 'COCO_val2014_000000182647.jpg', 'COCO_val2014_000000182647.jpg', 'COCO_val2014_000000182647.jpg', 'COCO_val2014_000000182647.jpg', 'COCO_val2014_000000065773.jpg', 'COCO_val2014_000000065773.jpg', 'COCO_val2014_000000065773.jpg', 'COCO_val2014_000000065773.jpg', 'COCO_val2014_000000065773.jpg', 'COCO_val2014_000000570022.jpg', 'COCO_val2014_000000570022.jpg', 'COCO_val2014_000000570022.jpg', 'COCO_val2014_000000570022.jpg', 'COCO_val2014_000000570022.jpg', 'COCO_val2014_000000160308.jpg', 'COCO_val2014_000000160308.jpg', 'COCO_val2014_000000160308.jpg', 'COCO_val2014_000000160308.jpg', 'COCO_val2014_000000160308.jpg', 'COCO_val2014_000000493273.jpg', 'COCO_val2014_000000493273.jpg', 'COCO_val2014_000000493273.jpg', 'COCO_val2014_000000493273.jpg', 'COCO_val2014_000000493273.jpg', 'COCO_val2014_000000153392.jpg', 'COCO_val2014_000000153392.jpg', 'COCO_val2014_000000153392.jpg', 'COCO_val2014_000000153392.jpg', 'COCO_val2014_000000153392.jpg', 'COCO_val2014_000000236909.jpg', 'COCO_val2014_000000236909.jpg', 'COCO_val2014_000000236909.jpg', 'COCO_val2014_000000236909.jpg', 'COCO_val2014_000000236909.jpg', 'COCO_val2014_000000356863.jpg', 'COCO_val2014_000000356863.jpg', 'COCO_val2014_000000356863.jpg', 'COCO_val2014_000000356863.jpg', 'COCO_val2014_000000356863.jpg', 'COCO_val2014_000000050926.jpg', 'COCO_val2014_000000050926.jpg', 'COCO_val2014_000000050926.jpg', 'COCO_val2014_000000050926.jpg', 'COCO_val2014_000000050926.jpg', 'COCO_val2014_000000054750.jpg', 'COCO_val2014_000000054750.jpg', 'COCO_val2014_000000054750.jpg', 'COCO_val2014_000000054750.jpg', 'COCO_val2014_000000054750.jpg', 'COCO_val2014_000000184388.jpg', 'COCO_val2014_000000184388.jpg', 'COCO_val2014_000000184388.jpg', 'COCO_val2014_000000184388.jpg', 'COCO_val2014_000000184388.jpg', 'COCO_val2014_000000212054.jpg', 'COCO_val2014_000000212054.jpg', 'COCO_val2014_000000212054.jpg', 'COCO_val2014_000000212054.jpg', 'COCO_val2014_000000212054.jpg', 'COCO_val2014_000000137408.jpg', 'COCO_val2014_000000137408.jpg', 'COCO_val2014_000000137408.jpg', 'COCO_val2014_000000137408.jpg', 'COCO_val2014_000000137408.jpg', 'COCO_val2014_000000404652.jpg', 'COCO_val2014_000000404652.jpg', 'COCO_val2014_000000404652.jpg', 'COCO_val2014_000000404652.jpg', 'COCO_val2014_000000404652.jpg', 'COCO_val2014_000000326820.jpg', 'COCO_val2014_000000326820.jpg', 'COCO_val2014_000000326820.jpg', 'COCO_val2014_000000326820.jpg', 'COCO_val2014_000000326820.jpg', 'COCO_val2014_000000557402.jpg', 'COCO_val2014_000000557402.jpg', 'COCO_val2014_000000557402.jpg', 'COCO_val2014_000000557402.jpg', 'COCO_val2014_000000557402.jpg', 'COCO_val2014_000000322620.jpg', 'COCO_val2014_000000322620.jpg', 'COCO_val2014_000000322620.jpg', 'COCO_val2014_000000322620.jpg', 'COCO_val2014_000000322620.jpg', 'COCO_val2014_000000225198.jpg', 'COCO_val2014_000000225198.jpg', 'COCO_val2014_000000225198.jpg', 'COCO_val2014_000000225198.jpg', 'COCO_val2014_000000225198.jpg', 'COCO_val2014_000000065520.jpg', 'COCO_val2014_000000065520.jpg', 'COCO_val2014_000000065520.jpg', 'COCO_val2014_000000065520.jpg', 'COCO_val2014_000000065520.jpg', 'COCO_val2014_000000188311.jpg', 'COCO_val2014_000000188311.jpg', 'COCO_val2014_000000188311.jpg', 'COCO_val2014_000000188311.jpg', 'COCO_val2014_000000188311.jpg', 'COCO_val2014_000000514797.jpg', 'COCO_val2014_000000514797.jpg', 'COCO_val2014_000000514797.jpg', 'COCO_val2014_000000514797.jpg', 'COCO_val2014_000000514797.jpg', 'COCO_val2014_000000503522.jpg', 'COCO_val2014_000000503522.jpg', 'COCO_val2014_000000503522.jpg', 'COCO_val2014_000000503522.jpg', 'COCO_val2014_000000503522.jpg', 'COCO_val2014_000000487925.jpg', 'COCO_val2014_000000487925.jpg', 'COCO_val2014_000000487925.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI()\n",
        "def generate(content):\n",
        "    messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": [\n",
        "                  {\"type\": \"text\", \"text\": content},\n",
        "                  {\n",
        "                      \"type\": \"image_url\",\n",
        "                      \"image_url\": {\n",
        "                          \"url\": \"https://i.postimg.cc/QCnfP8xh/image-1.jpg\",\n",
        "                      }\n",
        "                  },\n",
        "              ],\n",
        "          }\n",
        "      ]\n",
        "    print(\"running generate\")\n",
        "    model = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=1,\n",
        "        messages=messages,\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "    new_thought = model.choices[0].message.content\n",
        "\n",
        "    return new_thought"
      ],
      "metadata": {
        "id": "183sR9XMGe_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"DALL-E-2025-01-02-15-40-13-An-abstract-black-and-white-silhouette-of-a-woman-cutting-a-large-cake.webp\""
      ],
      "metadata": {
        "id": "qPZyEQhNP2cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "all_responses = []\n",
        "curr_filename = ''\n",
        "max_caption = ''\n",
        "count = 0\n",
        "\n",
        "# Create a progress bar\n",
        "total_iterations = len(ds[\"train\"][\"filename\"])\n",
        "with tqdm(total=total_iterations, desc=\"Processing\") as pbar:\n",
        "    for filename, caption in zip(ds[\"train\"][\"filename\"], ds[\"train\"][\"caption\"]):\n",
        "        if curr_filename != filename and curr_filename != '':\n",
        "            try:\n",
        "                response = generate(prompt.format(context=max_caption))\n",
        "                print(f\"{max_caption=}\\n{response}\")\n",
        "                print()\n",
        "                all_responses.append((max_caption, response))\n",
        "                count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {curr_filename}: {e}\")\n",
        "\n",
        "            curr_filename = filename\n",
        "            max_caption = caption\n",
        "        elif curr_filename != filename and curr_filename == '':\n",
        "            curr_filename = filename\n",
        "            max_caption = caption\n",
        "        else:\n",
        "            max_caption = max_caption if len(max_caption) > len(caption) else caption\n",
        "\n",
        "        # Update the progress bar\n",
        "        pbar.update(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb2R8omw-dVy",
        "outputId": "b7e584ac-a2dd-4e63-d696-4263bdef9a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   0%|          | 0/3114 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   0%|          | 3/3114 [00:02<43:17,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='some baseball players are playing baseball on a field'\n",
            "```\n",
            "Step 1: Some players are playing baseball on a field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   0%|          | 8/3114 [00:04<26:59,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Giant yellow teddy bear with light above and woman standing in front. '\n",
            "```\n",
            "Step 1: A large yellow teddy bear with a woman standing in front.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   0%|          | 13/3114 [00:06<25:35,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An umpire stands behind a catcher who stands in front of a baseball player holding a bat to his shoulder on a field.'\n",
            "```\n",
            "Step 1: An umpire standing behind a catcher on a baseball field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   1%|          | 18/3114 [00:08<21:58,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A baseball player in the batting box with the umpire and catcher.'\n",
            "```\n",
            "Step 1: A baseball player at bat with an umpire and catcher.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   1%|          | 23/3114 [00:10<21:09,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The boy throws a baseball to another boy who is ready to hit it.'\n",
            "```\n",
            "Step 1: A boy throws a baseball to another boy.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   1%|          | 28/3114 [00:12<20:12,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Pitcher throws ball to the batter who is ready to swing'\n",
            "```\n",
            "Step 1: A pitcher throwing a ball to a batter\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   1%|          | 33/3114 [00:13<19:18,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a little league baseball game in progress, player swinging the bat'\n",
            "```\n",
            "Step 1: A player swinging a bat in a baseball game\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   1%|          | 38/3114 [00:15<18:29,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A sign featuring a famous player claims allegiance to the Mets.'\n",
            "```\n",
            "Step 1: A sign supporting the Mets.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   1%|▏         | 43/3114 [00:17<19:24,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A batter on a baseball field in mid-swing with a catcher and an umpire behind him.'\n",
            "```\n",
            "Step 1: A batter swinging on a baseball field with a catcher and umpire behind him.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   2%|▏         | 48/3114 [00:19<19:33,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A batter has just hit the ball but has not dropped the bat yet to run.'\n",
            "```\n",
            "Step 1: A batter has just hit the ball.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   2%|▏         | 53/3114 [00:21<19:39,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A baseball player at home base is swinging his arm to hit the ball. '\n",
            "```\n",
            "Step 1: A baseball player swinging at the ball.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   2%|▏         | 58/3114 [00:23<18:58,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A batter at home plate just about to swing at a baseball'\n",
            "```\n",
            "Step 1: A batter at home plate ready to swing at a baseball.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   2%|▏         | 63/3114 [00:24<17:39,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A couple of men play baseball and the batter runs for base.'\n",
            "```\n",
            "Step 1: A man batting a baseball\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   2%|▏         | 68/3114 [00:26<18:08,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The runner tries to reach a plate before the baseman catches the ball.'\n",
            "```\n",
            "Step 1: A runner trying to reach a base before the ball arrives.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   2%|▏         | 73/3114 [00:28<17:30,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Man in baseball uniform holding a bat and moving away front he plate. '\n",
            "```\n",
            "Step 1: Man in a baseball uniform holding a bat.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   3%|▎         | 78/3114 [00:29<17:25,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The young baseball player in the red helmet is swinging his bat. '\n",
            "```\n",
            "Step 1: A young baseball player swinging a bat.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   3%|▎         | 83/3114 [00:32<20:05,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman on a tennis court poses her racquet as a ball comes towards her.'\n",
            "```\n",
            "Step 1: A woman on a tennis court with a racquet.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   3%|▎         | 88/3114 [00:35<21:48,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='There is a fresh pizza that just came out the oven'\n",
            "```\n",
            "Step 1: A fresh pizza out of the oven\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   3%|▎         | 93/3114 [00:37<23:01,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a man on a blue tennis court waiting for a tennis ball '\n",
            "```\n",
            "Step 1: A man waiting on a tennis court.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   3%|▎         | 98/3114 [00:40<23:18,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a man smiles as he sits in front of a big pizza '\n",
            "```\n",
            "Step 1: A man smiling in front of a pizza\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   3%|▎         | 103/3114 [00:41<21:57,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A male tennis player jumping in the air while swinging his tennis racket, on a hard surface court, with a scoreboard behind him.'\n",
            "```\n",
            "Step 1: A male tennis player jumping and swinging his racket on a court.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   3%|▎         | 108/3114 [00:44<24:15,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A couple of women playing a game of tennis on a tennis court.'\n",
            "```\n",
            "Step 1: Two women playing tennis on a court.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   4%|▎         | 113/3114 [00:47<23:52,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A hard surface tennis court with two girls on the first court together, holding tennis rackets in their hands.'\n",
            "```\n",
            "Step 1: Two girls on a tennis court holding rackets.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   4%|▍         | 118/3114 [00:50<25:22,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A large pizza sitting on top of a white plate.'\n",
            "```\n",
            "Step 1: A large pizza on a white plate.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   4%|▍         | 123/3114 [00:51<22:21,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Miicrosoft  manufactures the latest electronic devices in the market\\n'\n",
            "```\n",
            "Step 1: Microsoft makes electronic devices.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   4%|▍         | 128/3114 [00:53<21:04,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A laptop and a desktop sitting next to each other.'\n",
            "```\n",
            "Step 1: A laptop and a desktop next to each other.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   4%|▍         | 133/3114 [00:56<22:32,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='two cars parked in parking lot with a clock tower in the backgroound'\n",
            "```\n",
            "Step 1: Two cars parked with a clock tower in the background.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   4%|▍         | 138/3114 [00:58<22:23,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A work desk with a silver laptop propped up on top of the desk.'\n",
            "```\n",
            "Step 1: A desk with a laptop on top\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   5%|▍         | 143/3114 [01:00<22:53,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a man with eye glasses laying on a coach and holding a teddy bear'\n",
            "```\n",
            "Step 1: A man with glasses laying on a couch holding a teddy bear.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   5%|▍         | 148/3114 [01:03<23:30,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Seven people seated at table talking and working on computer devices.'\n",
            "```\n",
            "Step 1: Seven people sitting at a table with computers.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   5%|▍         | 153/3114 [01:05<23:47,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The orange stuffed teddy bear is on a tree limb. '\n",
            "```\n",
            "Step 1: An orange teddy bear on a tree branch.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   5%|▌         | 158/3114 [01:08<23:35,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A brown teddy bear laying on a carpet with the sun shining on it.'\n",
            "```\n",
            "Step 1: A teddy bear on a carpet\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   5%|▌         | 163/3114 [01:10<22:51,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A brown teddy bear sitting on top of an answering machine.'\n",
            "```\n",
            "Step 1: A teddy bear on an answering machine.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   5%|▌         | 168/3114 [01:11<20:33,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The woman are sitting at the restaurant table on the laptop.'\n",
            "```\n",
            "Step 1: Women sitting at a restaurant table with a laptop.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   6%|▌         | 173/3114 [01:14<20:52,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A small cell phone sitting next to a glass of Pepsi.'\n",
            "```\n",
            "Step 1: A cell phone next to a glass of Pepsi.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   6%|▌         | 178/3114 [01:16<21:49,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man has an intense cell phone conversation while making a gesture.'\n",
            "```\n",
            "Step 1: A man talking on the phone while gesturing.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   6%|▌         | 183/3114 [01:18<20:23,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A pair of orange scissors and eating utensils on a yellow surface.'\n",
            "```\n",
            "Step 1: A pair of orange scissors and utensils on a yellow surface.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   6%|▌         | 188/3114 [01:19<18:32,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Some people sitting around at various tables, with a railing dividing them'\n",
            "```\n",
            "Step 1: People sitting at tables with a railing in between\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   6%|▌         | 193/3114 [01:21<17:20,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Fridge and large appliances in industrial looking kitchen.'\n",
            "```\n",
            "Step 1: A fridge and appliances in a kitchen\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   6%|▋         | 198/3114 [01:23<18:04,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A new stainless steel stove ready for installation.'\n",
            "```\n",
            "Step 1: A stainless steel stove ready for installation.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   7%|▋         | 203/3114 [01:26<21:56,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman in black dress using a laptop by a park bench.'\n",
            "```\n",
            "Step 1: A woman in a dress using a laptop on a park bench.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   7%|▋         | 208/3114 [01:28<20:27,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A mouse sitting on a book under an illustration of a tree.'\n",
            "```\n",
            "Step 1: A mouse sitting on a book\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   7%|▋         | 213/3114 [01:30<20:17,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A lady wearing some white head covering using her phone at a restaurant.'\n",
            "```\n",
            "Step 1: A woman using her phone at a restaurant.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   7%|▋         | 218/3114 [01:32<20:15,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A row of different kind of kitchen stoves with different styles and colors.'\n",
            "```\n",
            "Step 1: A row of different kitchen stoves\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   7%|▋         | 223/3114 [01:35<22:14,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An old cell phone mounted on a wall above an awning.'\n",
            "```\n",
            "Step 1: An old cell phone mounted on a wall\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   7%|▋         | 228/3114 [01:37<21:02,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A smog darkened store clock tower providing a roost for pigeons. '\n",
            "```\n",
            "Step 1: A clock tower with pigeons\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   7%|▋         | 233/3114 [01:39<20:39,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A little girl is holding up a cell phone to the camera.'\n",
            "```\n",
            "Step 1: A girl holding a cell phone.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   8%|▊         | 238/3114 [01:42<24:37,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Women sitting at a table in a restaurant all looking at their phones '\n",
            "```\n",
            "Step 1: Women sitting at a restaurant table looking at their phones.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   8%|▊         | 243/3114 [01:44<22:32,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman is talking on her cell phone in the middle of a restaurant.'\n",
            "```\n",
            "Step 1: A woman talking on her cell phone in a restaurant.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   8%|▊         | 248/3114 [01:46<21:02,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Three men wearing specialty clothing with machines strapped to their backs.'\n",
            "```\n",
            "Step 1: Three men with special equipment on their backs.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   8%|▊         | 253/3114 [01:47<18:32,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A phone is sitting on its case with a charger next to that.'\n",
            "```\n",
            "Step 1: A phone on its case with a charger next to it.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   8%|▊         | 258/3114 [01:50<20:21,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man in a suit stands outside and talks on a phone next to a large window.'\n",
            "```\n",
            "Step 1: A man in a suit talking on the phone next to a large window.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   8%|▊         | 263/3114 [01:52<19:29,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a work desk with display with graphs, notebooks, and keyboard'\n",
            "```\n",
            "Step 1: A work desk with a display and notebooks\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   9%|▊         | 268/3114 [01:56<26:14,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man did something funny that the women laugh about it.'\n",
            "```\n",
            "Step 1: A man making women laugh.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   9%|▉         | 273/3114 [01:58<22:16,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The two markers are sitting on the holder on the table.'\n",
            "```\n",
            "Step 1: Two markers on a holder on a table.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   9%|▉         | 278/3114 [01:59<20:28,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A hand holds an old-style flip phone in the open position.  '\n",
            "```\n",
            "Step 1: A hand holding a flip phone\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   9%|▉         | 283/3114 [02:01<19:06,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The man is talking on the phone which is a older style phone.'\n",
            "```\n",
            "Step 1: A man talking on an old phone.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   9%|▉         | 288/3114 [02:04<21:03,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A smiling man wearing glasses talks on an older style cell phone.'\n",
            "```\n",
            "Step 1: A man talking on a cell phone.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   9%|▉         | 293/3114 [02:05<19:19,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The dash of a stove showing the oven temperature and pans on the stove top.'\n",
            "```\n",
            "Step 1: A stove with pans and an oven temperature display.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  10%|▉         | 298/3114 [02:07<19:18,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='This is a nice black over and under washer and dryer set.'\n",
            "```\n",
            "Step 1: A black washer and dryer set\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  10%|▉         | 303/3114 [02:09<18:45,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A little girl smiling as she is about to put something in the oven. '\n",
            "```\n",
            "Step 1: A little girl smiling as she approaches an oven.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  10%|▉         | 308/3114 [02:12<21:02,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A white refrigerator with two doors and a basket sitting on top of it.'\n",
            "```\n",
            "Step 1: A white refrigerator with two doors\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  10%|█         | 313/3114 [02:14<20:44,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption=\"A very tall brick clock tower with a clock on it's side.\"\n",
            "```\n",
            "Step 1: A tall brick clock tower\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  10%|█         | 318/3114 [02:16<19:25,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Many building roofs with a view of the ocean in the background.'\n",
            "```\n",
            "Step 1: Roofs of buildings with the ocean in the background.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  10%|█         | 323/3114 [02:19<20:35,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Vase sitting next to the window with droopy flowers in it.'\n",
            "```\n",
            "Step 1: A vase next to a window with flowers.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  11%|█         | 328/3114 [02:21<20:22,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Various supplies and food on a carpet that include water bottles and pens.'\n",
            "```\n",
            "Step 1: Supplies and food on a carpet\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  11%|█         | 333/3114 [02:23<19:32,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a large vase with a big colorful boquet sitting on a table '\n",
            "```\n",
            "Step 1: A large vase with a colorful bouquet on a table.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  11%|█         | 338/3114 [02:25<20:41,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The clock tower that has a sign saying \"Go By Train\" is surrounded by greenery.'\n",
            "```\n",
            "Step 1: A clock tower with a \"Go By Train\" sign surrounded by greenery.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  11%|█         | 343/3114 [02:27<19:06,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman brandishes a hair dryer with a suspicious look'\n",
            "```\n",
            "Step 1: A woman holding a hair dryer\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  11%|█         | 348/3114 [02:30<22:03,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing COCO_val2014_000000396768.jpg: Error code: 400 - {'error': {'message': 'Timeout while downloading https://i.postimg.cc/QCnfP8xh/image-1.jpg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  11%|█▏        | 353/3114 [02:31<19:40,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a clock in a clock tower and some buildings and clouds'\n",
            "```\n",
            "Step 1: A clock in a clock tower with buildings and clouds\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  11%|█▏        | 358/3114 [02:33<18:56,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The tower clock is architecturally sound in purpose and appearance.'\n",
            "```\n",
            "Step 1: A tower clock with a strong design.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  12%|█▏        | 363/3114 [02:36<21:31,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A large clock standing in front a building with lots of windows.'\n",
            "```\n",
            "Step 1: A large clock in front of a building\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  12%|█▏        | 368/3114 [02:41<26:31,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Big Been clock tower in London, England on an overcast day.'\n",
            "```\n",
            "Step 1: Big Ben clock tower in London\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  12%|█▏        | 373/3114 [02:42<22:37,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A tall, ornate tower features clocks on its front and side.'\n",
            "```\n",
            "Step 1: A tall tower with clocks on two sides.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  12%|█▏        | 378/3114 [02:44<22:03,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A golden clock with figures of children in a glass case on display.'\n",
            "```\n",
            "Step 1: A golden clock with child figures in a display case.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  12%|█▏        | 383/3114 [02:47<21:23,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A meal set out on a plate with a glass of orange juice and a cup of coffee.'\n",
            "```\n",
            "Step 1: A meal on a plate with orange juice and coffee.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  12%|█▏        | 388/3114 [02:48<19:33,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man sitting down with a brown teddy bear on his shoulders.'\n",
            "```\n",
            "Step 1: A man sitting with a teddy bear on his shoulders.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  13%|█▎        | 393/3114 [02:51<21:39,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man in black shirt laying on bed with a teddy bear.'\n",
            "```\n",
            "Step 1: A man lying on a bed with a teddy bear.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  13%|█▎        | 398/3114 [02:53<20:42,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Small baby in a hello kitty sweater smiling for the camera.'\n",
            "```\n",
            "Step 1: A baby smiling for the camera.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  13%|█▎        | 403/3114 [02:55<20:22,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A small wooden clock sitting on a counter next to a note pad and pen.'\n",
            "```\n",
            "Step 1: A small wooden clock on a counter with a notepad and pen.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  13%|█▎        | 408/3114 [02:58<20:09,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A high tower with a point on top has a clock near the top.'\n",
            "```\n",
            "Step 1: A tall tower with a clock near the top.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  13%|█▎        | 413/3114 [03:00<21:24,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An ancient-looking clock on a building has two bells with a soldier stationed at each end.'\n",
            "```\n",
            "Step 1: A clock on a building with soldiers at each end.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  13%|█▎        | 418/3114 [03:04<25:09,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Roof of a brick building with a chimney and a steeple with a weather vane on top.'\n",
            "```\n",
            "Step 1: Roof of a brick building with a chimney and a steeple\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  14%|█▎        | 423/3114 [03:06<23:41,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A large brick bulding with a massive clock on the face of the building.'\n",
            "```\n",
            "Step 1: A large brick building with a clock.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  14%|█▎        | 428/3114 [03:08<20:55,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A silver vase sits on a wood surface with sprigs of silver leaves in it next to a leafy green plant.'\n",
            "```\n",
            "Step 1: A silver vase with silver leaves next to a green plant\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  14%|█▍        | 433/3114 [03:10<20:48,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a vase covered in mosaic tiles holding three flowers'\n",
            "```\n",
            "Step 1: A vase with three flowers\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  14%|█▍        | 438/3114 [03:17<31:41,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Pens, markers, pencils and scissors in a cup on a desk next to a cellphone.'\n",
            "```\n",
            "Step 1: A cup with pens, markers, and scissors on a desk next to a cellphone.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  14%|█▍        | 443/3114 [03:21<32:48,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A girl holding a small dog poses for a photograph at a park.'\n",
            "```\n",
            "Step 1: A girl holding a small dog in a park.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  14%|█▍        | 448/3114 [03:23<29:28,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The stuffed bear is suspended from a plant hook by a  long strand of gray pearls.'\n",
            "```\n",
            "Step 1: A stuffed bear hanging from a hook by a strand of pearls.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  15%|█▍        | 453/3114 [03:25<26:25,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='There are is a picture of a couple, a beany baby bear, and pot of grass on a mantle.'\n",
            "```\n",
            "Step 1: A couple with a teddy bear and a pot of grass on a mantle.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  15%|█▍        | 458/3114 [03:28<24:48,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man sitting on a love seat holding a newspaper and covering his face with the shirt he is wearing '\n",
            "```\n",
            "Step 1: A man sitting on a love seat holding a newspaper\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  15%|█▍        | 463/3114 [03:30<23:04,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The table has a sandwich, a mug of coffee and custard cream on it.'\n",
            "```\n",
            "Step 1: A table with a sandwich, coffee, and custard cream.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  15%|█▌        | 468/3114 [03:32<21:30,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A half-filled cup of coffee on a table with pastries and bread.'\n",
            "```\n",
            "Step 1: A cup of coffee on a table with pastries and bread.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  15%|█▌        | 473/3114 [03:34<19:49,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An ice cream and banana crepe dessert on a plate next to a Cappucino in a restaurant.. '\n",
            "```\n",
            "Step 1: A dessert with ice cream and a banana crepe next to a cappuccino.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  15%|█▌        | 478/3114 [03:36<18:52,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of people sitting around a wooden table with food.'\n",
            "```\n",
            "Step 1: A group of people sitting at a table with food.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  16%|█▌        | 483/3114 [03:38<20:12,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of people crowd around a table on a balcony. '\n",
            "```\n",
            "Step 1: A group of people around a table\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  16%|█▌        | 488/3114 [03:40<19:18,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A table with breadsticks and three parcially filled glasses of wine and a wine bottle.'\n",
            "```\n",
            "Step 1: A table with breadsticks and glasses of wine.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  16%|█▌        | 493/3114 [03:44<21:59,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two women wearing sunglasses enjoying a glass of alcohol.'\n",
            "```\n",
            "Step 1: Two women enjoying drinks.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  16%|█▌        | 498/3114 [03:45<20:25,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man in a suit is sitting with a glass of wine.'\n",
            "```\n",
            "Step 1: A man in a suit sitting with a glass of wine.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  16%|█▌        | 503/3114 [03:49<24:46,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A lit candle is on a table where red wine is being poured into a glass.'\n",
            "```\n",
            "Step 1: A lit candle on a table with wine being poured into a glass.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  16%|█▋        | 508/3114 [03:52<25:10,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A lady laying down with a bright blue thing on her face.'\n",
            "```\n",
            "Step 1: A lady laying down with something blue on her face.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  16%|█▋        | 513/3114 [03:54<21:21,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A black and white photo of a man riding his motorcycle.'\n",
            "```\n",
            "Step 1: A man riding a motorcycle\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  17%|█▋        | 518/3114 [03:56<19:42,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Woman with laptop near man on cell phone dressed in construction worker gear.'\n",
            "```\n",
            "Step 1: A woman with a laptop and a man in construction gear using a cellphone.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  17%|█▋        | 523/3114 [03:59<23:05,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person looks at the camera while holding a black cat.'\n",
            "```\n",
            "Step 1: A person holding a black cat.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  17%|█▋        | 528/3114 [04:01<21:00,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man standing in front of a board that says \"Who do you think you are?\"'\n",
            "```\n",
            "Step 1: A man in front of a sign that says \"Who are you?\"\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  17%|█▋        | 533/3114 [04:03<19:18,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A coffee shop is equipped with pots of coffee, paper cups and other supplies.'\n",
            "```\n",
            "Step 1: A coffee shop with coffee pots and cups.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  17%|█▋        | 538/3114 [04:06<20:19,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a compact kitchen with stainless-steel cabinets behind glass blocks'\n",
            "```\n",
            "Step 1: A compact kitchen with stainless-steel cabinets\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  17%|█▋        | 543/3114 [04:09<22:01,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Several bikes laying on the grass and a person holding a frisbee.'\n",
            "```\n",
            "Step 1: Several bikes on the grass with a person holding a frisbee.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  18%|█▊        | 548/3114 [04:10<19:14,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A kitchen with a stove, microwave, counters, cabinets and an opened pantry'\n",
            "```\n",
            "Step 1: A kitchen with a stove, microwave, and cabinets.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  18%|█▊        | 553/3114 [04:12<17:36,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Three people stand on a grassy hill flying kites.'\n",
            "```\n",
            "Step 1: Three people flying kites on a hill.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  18%|█▊        | 558/3114 [04:17<25:11,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A full dressed marine is looking at his cell phone.'\n",
            "```\n",
            "Step 1: A marine looking at his cell phone.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  18%|█▊        | 563/3114 [04:19<23:49,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person cuts green leaves into smaller pieces with scissors.'\n",
            "```\n",
            "Step 1: A person cutting green leaves with scissors.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  18%|█▊        | 568/3114 [04:22<23:16,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='One  horseback rider trailing a younger horseback rider\\n\\n\\n\\n\\n\\n\\n'\n",
            "```\n",
            "Step 1: One horseback rider following a younger rider\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  18%|█▊        | 573/3114 [04:24<20:42,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A kitchen sink with a flower pot, pans and utensils.'\n",
            "```\n",
            "Step 1: A kitchen sink with utensils and a flower pot.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  19%|█▊        | 578/3114 [04:26<20:20,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A kitchen with wood cabinets, white refrigerator, white stove and a microwave above the refrigerator.'\n",
            "```\n",
            "Step 1: A kitchen with wood cabinets and white appliances.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  19%|█▊        | 583/3114 [04:29<22:01,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A black and white photo of a woman standing next to a cows rear'\n",
            "```\n",
            "Step 1: A woman standing next to a cow\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  19%|█▉        | 588/3114 [04:32<21:40,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A  young boy standing next to a kitchen sink next to a dish rack.'\n",
            "```\n",
            "Step 1: A young boy next to a kitchen sink.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  19%|█▉        | 593/3114 [04:33<19:25,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A toddler in his underwear stands in front of a sink.'\n",
            "```\n",
            "Step 1: A toddler stands in front of a sink.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  19%|█▉        | 598/3114 [04:35<18:50,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption=' a river.A group of people with life jacket rowing a long boat in'\n",
            "```\n",
            "Step 1: A group of people with life jackets rowing a boat on a river\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  19%|█▉        | 603/3114 [04:37<17:51,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Speedboat making turn on open ocean water with one passenger'\n",
            "```\n",
            "Step 1: A speedboat making a turn in the ocean\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  20%|█▉        | 608/3114 [04:41<21:29,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A team of row boat racers being instructed by their captain.'\n",
            "```\n",
            "Step 1: A team of boat racers listening to their captain.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  20%|█▉        | 613/3114 [04:45<26:22,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A lego style kitchen with appliances and cabinets along with a checkered tile floor.'\n",
            "```\n",
            "Step 1: A lego kitchen with appliances and a checkered floor.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  20%|█▉        | 618/3114 [04:47<23:31,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Three men and one woman stand around a green table as one man holds a silver bowl.'\n",
            "```\n",
            "Step 1: Three people standing around a table with one holding a bowl.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  20%|██        | 623/3114 [04:49<20:07,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An aerial shot of a kitchen and living room model of hosue'\n",
            "```\n",
            "Step 1: Aerial view of a kitchen and living room\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  20%|██        | 628/3114 [04:51<20:07,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A cat on a table in a fancy basket with fringe beside a parked bicycle.'\n",
            "```\n",
            "Step 1: A cat on a table with a bicycle nearby.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  20%|██        | 633/3114 [04:53<18:00,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Well lit bathroom with a jacuzzi style bath tub and small sink. '\n",
            "```\n",
            "Step 1: A bathroom with a jacuzzi bath and sink.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  20%|██        | 638/3114 [04:55<18:08,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a long hair cat sitting on a bench with a bicycle behind it'\n",
            "```\n",
            "Step 1: A long-haired cat sitting on a bench\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  21%|██        | 643/3114 [04:57<16:21,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The large cat is sitting on the bench on the side of the house where the bike is parked. '\n",
            "```\n",
            "Step 1: A large cat sitting on a bench next to a bike.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  21%|██        | 648/3114 [04:59<17:18,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A crowded city street with lots of people walking around.'\n",
            "```\n",
            "Step 1: A busy street with many people walking.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  21%|██        | 653/3114 [05:01<17:23,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A brown cat crouches and arches its back in a white sink.'\n",
            "```\n",
            "Step 1: A brown cat in a sink\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  21%|██        | 658/3114 [05:04<18:55,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a bathroom toilet with a carpteted seat cover and floor rug.'\n",
            "```\n",
            "Step 1: A toilet with a carpeted seat cover.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  21%|██▏       | 663/3114 [05:06<18:46,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two people in jackets and helmets ride bicycles on a city street.'\n",
            "```\n",
            "Step 1: Two people riding bicycles on a city street.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  21%|██▏       | 668/3114 [05:09<18:39,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Bicycles sit solidarity on a train car against the window'\n",
            "```\n",
            "Step 1: Bicycles on a train car\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  22%|██▏       | 673/3114 [05:13<23:39,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A street with cars and traffic lights on it during day.'\n",
            "```\n",
            "Step 1: A street with cars and traffic lights\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  22%|██▏       | 678/3114 [05:15<21:21,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Miniature bathroom area made from white and blue toy blocks.'\n",
            "```\n",
            "Step 1: Miniature bathroom made from toy blocks.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  22%|██▏       | 683/3114 [05:16<18:43,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A template example of a bathroom is shown in bright colors.'\n",
            "```\n",
            "Step 1: A bathroom template example\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  22%|██▏       | 688/3114 [05:18<16:54,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a bathroom with various bathroom items, including a cabinet, sink, and towels, and a washing machine'\n",
            "```\n",
            "Step 1: A bathroom with a sink, towels, and a washing machine.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  22%|██▏       | 693/3114 [05:20<15:23,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a bathroom with towels , lights, and a sink that is clean '\n",
            "```\n",
            "Step 1: A clean bathroom with towels and a sink.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  22%|██▏       | 698/3114 [05:24<21:50,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A stop sign with a sticker that says \"worrying\" fastened to it.'\n",
            "```\n",
            "Step 1: A stop sign with a sticker\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  23%|██▎       | 703/3114 [05:26<20:35,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A mouse cruelly placed into the toilet bowl for disposal.'\n",
            "```\n",
            "Step 1: A mouse in a toilet bowl.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  23%|██▎       | 708/3114 [05:29<19:40,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man riding a bike with a wooden trainer attached and a dog riding in it.'\n",
            "```\n",
            "Step 1: A man riding a bike with a dog in a wooden cart.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  23%|██▎       | 713/3114 [05:31<19:09,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An adult golden retriever standing next to a car.'\n",
            "```\n",
            "Step 1: An adult golden retriever next to a car.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  23%|██▎       | 718/3114 [05:33<18:19,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A dog is in a car and wearing a harness and leash is looking at us.'\n",
            "```\n",
            "Step 1: A dog in a car wearing a harness and leash\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  23%|██▎       | 723/3114 [05:35<19:03,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption=\"The dog is sitting behind the driver's seat of a blue car. \"\n",
            "```\n",
            "Step 1: A dog sitting in a car.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  23%|██▎       | 728/3114 [05:38<20:09,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A clock on a pedestal in a parking lot with people walking with bags.'\n",
            "```\n",
            "Step 1: A clock on a pedestal in a parking lot\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  24%|██▎       | 733/3114 [05:41<19:19,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A clock stands on the sidewalk while a police car turns the intersection in front of an old looking building.'\n",
            "```\n",
            "Step 1: A clock on the sidewalk with a police car turning in front of a building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  24%|██▎       | 738/3114 [05:42<18:10,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='In a library children look on as costumed characters give a presentation'\n",
            "```\n",
            "Step 1: Children watching costumed characters in a library\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  24%|██▍       | 743/3114 [05:45<17:33,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A few containers sitting on top of a table next to a blue wall.'\n",
            "```\n",
            "Step 1: A few containers on a table by a blue wall.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  24%|██▍       | 748/3114 [05:47<17:03,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The bathroom has white and green tiles on the wall, and green tiles on the floor, along with a white porcelain toilette, and a white garden style tub with a shower hook up.'\n",
            "```\n",
            "Step 1: A bathroom with white and green tiles and a white bathtub.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  24%|██▍       | 753/3114 [05:49<17:51,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Outside back of a building person is by a parked motorcycle.'\n",
            "```\n",
            "Step 1: A person by a parked motorcycle behind a building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  24%|██▍       | 758/3114 [05:51<17:19,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A black and white picture of an elderly woman sitting at a sewing machine.'\n",
            "```\n",
            "Step 1: An elderly woman sitting at a sewing machine.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  25%|██▍       | 763/3114 [05:53<17:07,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A tipped over and broken toilet outside, surrounded by other thrown out items.'\n",
            "```\n",
            "Step 1: A broken toilet outside among discarded items.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  25%|██▍       | 768/3114 [05:55<15:56,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An orange and blue bus parked on the side of a road.'\n",
            "```\n",
            "Step 1: A bus parked on the side of a road.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  25%|██▍       | 773/3114 [05:58<18:02,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A black and white cat is staring into a toilet with the words \"barf\" on the picture.'\n",
            "```\n",
            "Step 1: A cat looking into a toilet\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  25%|██▍       | 778/3114 [06:00<17:20,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bathroom with a stained glass and stone wall and tile of different shapes, sizes, and colors decorating the floor and walls with a toilet visible.'\n",
            "```\n",
            "Step 1: A bathroom with decorative walls and a visible toilet.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  25%|██▌       | 783/3114 [06:01<15:40,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='People at a veggie and fruit market looking at the merchandise.'\n",
            "```\n",
            "Step 1: People at a fruit and vegetable market.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  25%|██▌       | 788/3114 [06:06<21:33,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man sits on the toilet playing on a desktop computer in front of him.'\n",
            "```\n",
            "Step 1: A man sitting on a toilet using a computer.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  25%|██▌       | 793/3114 [06:07<18:21,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A striped cat standing next to an open toilet.'\n",
            "```\n",
            "Step 1: A cat standing next to a toilet.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  26%|██▌       | 798/3114 [06:10<18:45,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man stands in between a gas pump and a motorcycle while a woman in heels stands next to them.'\n",
            "```\n",
            "Step 1: A man and woman next to a gas pump and motorcycle.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  26%|██▌       | 803/3114 [06:12<17:28,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A girl on a motorcycle holding a DSW bag and kissing a guy who is driving the bike.'\n",
            "```\n",
            "Step 1: A girl on a motorcycle kissing a guy.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  26%|██▌       | 808/3114 [06:14<16:40,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='People passed out on the floor of a bathroom with urinals and a toilet.'\n",
            "```\n",
            "Step 1: People lying on the bathroom floor.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  26%|██▌       | 813/3114 [06:16<17:08,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A boy stands next to some motorcycles while adults ride down the street behind him.'\n",
            "```\n",
            "Step 1: A boy next to motorcycles while adults ride in the background.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  26%|██▋       | 818/3114 [06:18<16:51,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a white bathroom with a silver toilet paper holder and a toilet'\n",
            "```\n",
            "Step 1: A white bathroom with a toilet and toilet paper holder.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  26%|██▋       | 823/3114 [06:20<15:22,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bathroom with two toilets and a shower in it, with no space for any of them.'\n",
            "```\n",
            "Step 1: A small bathroom with two toilets and a shower.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  27%|██▋       | 828/3114 [06:22<15:42,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Closed toilet in small yellow bathroom bathed in sunlight from a window.'\n",
            "```\n",
            "Step 1: Closed toilet in a bright bathroom\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  27%|██▋       | 833/3114 [06:24<14:54,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Waffle-textured red linen holds a white plant with a dish, featuring tri-colored spiral pasta, and broccoli. '\n",
            "```\n",
            "Step 1: A white plant in a dish with pasta and broccoli\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  27%|██▋       | 838/3114 [06:26<15:07,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A cat resting inside a bowl next to different household items. '\n",
            "```\n",
            "Step 1: A cat resting in a bowl\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  27%|██▋       | 843/3114 [06:30<19:45,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Toilet in a bathroom in an international location with a basket.'\n",
            "```\n",
            "Step 1: A toilet in a bathroom with a basket.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  27%|██▋       | 848/3114 [06:32<17:24,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The sport motorcycle sits in front of the graffiti filled wall.'\n",
            "```\n",
            "Step 1: A motorcycle in front of a graffiti wall.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  27%|██▋       | 853/3114 [06:33<16:22,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='One man is riding a bike while another rides a motorcycle while some people are gathering around  to talk.'\n",
            "```\n",
            "Step 1: One man riding a bike and another on a motorcycle with people talking nearby.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  28%|██▊       | 858/3114 [06:36<17:08,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man seated on a blue motorcycle in the middle of the street.'\n",
            "```\n",
            "Step 1: A man on a motorcycle in the street.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  28%|██▊       | 863/3114 [06:38<15:32,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a young man riding on a motorcycle wearing dark sunglasses and a black messenger bag.'\n",
            "```\n",
            "Step 1: A young man riding a motorcycle with sunglasses and a bag.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  28%|██▊       | 868/3114 [06:39<14:39,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of people look at the dark green motorcycle parked on the grass.'\n",
            "```\n",
            "Step 1: A group of people looking at a green motorcycle on the grass.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  28%|██▊       | 873/3114 [06:42<15:21,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A motorcycle being used as a display at an outdoor event.'\n",
            "```\n",
            "Step 1: A motorcycle on display at an outdoor event.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  28%|██▊       | 878/3114 [06:43<14:07,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Blue motorcycle parked in small area with wall marked with lots of graffiti.'\n",
            "```\n",
            "Step 1: Blue motorcycle parked near a graffiti-covered wall.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  28%|██▊       | 883/3114 [06:46<15:54,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman lying down on a couch with newspapers near her feet.'\n",
            "```\n",
            "Step 1: A woman lying on a couch with newspapers nearby.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  29%|██▊       | 888/3114 [06:48<15:51,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A picture of a plate of food that looks to be a soup.'\n",
            "```\n",
            "Step 1: A plate of soup.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  29%|██▊       | 893/3114 [06:50<14:59,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bowl of prepared food including rice, meat and broccoli.'\n",
            "```\n",
            "Step 1: A bowl of rice, meat, and broccoli.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  29%|██▉       | 899/3114 [06:52<14:43,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A picture of microwave with a glass dish full of rice and mushrooms. '\n",
            "```\n",
            "Step 1: A microwave with a dish of rice and mushrooms\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  29%|██▉       | 904/3114 [06:54<15:33,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two monitors sitting on a desk by a chair and a window.'\n",
            "```\n",
            "Step 1: Two monitors on a desk by a chair and a window.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  29%|██▉       | 909/3114 [06:56<15:24,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An airplane cockpit is sticking out of the front of a building.'\n",
            "```\n",
            "Step 1: An airplane cockpit protruding from a building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  29%|██▉       | 914/3114 [06:58<14:06,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A motorcyclist riding alongside an airplane that is just taking off.'\n",
            "```\n",
            "Step 1: A motorcyclist riding next to a plane taking off.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  30%|██▉       | 919/3114 [07:00<14:24,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man riding on his motorcycle down the road. '\n",
            "```\n",
            "Step 1: A man riding a motorcycle\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  30%|██▉       | 924/3114 [07:03<15:46,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Artistic black and white photo of man on a motorcycle.'\n",
            "```\n",
            "Step 1: A black and white photo of a man on a motorcycle.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  30%|██▉       | 929/3114 [07:06<19:06,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The cat is laying down on the floor by the glass doors. '\n",
            "```\n",
            "Step 1: A cat lying on the floor by glass doors.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  30%|██▉       | 934/3114 [07:08<16:40,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person driving a 4 wheeler after a herd of cows.'\n",
            "```\n",
            "Step 1: A person driving a 4-wheeler near a herd of cows.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  30%|███       | 939/3114 [07:11<17:25,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Looking in the door of a commuter train from the platform'\n",
            "```\n",
            "Step 1: Looking into a train from the platform\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  30%|███       | 944/3114 [07:14<20:29,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption=\"A passenger train's door is open at the station platform.\"\n",
            "```\n",
            "Step 1: A train door is open at the platform.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  30%|███       | 949/3114 [07:16<18:48,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A vacant bus has seats facing in multiple directions.'\n",
            "```\n",
            "Step 1: A vacant bus with seats facing different directions.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  31%|███       | 954/3114 [07:19<18:12,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A cat being lazy and a cat being nozy in a living room with tv and a laptop displaying the same things.'\n",
            "```\n",
            "Step 1: A lazy cat and a curious cat in a living room with a TV and a laptop.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  31%|███       | 959/3114 [07:21<16:59,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='several hospital staff watching monitors with soundboard and headphones'\n",
            "```\n",
            "Step 1: Several hospital staff watching monitors with headphones\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  31%|███       | 964/3114 [07:23<17:31,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Several people climbing a mobile staircase to board an airplane.'\n",
            "```\n",
            "Step 1: People climbing a staircase to board an airplane.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  31%|███       | 969/3114 [07:27<19:50,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A large jumbo jet is ascending from an airport runway.'\n",
            "```\n",
            "Step 1: A jumbo jet taking off from a runway.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  31%|███▏      | 974/3114 [07:29<18:36,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A Singapore Airlines jetliner sits on a runway with baggage carts nearby.'\n",
            "```\n",
            "Step 1: A jetliner on a runway with baggage carts nearby.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  31%|███▏      | 979/3114 [07:31<16:19,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A airplane followed by birds flying in \"v-formation.\"'\n",
            "```\n",
            "Step 1: An airplane flying with birds\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  32%|███▏      | 984/3114 [07:32<14:51,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A statue of a man sitting on a horse is siting on top of a rock.'\n",
            "```\n",
            "Step 1: A statue of a man on a horse atop a rock.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  32%|███▏      | 989/3114 [07:36<18:37,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='View of clouds and the edge of a wing, from the interior of an airplane.'\n",
            "```\n",
            "Step 1: View of clouds from an airplane window\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  32%|███▏      | 994/3114 [07:39<18:04,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A window shot of a plane in the air with another plane present. '\n",
            "```\n",
            "Step 1: A shot of a plane in the air with another plane visible.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  32%|███▏      | 999/3114 [07:40<16:13,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An airplane flies high above in the sky with telephone lines in the picture as well. '\n",
            "```\n",
            "Step 1: An airplane flying in the sky with telephone lines below.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  32%|███▏      | 1004/3114 [07:42<15:18,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A small jet plane getting ready to be fueled at the airport.'\n",
            "```\n",
            "Step 1: A small jet plane at the airport\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  32%|███▏      | 1009/3114 [07:44<15:18,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a city street with multiple bildings and a street light'\n",
            "```\n",
            "Step 1: A city street with buildings and a street light\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  33%|███▎      | 1014/3114 [07:47<15:28,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A giraffe is standing alongside the road staring at an oncoming vehicle.'\n",
            "```\n",
            "Step 1: A giraffe standing by the road\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  33%|███▎      | 1019/3114 [07:51<20:27,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A red car driving down a mountain road next to a herd of sheep.'\n",
            "```\n",
            "Step 1: A car driving on a mountain road with sheep nearby.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  33%|███▎      | 1024/3114 [07:53<18:43,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Some yellow street lights on some poles in the middle of a street.'\n",
            "```\n",
            "Step 1: Yellow street lights on poles in the middle of a street.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  33%|███▎      | 1029/3114 [07:55<16:59,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man sitting on a park bench reading while a dog lays on the ground in front of him.'\n",
            "```\n",
            "Step 1: A man reading on a park bench with a dog laying in front of him.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  33%|███▎      | 1034/3114 [07:59<20:19,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A small building surrounded by a fence with yard furniture and houseplants.'\n",
            "```\n",
            "Step 1: A small building with yard furniture and plants\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  33%|███▎      | 1039/3114 [08:01<17:42,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A red bench next to a set of windows inside a building.'\n",
            "```\n",
            "Step 1: A red bench next to a window in a building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  34%|███▎      | 1044/3114 [08:03<15:42,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a black and white photo of a long bench for sitting near a building'\n",
            "```\n",
            "Step 1: A black and white photo of a long bench near a building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  34%|███▎      | 1049/3114 [08:05<15:28,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Sheep huddle together in a pile of hay next to a fence.'\n",
            "```\n",
            "Step 1: Sheep huddled in hay near a fence.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  34%|███▍      | 1054/3114 [08:06<13:53,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A herd of sheep standing on top of a lush green field.'\n",
            "```\n",
            "Step 1: A herd of sheep on a green field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  34%|███▍      | 1059/3114 [08:08<13:30,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A commercial plane on a runway just underneath the bright sun.'\n",
            "```\n",
            "Step 1: A plane on a runway\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  34%|███▍      | 1064/3114 [08:12<16:56,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A small airliner proceeds down the runway on takeoff.'\n",
            "```\n",
            "Step 1: A small airliner taking off\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  34%|███▍      | 1069/3114 [08:14<16:10,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A black and white colored cat on top of a wooden bench.'\n",
            "```\n",
            "Step 1: A cat on a wooden bench.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  34%|███▍      | 1074/3114 [08:16<14:27,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A view of a busy city scene through the tree tops.'\n",
            "```\n",
            "Step 1: A view of a city scene through tree tops.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  35%|███▍      | 1079/3114 [08:19<16:13,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A stop light on a street in front of a red brick building and a tall green building.'\n",
            "```\n",
            "Step 1: A stop light in front of buildings\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  35%|███▍      | 1084/3114 [08:20<15:06,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two men are sitting on a wooden crate with a cow next to them.'\n",
            "```\n",
            "Step 1: Two men sitting next to a cow.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  35%|███▍      | 1089/3114 [08:23<16:44,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A solo man with a hat and cane sitting on a graffiti filled bench on a cobbled path.'\n",
            "```\n",
            "Step 1: A man sitting on a bench\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  35%|███▌      | 1094/3114 [08:25<15:12,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A sign with plants and shade umbrellas sitting on the side of the road. '\n",
            "```\n",
            "Step 1: A sign with plants and umbrellas by the road.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  35%|███▌      | 1099/3114 [08:27<13:43,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman wearing a large black hat interacts with a little girl as she played with her stroller, which also has an umbrella over it. '\n",
            "```\n",
            "Step 1: A woman in a black hat with a little girl and a stroller.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  35%|███▌      | 1104/3114 [08:28<12:50,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a street light and a white pole against a blue background'\n",
            "```\n",
            "Step 1: A street light against a blue background\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  36%|███▌      | 1109/3114 [08:30<13:03,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='This intersection has more pedestrians than vehicles near it.'\n",
            "```\n",
            "Step 1: This intersection has more pedestrians than cars.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  36%|███▌      | 1114/3114 [08:32<12:37,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two green street lights in front of a building with a lot of windows.'\n",
            "```\n",
            "Step 1: Two street lights in front of a building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  36%|███▌      | 1119/3114 [08:34<12:38,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bus sits at a bus terminal in the early afternoon.'\n",
            "```\n",
            "Step 1: A bus at a terminal\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  36%|███▌      | 1124/3114 [08:36<12:20,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Black and white photo of a man sitting on a bench.'\n",
            "```\n",
            "Step 1: A man sitting on a bench\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  36%|███▋      | 1129/3114 [08:38<13:07,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A trolly bus is sitting in front of a bus stop as a man and women walk by.'\n",
            "```\n",
            "Step 1: A trolley bus in front of a bus stop with a man and woman walking by.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  36%|███▋      | 1134/3114 [08:40<13:08,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A zebra grazes on trees as deer graze on grass in the background.'\n",
            "```\n",
            "Step 1: A zebra grazing with deer in the background.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  37%|███▋      | 1139/3114 [08:43<13:54,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Sheep grazing on a green hillside in the grass with trees and small hills in the distance.'\n",
            "```\n",
            "Step 1: Sheep grazing on a green hillside\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  37%|███▋      | 1144/3114 [08:44<13:05,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A giraffe walking through the forest in the wild. '\n",
            "```\n",
            "Step 1: A giraffe walking in the forest.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  37%|███▋      | 1149/3114 [08:46<12:54,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two giraffes standing next to each other in front of some trees.'\n",
            "```\n",
            "Step 1: Two giraffes standing near trees.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  37%|███▋      | 1154/3114 [08:48<12:15,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='random goat standing in the outside looking around.'\n",
            "```\n",
            "Step 1: A goat standing outside\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  37%|███▋      | 1159/3114 [08:51<14:30,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A giraffe standing near a tree branch in the grass near a grove of trees.'\n",
            "```\n",
            "Step 1: A giraffe standing near a tree in the grass.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  37%|███▋      | 1164/3114 [08:53<15:13,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A black colored park bench next to fallen leaves and large trees that are bare.'\n",
            "```\n",
            "Step 1: A black park bench among fallen leaves and bare trees.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  38%|███▊      | 1169/3114 [08:55<13:55,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='There are two traffic signals on a metal pole, each with three light signals on them.'\n",
            "```\n",
            "Step 1: Two traffic signals on a pole with three lights each.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  38%|███▊      | 1174/3114 [08:57<12:51,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A lady walks a child towards a bus parked in a harbor.'\n",
            "```\n",
            "Step 1: A lady walking with a child towards a bus.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  38%|███▊      | 1179/3114 [08:59<13:09,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A giraffe in an indoor cage,standing against the back wall.\\n'\n",
            "```\n",
            "Step 1: A giraffe in a cage\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  38%|███▊      | 1184/3114 [09:02<14:28,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bus traveling on a road next to cars with building in background.'\n",
            "```\n",
            "Step 1: A bus on a road with cars and buildings in the background.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  38%|███▊      | 1189/3114 [09:04<14:36,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Close up from behind of a young giraffe standing with front legs splayed and head the ground by a fence outside.'\n",
            "```\n",
            "Step 1: A young giraffe with its front legs splayed near a fence.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  38%|███▊      | 1194/3114 [09:06<13:44,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two giraffes standing in an enclosure with green grass and rocks.'\n",
            "```\n",
            "Step 1: Two giraffes in an enclosure\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  39%|███▊      | 1199/3114 [09:10<16:35,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two giraffes standing in a field together in front of rocks and trees. '\n",
            "```\n",
            "Step 1: Two giraffes in a field with trees and rocks.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  39%|███▊      | 1204/3114 [09:11<14:43,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='There are three giraffes standing together under some trees'\n",
            "```\n",
            "Step 1: Three giraffes under trees\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  39%|███▉      | 1209/3114 [09:14<16:33,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Three giraffes in a zoo or park setting investigating each other.'\n",
            "```\n",
            "Step 1: Three giraffes in a park\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  39%|███▉      | 1214/3114 [09:17<15:34,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The truck and the van are driving through a street intersection.'\n",
            "```\n",
            "Step 1: A truck and a van driving through an intersection.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  39%|███▉      | 1219/3114 [09:19<14:47,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Someone stands on a fire hydrant, only their shoes and pants visible.'\n",
            "```\n",
            "Step 1: Someone standing on a fire hydrant with only their shoes and pants visible.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  39%|███▉      | 1224/3114 [09:21<14:05,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man and a woman sitting on a bench under a tree in formal dress clothes.'\n",
            "```\n",
            "Step 1: A man and a woman sitting on a bench\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  39%|███▉      | 1229/3114 [09:22<12:49,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A couple people standing by a hydrant that someone turned on.'\n",
            "```\n",
            "Step 1: A few people by an open hydrant.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  40%|███▉      | 1234/3114 [09:24<12:01,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of sheep stand in the grass by a rock cliff.'\n",
            "```\n",
            "Step 1: A group of sheep by a rock cliff\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  40%|███▉      | 1239/3114 [09:25<11:19,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a big long sidewalk that has a green and yellow fire hydration '\n",
            "```\n",
            "Step 1: A long sidewalk with a fire hydrant\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  40%|███▉      | 1244/3114 [09:27<11:44,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='some little goats and sheep standing next to a larger goat '\n",
            "```\n",
            "Step 1: Some little goats and sheep next to a larger goat.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  40%|████      | 1249/3114 [09:30<13:42,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman dressed up and a man dressed up walking in a grassy area.'\n",
            "```\n",
            "Step 1: A woman and a man walking in a grassy area.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  40%|████      | 1254/3114 [09:33<13:28,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man taking off his pants in front of a park bench.'\n",
            "```\n",
            "Step 1: A man by a park bench\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  40%|████      | 1259/3114 [09:34<12:28,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Woman sitting on a bench with man standing next to her while group watches'\n",
            "```\n",
            "Step 1: A woman sitting on a bench with a man standing nearby while a group looks on.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  41%|████      | 1264/3114 [09:39<18:26,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Three different red buses all parked on the side of the street .'\n",
            "```\n",
            "Step 1: Three red buses parked on the street.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  41%|████      | 1269/3114 [09:41<15:46,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A red fire hydrant sitting in a lush green field.'\n",
            "```\n",
            "Step 1: A red fire hydrant in a green field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  41%|████      | 1274/3114 [09:43<14:53,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man sitting on a bench with a book and a bag. '\n",
            "```\n",
            "Step 1: A man sitting on a bench with a book.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  41%|████      | 1279/3114 [09:45<13:26,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A giraffe laying in grassy field with tree and fence in background.'\n",
            "```\n",
            "Step 1: A giraffe lying in a grassy field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  41%|████      | 1284/3114 [09:46<12:16,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a couple of giraffes that are outside a brick building'\n",
            "```\n",
            "Step 1: A couple of giraffes outside a building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  41%|████▏     | 1289/3114 [09:48<12:13,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a couple of cars that are parked next to a sidewalk'\n",
            "```\n",
            "Step 1: A couple of cars parked by a sidewalk\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  42%|████▏     | 1294/3114 [09:51<12:39,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A modern transportation building with busses lined up for passengers.'\n",
            "```\n",
            "Step 1: A transportation building with buses lined up\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  42%|████▏     | 1299/3114 [09:53<12:50,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A giraffe lays down on the grass as a bird stands in the background.'\n",
            "```\n",
            "Step 1: A giraffe lying on the grass\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  42%|████▏     | 1304/3114 [09:56<15:33,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Small gray and white cat looking at a March white Swan. '\n",
            "```\n",
            "Step 1: A small cat looking at a swan.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  42%|████▏     | 1309/3114 [09:58<14:11,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A fire hydrant on a neighborhood street with trees and shrubs around it.'\n",
            "```\n",
            "Step 1: A fire hydrant on a street with trees nearby.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  42%|████▏     | 1314/3114 [10:00<13:35,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Several sheep are in a grassy field with trees.'\n",
            "```\n",
            "Step 1: Several sheep in a grassy field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  42%|████▏     | 1319/3114 [10:04<16:18,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='there is a white disney bus that passed under the train tracks'\n",
            "```\n",
            "Step 1: A white bus passing under train tracks\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  43%|████▎     | 1324/3114 [10:07<16:25,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='street signs on a metal pole lining a sidewalk lined with shrubbery.'\n",
            "```\n",
            "Step 1: Street signs on a pole by a sidewalk with shrubs.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  43%|████▎     | 1329/3114 [10:09<15:27,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bus being loaded with bags of luggage parked in front of a building.'\n",
            "```\n",
            "Step 1: A bus loaded with luggage in front of a building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  43%|████▎     | 1334/3114 [10:12<14:59,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two ceramic cups - one with a bird and the other with a fox.'\n",
            "```\n",
            "Step 1: Two ceramic cups, one with a bird and one with a fox.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  43%|████▎     | 1339/3114 [10:14<14:28,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A row of buildings and a city street on a hill that is pretty steep.'\n",
            "```\n",
            "Step 1: A street with buildings on a steep hill.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  43%|████▎     | 1344/3114 [10:16<14:02,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A pizza is covered with toppings to resemble an angry bird.'\n",
            "```\n",
            "Step 1: A pizza with various toppings\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  43%|████▎     | 1349/3114 [10:19<14:43,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two buses parked next to each other in front of a building.'\n",
            "```\n",
            "Step 1: Two buses parked in front of a building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  44%|████▎     | 1355/3114 [10:20<12:09,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A sheep standing near a table and chair decorated with flowers.'\n",
            "```\n",
            "Step 1: A sheep near a table decorated with flowers.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  44%|████▎     | 1360/3114 [10:22<11:29,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A dinner party draped in sheer drapes and adorned with stuffed farm animals.'\n",
            "```\n",
            "Step 1: A dinner party with stuffed farm animals\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  44%|████▍     | 1365/3114 [10:25<12:24,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a streets intersection with some street signs and street lights and cars'\n",
            "```\n",
            "Step 1: A street intersection with signs, lights, and cars.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  44%|████▍     | 1370/3114 [10:27<12:13,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The front of a bus on a city street with buildings and pedestrians around.'\n",
            "```\n",
            "Step 1: Front of a bus on a city street\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  44%|████▍     | 1375/3114 [10:28<10:54,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman pushing a stroller and others walking outside near buildings. '\n",
            "```\n",
            "Step 1: A woman with a stroller and others walking near buildings.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  44%|████▍     | 1380/3114 [10:30<11:30,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a large empty intersection with a florist shop displaying its flowers'\n",
            "```\n",
            "Step 1: A large intersection with a florist shop\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  44%|████▍     | 1385/3114 [10:34<15:16,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A chick inside of an oven covered in herbs and seasoning.'\n",
            "```\n",
            "Step 1: A chick covered in herbs and seasoning.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  45%|████▍     | 1390/3114 [10:36<14:00,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='two bird statutes sit on a clock with a brick tower'\n",
            "```\n",
            "Step 1: Two bird statues on a clock\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  45%|████▍     | 1395/3114 [10:38<13:15,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A black and white photo of a bunch of people walking along a busy street.'\n",
            "```\n",
            "Step 1: A black and white photo of people walking on a busy street.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  45%|████▍     | 1400/3114 [10:40<12:34,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman standing beside a statue of a zebra in front of a building.'\n",
            "```\n",
            "Step 1: A woman beside a zebra statue in front of a building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  45%|████▌     | 1405/3114 [10:43<12:43,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The two giraffes are standing next to each other in the field. '\n",
            "```\n",
            "Step 1: Two giraffes standing in a field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  45%|████▌     | 1410/3114 [10:44<11:33,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bird is perched on a rock in the sea water.'\n",
            "```\n",
            "Step 1: A bird on a rock by the sea\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  45%|████▌     | 1415/3114 [10:46<11:25,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An open square with people walking, several restaurants and buildings. '\n",
            "```\n",
            "Step 1: A square with people walking and buildings.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  46%|████▌     | 1420/3114 [10:48<10:53,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A watch tower stands as the ocean laps the concrete ground.'\n",
            "```\n",
            "Step 1: A watch tower by the ocean.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  46%|████▌     | 1425/3114 [10:50<11:06,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A street sign marks the intersection of S Lane St. and 12th Ave S.'\n",
            "```\n",
            "Step 1: A street sign at an intersection.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  46%|████▌     | 1430/3114 [10:54<13:46,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man in camouflage holds up a large dead turkey.'\n",
            "```\n",
            "Step 1: A man holding a large turkey.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  46%|████▌     | 1435/3114 [10:55<12:39,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Man wearing a white hat standing by a table with a table in his hand.'\n",
            "```\n",
            "Step 1: A man with a white hat standing by a table.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  46%|████▌     | 1440/3114 [10:57<12:10,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A hummingbird sitting on a plant preparing to flap its wings.'\n",
            "```\n",
            "Step 1: A hummingbird on a plant\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  46%|████▋     | 1445/3114 [10:59<11:49,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A yellow sign against a gray backdrop warns of a moving vehicle.'\n",
            "```\n",
            "Step 1: A yellow warning sign\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  47%|████▋     | 1450/3114 [11:01<11:15,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two little birds with white chests sit on barbed wire.'\n",
            "```\n",
            "Step 1: Two birds sitting on barbed wire.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  47%|████▋     | 1455/3114 [11:05<13:51,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Brown animal sticking its face into the inside of a red rose. '\n",
            "```\n",
            "Step 1: A brown animal smelling a red rose.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  47%|████▋     | 1460/3114 [11:07<13:06,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A busy train station has passengers getting on and off the trains.'\n",
            "```\n",
            "Step 1: Passengers getting on and off trains at a station.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  47%|████▋     | 1465/3114 [11:08<11:49,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A dark colored street car trollet near a wooden telephone pole.'\n",
            "```\n",
            "Step 1: A streetcar near a wooden telephone pole.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  47%|████▋     | 1470/3114 [11:11<12:30,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a blue bird is perching on a thin upright branch.'\n",
            "```\n",
            "Step 1: A blue bird on a branch.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  47%|████▋     | 1475/3114 [11:13<12:26,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A black cat wearing a black beanie while laying on a red couch..'\n",
            "```\n",
            "Step 1: A black cat on a red couch.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  48%|████▊     | 1480/3114 [11:18<16:13,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a large cat resting on a cardboard box next to a mirror on the wall'\n",
            "```\n",
            "Step 1: A large cat resting on a box next to a mirror.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  48%|████▊     | 1485/3114 [11:20<14:02,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two men smiling while they are in a car with a dog.'\n",
            "```\n",
            "Step 1: Two men in a car with a dog\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  48%|████▊     | 1490/3114 [11:22<13:01,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A little girl reaches for some wipes while her stuffed bear sits on the toilet.'\n",
            "```\n",
            "Step 1: A little girl reaching for wipes next to her stuffed bear on the toilet.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  48%|████▊     | 1495/3114 [11:24<12:44,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bird perched on top of a tree branch with large wings.l'\n",
            "```\n",
            "Step 1: A bird on a tree branch\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  48%|████▊     | 1500/3114 [11:27<13:17,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Chocolate dessert bars covered in frosting and sprinkles.'\n",
            "```\n",
            "Step 1: Chocolate dessert bars with frosting and sprinkles.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  48%|████▊     | 1505/3114 [11:30<15:03,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='This is a view inside the cabin of the high speed train, showing relection of the light.'\n",
            "```\n",
            "Step 1: View inside a train cabin with light reflections.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  48%|████▊     | 1510/3114 [11:32<13:43,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A lamb relaxes on a picturesque hillside, next to a tree.'\n",
            "```\n",
            "Step 1: A lamb resting on a hillside.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  49%|████▊     | 1515/3114 [11:34<13:04,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A white and red train at a train depot with passengers sitting inside.'\n",
            "```\n",
            "Step 1: A red and white train at a depot with passengers inside.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  49%|████▉     | 1520/3114 [11:36<12:23,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Low view of small passenger train moving through the countryside.'\n",
            "```\n",
            "Step 1: A small passenger train moving through the countryside.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  49%|████▉     | 1525/3114 [11:38<11:52,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train rides down tracks that are surrounded by grass.'\n",
            "```\n",
            "Step 1: A train on grassy tracks.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  49%|████▉     | 1530/3114 [11:41<11:56,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Passenger train stopped on the track under a bridge.'\n",
            "```\n",
            "Step 1: A train stopped under a bridge.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  49%|████▉     | 1535/3114 [11:42<10:49,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A sheep sniffing another sheep in a field of grass.'\n",
            "```\n",
            "Step 1: A sheep sniffing another sheep in a field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  49%|████▉     | 1540/3114 [11:44<10:54,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Small train pulling passengers like something you see in an amusement park'\n",
            "```\n",
            "Step 1: A small train pulling passengers\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  50%|████▉     | 1545/3114 [11:48<13:23,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of four street signs stacked on top of each other.'\n",
            "```\n",
            "Step 1: Four street signs stacked together.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  50%|████▉     | 1550/3114 [11:50<11:44,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of hawks are perched with hunting caps on their heads. '\n",
            "```\n",
            "Step 1: A group of hawks with caps on their heads.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  50%|████▉     | 1555/3114 [11:53<13:59,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An old fashioned looking red train is on the tracks by a green grassy hill.'\n",
            "```\n",
            "Step 1: A red train on the tracks by a hill.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  50%|█████     | 1560/3114 [11:56<13:26,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train cart travels down the road on some tracks'\n",
            "```\n",
            "Step 1: A train on tracks\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  50%|█████     | 1565/3114 [11:57<11:45,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Caution sign on a pole in a tropical area with palm trees in the background.'\n",
            "```\n",
            "Step 1: A caution sign on a pole with palm trees in the background.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  50%|█████     | 1570/3114 [12:00<12:32,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bird with a red and yellow beak leaning over to some water.'\n",
            "```\n",
            "Step 1: A bird leaning over water\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  51%|█████     | 1575/3114 [12:02<12:13,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A black and white picture of a building with a neon sign.'\n",
            "```\n",
            "Step 1: A black and white picture of a building\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  51%|█████     | 1580/3114 [12:05<11:52,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train on a railroad track with a huge mountain range in the background.'\n",
            "```\n",
            "Step 1: A train on a railroad track with mountains in the background.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  51%|█████     | 1585/3114 [12:07<11:29,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a vintage photo of a train passing through a rural area '\n",
            "```\n",
            "Step 1: A train passing through a rural area\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  51%|█████     | 1590/3114 [12:08<10:26,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The connecting mechanism of a train is shown in black and white.'\n",
            "```\n",
            "Step 1: A train's connection mechanism in black and white.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  51%|█████     | 1595/3114 [12:10<09:41,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A blue and yellow train is sitting on some railroad tracks.'\n",
            "```\n",
            "Step 1: A train on railroad tracks.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  51%|█████▏    | 1600/3114 [12:12<10:18,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a silver train with an orange front is moving on the track '\n",
            "```\n",
            "Step 1: A silver train is moving on the track.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  52%|█████▏    | 1605/3114 [12:14<10:26,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a train on a train track with a building in the background'\n",
            "```\n",
            "Step 1: A train on a track with a building behind it\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  52%|█████▏    | 1610/3114 [12:17<11:22,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a yellow train parked at a platfrom with a bright light '\n",
            "```\n",
            "Step 1: A yellow train at a platform\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  52%|█████▏    | 1615/3114 [12:19<10:44,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two trains driving on adjoining tracks at the same time.'\n",
            "```\n",
            "Step 1: Two trains on adjacent tracks\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  52%|█████▏    | 1620/3114 [12:20<09:50,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A passanger train stopped to pick up passangers at a station.'\n",
            "```\n",
            "Step 1: A train stopped at a station to pick up passengers.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  52%|█████▏    | 1625/3114 [12:22<09:02,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train that is stationary at the station waiting for passengers. '\n",
            "```\n",
            "Step 1: A train at the station\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  52%|█████▏    | 1630/3114 [12:24<08:49,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The large freight train is pulling many cars of cargo. '\n",
            "```\n",
            "Step 1: A large freight train pulling cargo cars.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  53%|█████▎    | 1635/3114 [12:28<12:32,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A miniature blue train engine sits on the tracks in a rural setting.'\n",
            "```\n",
            "Step 1: A blue train engine on tracks in a rural area.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  53%|█████▎    | 1640/3114 [12:30<11:43,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption=\"Two conductors of children's miniature trains talking while groups of families wait in line.\"\n",
            "```\n",
            "Step 1: Two train conductors talking while families wait in line.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  53%|█████▎    | 1645/3114 [12:32<10:37,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train engineer preparing the engine of this train for travel.'\n",
            "```\n",
            "Step 1: A train engineer preparing the train for travel.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  53%|█████▎    | 1650/3114 [12:36<14:04,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A commuter train pulling out of a suburban station.'\n",
            "```\n",
            "Step 1: A train leaving a station.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  53%|█████▎    | 1655/3114 [12:38<12:43,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Passengers wait at the platform as a passenger train approaches.'\n",
            "```\n",
            "Step 1: Passengers wait on the platform as a train arrives.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  53%|█████▎    | 1660/3114 [12:40<11:43,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A yellow & blue commuter train pulling up to a train station'\n",
            "```\n",
            "Step 1: A blue and yellow train arriving at a station\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  53%|█████▎    | 1665/3114 [12:44<13:17,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The green train is pulling up next to the platform of a train station.'\n",
            "```\n",
            "Step 1: A green train next to a train station platform.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  54%|█████▎    | 1670/3114 [12:45<11:41,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A purple train with a yellow front is under neath an over path.'\n",
            "```\n",
            "Step 1: A purple train under an overpass.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  54%|█████▍    | 1675/3114 [12:48<11:36,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A blue and yellow train parked in front of a station.'\n",
            "```\n",
            "Step 1: A train parked in front of a station.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  54%|█████▍    | 1680/3114 [12:50<11:21,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A large train car labeled \"buffet\" and \"first class\" is parked in a train yard.'\n",
            "```\n",
            "Step 1: A large train car labeled \"buffet\" parked in a train yard.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  54%|█████▍    | 1685/3114 [12:54<13:31,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Green and yellow trains sitting at a station next to each other. '\n",
            "```\n",
            "Step 1: Green and yellow trains at a station.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  54%|█████▍    | 1690/3114 [12:56<12:50,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two yellow Metro passenger trains going under a red steel bridge.'\n",
            "```\n",
            "Step 1: Two yellow trains under a steel bridge.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  54%|█████▍    | 1695/3114 [13:01<15:20,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A passenger train travels under a building near a station platform.'\n",
            "```\n",
            "Step 1: A train traveling under a building near a platform.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  55%|█████▍    | 1700/3114 [13:04<14:43,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='People walk on the platform beside two trains that are beside one another.'\n",
            "```\n",
            "Step 1: People walk beside two trains on a platform.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  55%|█████▍    | 1705/3114 [13:06<13:49,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An empty train station with a train pulled up with its doors open.'\n",
            "```\n",
            "Step 1: An empty train station with a train at the platform.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  55%|█████▍    | 1710/3114 [13:08<11:58,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a green train engine sitting at the end of the train and next to the buidling'\n",
            "```\n",
            "Step 1: A green train engine next to a building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  55%|█████▌    | 1715/3114 [13:10<11:17,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='an image of a railroad track with train coming down'\n",
            "```\n",
            "Step 1: A railroad track with a train approaching\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  55%|█████▌    | 1720/3114 [13:12<10:51,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A yellow train traveling down train tracks next to a field.'\n",
            "```\n",
            "Step 1: A yellow train on train tracks next to a field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  55%|█████▌    | 1725/3114 [13:14<09:50,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two empty modern train engines face each other on urban tracks.'\n",
            "```\n",
            "Step 1: Two modern train engines face each other on tracks.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  56%|█████▌    | 1730/3114 [13:15<08:57,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train traveling down tracks next to a train station.'\n",
            "```\n",
            "Step 1: A train next to a train station.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  56%|█████▌    | 1735/3114 [13:17<09:19,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train is pulling up to a platform to pick up passengers.'\n",
            "```\n",
            "Step 1: A train arriving at a platform\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  56%|█████▌    | 1740/3114 [13:20<09:40,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The train engine is different than the ones we have in the USA.'\n",
            "```\n",
            "Step 1: A train engine that is different from those in the USA.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  56%|█████▌    | 1745/3114 [13:23<11:18,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A commuting train movig through a rail yard with tracks on'\n",
            "```\n",
            "Step 1: A train moving through a rail yard\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  56%|█████▌    | 1750/3114 [13:27<12:38,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a white and black train engine pulling several train cars next to trees.'\n",
            "```\n",
            "Step 1: A black and white train engine pulling train cars next to trees.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  56%|█████▋    | 1755/3114 [13:29<11:43,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of people standing on a platform waiting for a train.'\n",
            "```\n",
            "Step 1: A group of people waiting for a train on a platform.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  57%|█████▋    | 1760/3114 [13:30<10:25,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An old fashioned train is parked as workers gather around it.'\n",
            "```\n",
            "Step 1: An old-fashioned train with workers around it.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  57%|█████▋    | 1765/3114 [13:32<09:04,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a yellow and white passenger train parked beside a train platform '\n",
            "```\n",
            "Step 1: A yellow and white train parked at a platform\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  57%|█████▋    | 1770/3114 [13:33<08:27,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Trees with orange and yellow leaves during autumn and traffic signs'\n",
            "```\n",
            "Step 1: Trees with orange and yellow leaves\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  57%|█████▋    | 1775/3114 [13:35<08:07,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A green and yellow rain on tracks with building in background.'\n",
            "```\n",
            "Step 1: A rain on tracks with a building in the background.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  57%|█████▋    | 1780/3114 [13:37<08:13,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A very old train parked at a station in a black and white photo.'\n",
            "```\n",
            "Step 1: An old train parked at a station\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  57%|█████▋    | 1785/3114 [13:38<07:47,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train car pulls into a train station where travelers wait nearby.'\n",
            "```\n",
            "Step 1: A train arriving at a station with passengers nearby.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  57%|█████▋    | 1790/3114 [13:41<08:46,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train traveling through a rural country side covered in grass.'\n",
            "```\n",
            "Step 1: A train traveling through grassy countryside.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  58%|█████▊    | 1795/3114 [13:44<10:02,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bright red train with a yellow face is being approached by people in the background.'\n",
            "```\n",
            "Step 1: A red train being approached by people\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  58%|█████▊    | 1800/3114 [13:46<09:19,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train engine carrying a cart down a track through the woods.'\n",
            "```\n",
            "Step 1: A train carrying a cart on a track in the woods.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  58%|█████▊    | 1805/3114 [13:49<10:35,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The clock reads 2:35 at the train station with two trains present.'\n",
            "```\n",
            "Step 1: The clock shows 2:35 at the train station with two trains.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  58%|█████▊    | 1810/3114 [13:51<09:56,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Small passenger train passing through verdant country side. '\n",
            "```\n",
            "Step 1: A small train passing through the countryside.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  58%|█████▊    | 1815/3114 [13:54<11:15,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A grouping of old trains on tracks behind a train depot.'\n",
            "```\n",
            "Step 1: A group of old trains on tracks\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  58%|█████▊    | 1820/3114 [13:58<13:23,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train engine on the tracks with a side rail beside it.'\n",
            "```\n",
            "Step 1: A train engine on the tracks\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  59%|█████▊    | 1825/3114 [14:02<13:32,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The red and orange train is pulling up to the platform.'\n",
            "```\n",
            "Step 1: A red and orange train arriving at a platform.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  59%|█████▉    | 1830/3114 [14:04<12:09,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train traveling through a rural green countryside.'\n",
            "```\n",
            "Step 1: A train traveling through green countryside.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  59%|█████▉    | 1835/3114 [14:06<11:01,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption=' a stop sign on a wooden pole with a street name stenciled on it'\n",
            "```\n",
            "Step 1: A stop sign on a pole\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  59%|█████▉    | 1840/3114 [14:08<10:42,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A view of the woods from a car of knocked down trees. '\n",
            "```\n",
            "Step 1: A view of knocked down trees in the woods\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  59%|█████▉    | 1845/3114 [14:10<10:02,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Locomotive engine and cargo cars traveling on train tracks.'\n",
            "```\n",
            "Step 1: A train with cargo cars on tracks.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  59%|█████▉    | 1850/3114 [14:13<10:26,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A yellow, red, and silver train makes its way to the loading platform.'\n",
            "```\n",
            "Step 1: A train approaching the loading platform.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  60%|█████▉    | 1855/3114 [14:16<11:37,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The metro train is approaching the platform near many trees.'\n",
            "```\n",
            "Step 1: A metro train approaching a platform near trees.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  60%|█████▉    | 1860/3114 [14:18<10:28,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of trains passing by each other on a track.'\n",
            "```\n",
            "Step 1: Trains passing each other on a track.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  60%|█████▉    | 1865/3114 [14:20<09:06,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train parked on top of the tracks near a station.'\n",
            "```\n",
            "Step 1: A train on the tracks near a station.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  60%|██████    | 1870/3114 [14:21<08:30,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A passenger train moving down the tracks next to a field.'\n",
            "```\n",
            "Step 1: A train moving next to a field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  60%|██████    | 1875/3114 [14:23<07:44,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two trains are on the tracks awaiting passengers for their next trip.'\n",
            "```\n",
            "Step 1: Two trains on the tracks\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  60%|██████    | 1880/3114 [14:25<07:51,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='\\nThere is a red canned beverage in between the two parking meters.'\n",
            "```\n",
            "Step 1: A red beverage can between two parking meters\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  61%|██████    | 1885/3114 [14:27<08:17,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A long train traveling along train tracks near a platform.'\n",
            "```\n",
            "Step 1: A train traveling along tracks near a platform.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  61%|██████    | 1890/3114 [14:30<08:49,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A commuter train running under a bridge along urban tracks.'\n",
            "```\n",
            "Step 1: A train running under a bridge\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  61%|██████    | 1895/3114 [14:36<13:27,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A yellow train next to a platform with two men wearing orange jackets and another man standing next to them.'\n",
            "```\n",
            "Step 1: A yellow train at a platform with three men nearby.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  61%|██████    | 1900/3114 [14:37<11:30,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The blue train engine emits black smoke as it speeds down the track.'\n",
            "```\n",
            "Step 1: A blue train engine emitting smoke on the tracks.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  61%|██████    | 1905/3114 [14:39<10:03,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Several trains are parked next to each other on some tracks.'\n",
            "```\n",
            "Step 1: Several trains on tracks.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  61%|██████▏   | 1910/3114 [14:41<09:39,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train riding through a train station with no one on the platform. '\n",
            "```\n",
            "Step 1: A train moving through an empty train station.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  61%|██████▏   | 1915/3114 [14:46<12:16,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A commuter train traveling down snow covered train tracks.'\n",
            "```\n",
            "Step 1: A train traveling on snow-covered tracks.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  62%|██████▏   | 1920/3114 [14:48<11:27,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train traveling down tracks through the countryside.'\n",
            "```\n",
            "Step 1: A train traveling through the countryside.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  62%|██████▏   | 1925/3114 [14:50<09:39,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A yellow and black train passing by trees and building.'\n",
            "```\n",
            "Step 1: A train passing by trees and a building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  62%|██████▏   | 1930/3114 [14:53<10:56,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train has made its way through a grand tunnel cut into the mountain.'\n",
            "```\n",
            "Step 1: A train passing through a tunnel in the mountain.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  62%|██████▏   | 1935/3114 [14:56<11:12,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a bus parked on a rail way under a walking bridge.'\n",
            "```\n",
            "Step 1: A bus parked under a bridge\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  62%|██████▏   | 1940/3114 [14:58<09:47,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train arriving at a station platform with no people in sight.'\n",
            "```\n",
            "Step 1: A train at a station platform\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  62%|██████▏   | 1945/3114 [15:00<08:37,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A large blue and yellow train stops near a fairly-non urban train-station.'\n",
            "```\n",
            "Step 1: A blue and yellow train at a train station.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  63%|██████▎   | 1950/3114 [15:03<09:34,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A train in an indoor station standing on the tracks.'\n",
            "```\n",
            "Step 1: A train in an indoor station\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  63%|██████▎   | 1955/3114 [15:04<08:32,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A red and white train traveling past a train station.'\n",
            "```\n",
            "Step 1: A train passing a train station.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  63%|██████▎   | 1960/3114 [15:06<08:20,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two old trains on a train track heading in opposite directions.'\n",
            "```\n",
            "Step 1: Two trains on a track going in opposite directions.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  63%|██████▎   | 1965/3114 [15:09<09:14,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Parking meters in pavement with corresponding numbered poles.'\n",
            "```\n",
            "Step 1: Parking meters with numbered poles.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  63%|██████▎   | 1970/3114 [15:13<10:39,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An older flat bed truck with equipment in it parked in a farm field with three men.'\n",
            "```\n",
            "Step 1: An old flatbed truck parked in a field with three men.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  63%|██████▎   | 1975/3114 [15:15<09:47,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a dog is sitting inside a vehicle right in the front seat. '\n",
            "```\n",
            "Step 1: A dog sitting in the front seat of a vehicle.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  64%|██████▎   | 1980/3114 [15:17<08:48,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A dog on a leash looks out the rear window while sitting next to a male passenger.'\n",
            "```\n",
            "Step 1: A dog on a leash looking out of a window\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  64%|██████▎   | 1985/3114 [15:20<10:00,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Older Americans ride in a simple parade float adorned with red, white and blue decorations.'\n",
            "```\n",
            "Step 1: Older Americans on a parade float with red, white, and blue decorations.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  64%|██████▍   | 1990/3114 [15:22<09:12,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A girl sitting in a truck is reflected in a mirror. '\n",
            "```\n",
            "Step 1: A girl in a truck\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  64%|██████▍   | 1995/3114 [15:24<08:10,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Windows reflect cars sitting in traffic on a road next to an old building.'\n",
            "```\n",
            "Step 1: Windows reflecting traffic on a road next to an old building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  64%|██████▍   | 2000/3114 [15:26<08:41,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman sitting on a truck holding a black and white sign congratulating AAF Supply. '\n",
            "```\n",
            "Step 1: A woman sitting on a truck holding a sign.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  64%|██████▍   | 2005/3114 [15:28<07:56,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Four people are trying to dissemble an object in front of their truck. '\n",
            "```\n",
            "Step 1: Four people are working in front of a truck.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  65%|██████▍   | 2010/3114 [15:30<07:16,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A small brightly colored commercial vehicle parked on a gravel parking lot.'\n",
            "```\n",
            "Step 1: A small colorful vehicle parked on gravel.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  65%|██████▍   | 2015/3114 [15:32<07:34,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The black dog runs past the black and white cat.'\n",
            "```\n",
            "Step 1: A black dog runs past a cat.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  65%|██████▍   | 2020/3114 [15:35<08:38,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A black and tan dog is shown snuggling with a white cat.'\n",
            "```\n",
            "Step 1: A dog snuggling with a cat.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  65%|██████▌   | 2025/3114 [15:37<08:16,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A red dog with a white face looks at an orange tabby cat who is on top of a bar stool.'\n",
            "```\n",
            "Step 1: A red dog looking at an orange cat on a stool.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  65%|██████▌   | 2030/3114 [15:40<09:12,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A cat looking out from a cage with a strange look'\n",
            "```\n",
            "Step 1: A cat looking out from a cage\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  65%|██████▌   | 2035/3114 [15:43<09:34,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The cat must have found an interesting smell on that umbrella.'\n",
            "```\n",
            "Step 1: A cat sniffing an umbrella.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  66%|██████▌   | 2040/3114 [15:45<08:38,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A cat sitting on a table outside with a dog laying on the ground '\n",
            "```\n",
            "Step 1: A cat on a table with a dog on the ground\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  66%|██████▌   | 2045/3114 [15:48<09:18,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A yellow truck carrying people on the back of it and something huge on top of it.'\n",
            "```\n",
            "Step 1: A yellow truck with people and a large object on top.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  66%|██████▌   | 2050/3114 [15:50<07:58,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of young men wearing sunglasses are crowded into the back of a truck.'\n",
            "```\n",
            "Step 1: A group of young men in a truck.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  66%|██████▌   | 2055/3114 [15:52<07:46,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A cat with glowing eyes sitting on shoes with reflective heels.'\n",
            "```\n",
            "Step 1: A cat sitting on shoes\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  66%|██████▌   | 2060/3114 [15:55<08:27,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A cat with a pink bow sits underneath something silver.'\n",
            "```\n",
            "Step 1: A cat with a bow sitting underneath something shiny.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  66%|██████▋   | 2065/3114 [15:57<08:36,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man in a lab coat walks a longhorn cow around a show ring.'\n",
            "```\n",
            "Step 1: A man in a lab coat walking a cow\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  66%|██████▋   | 2070/3114 [15:59<07:25,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A multi-colored cat laying down next to several pieces of luggage that are various colors and sizes.'\n",
            "```\n",
            "Step 1: A cat lying next to some luggage.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  67%|██████▋   | 2075/3114 [16:03<09:20,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two large yellow trucks are working on a road being built.'\n",
            "```\n",
            "Step 1: Two large yellow trucks on a construction site.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  67%|██████▋   | 2080/3114 [16:05<08:48,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person passes an expanse of snow on skis while another watches in the distance.'\n",
            "```\n",
            "Step 1: A person skiing in the snow while another watches.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  67%|██████▋   | 2085/3114 [16:07<08:10,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Green and white tote truck pulling a white truck behind it. '\n",
            "```\n",
            "Step 1: A green and white truck pulling a white truck.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  67%|██████▋   | 2090/3114 [16:10<09:31,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A cow standing in a lush green field surrounded by trees.'\n",
            "```\n",
            "Step 1: A cow in a green field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  67%|██████▋   | 2095/3114 [16:14<09:46,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two cows standing next to each other in a field with high grass. '\n",
            "```\n",
            "Step 1: Two cows in a field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  67%|██████▋   | 2100/3114 [16:16<08:51,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A cat sit on  a cushion in a cage with the door open.'\n",
            "```\n",
            "Step 1: A cat sitting on a cushion in an open cage.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  68%|██████▊   | 2105/3114 [16:17<07:44,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption=\"Bovine and handler await the result of the judges' inspection.\"\n",
            "```\n",
            "Step 1: A cow and its handler waiting for the judge's decision.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  68%|██████▊   | 2110/3114 [16:20<07:50,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A red pick up truck parked on a field next to another truck.'\n",
            "```\n",
            "Step 1: A red truck parked in a field next to another truck.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  68%|██████▊   | 2115/3114 [16:21<07:05,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a cat resting on top of a tv monitor which is hanging flush against a wall'\n",
            "```\n",
            "Step 1: A cat resting on a TV.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  68%|██████▊   | 2120/3114 [16:24<07:15,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A cat on a wood floor watching a TV sitting on a chair.'\n",
            "```\n",
            "Step 1: A cat on a wood floor watching a TV\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  68%|██████▊   | 2125/3114 [16:25<06:28,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Green fields with shrubs and gentle rises and dips in the terrain has a large black cow standing on it, face-front, and a second one that is looking around at the other one.  '\n",
            "```\n",
            "Step 1: Two black cows in a green field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  68%|██████▊   | 2130/3114 [16:27<06:05,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A brown and white cow leaning over a stable fence.'\n",
            "```\n",
            "Step 1: A cow leaning over a fence.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  69%|██████▊   | 2135/3114 [16:31<08:07,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='two calfs walk side by side in a pen on a sunny day'\n",
            "```\n",
            "Step 1: Two calves walking in a pen\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  69%|██████▊   | 2140/3114 [16:32<07:06,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A giant cruise ship next to another giant cruise ship next to a long pier.'\n",
            "```\n",
            "Step 1: Two giant cruise ships next to a pier.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  69%|██████▉   | 2145/3114 [16:35<07:29,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A brown kitten sitting on an open laptop computer.'\n",
            "```\n",
            "Step 1: A kitten sitting on a laptop.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  69%|██████▉   | 2150/3114 [16:36<06:42,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A large herd of cattle grazing on a lush green hillside.'\n",
            "```\n",
            "Step 1: A herd of cattle grazing on a green hillside.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  69%|██████▉   | 2155/3114 [16:39<07:33,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Group of brown cows all grouped together in front of a wired fence.'\n",
            "```\n",
            "Step 1: A group of brown cows by a fence.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  69%|██████▉   | 2160/3114 [16:41<06:30,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A red and white boat sitting on top of tables in a workshop.'\n",
            "```\n",
            "Step 1: A boat on tables in a workshop.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  70%|██████▉   | 2165/3114 [16:42<06:10,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A small kitten fast asleep with its head resting on a remote control'\n",
            "```\n",
            "Step 1: A small kitten sleeping on a remote control.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  70%|██████▉   | 2170/3114 [16:44<05:50,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Military men are holding awards while standing next to a man in a suit.'\n",
            "```\n",
            "Step 1: Military men holding awards next to a man in a suit.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  70%|██████▉   | 2175/3114 [16:46<06:04,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The man is taking a picture of himself in glasses and a tie. '\n",
            "```\n",
            "Step 1: A man taking a selfie in glasses and a tie.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  70%|███████   | 2180/3114 [16:48<06:07,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='two women and a baby are sitting on a red bench and some men walking'\n",
            "```\n",
            "Step 1: Two women and a baby sitting on a bench.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  70%|███████   | 2185/3114 [16:50<06:21,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An older man in a business suit who has a beard and glasses. '\n",
            "```\n",
            "Step 1: An older man in a suit with a beard and glasses.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  70%|███████   | 2190/3114 [16:52<05:45,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Group of people in dress clothes sitting around a conference table. '\n",
            "```\n",
            "Step 1: People in formal clothes sitting at a table.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  70%|███████   | 2195/3114 [16:54<06:07,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A cruise ship is sailing close to the shore as two adults and a child walk through the sand.'\n",
            "```\n",
            "Step 1: A cruise ship near the shore with people walking on the sand.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  71%|███████   | 2200/3114 [16:56<06:15,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption=\"An elephant's front legs are in the water and back legs are out of the water.\"\n",
            "```\n",
            "Step 1: An elephant standing in water\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  71%|███████   | 2205/3114 [16:58<06:21,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person in a suit and tie drinking out of a mug. '\n",
            "```\n",
            "Step 1: A person in a suit drinking from a mug.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  71%|███████   | 2210/3114 [17:01<06:25,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A boat that has blue covers sitting on the side of the water'\n",
            "```\n",
            "Step 1: A boat with blue covers by the water\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  71%|███████   | 2215/3114 [17:05<08:27,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man throws his head back as an elephant touches his face with its trunk.'\n",
            "```\n",
            "Step 1: A man laughing as an elephant touches him\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  71%|███████▏  | 2220/3114 [17:07<07:21,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Three men are wearing identical black suits, vests, ties and shiny black shoes.'\n",
            "```\n",
            "Step 1: Three men in identical black suits\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  71%|███████▏  | 2225/3114 [17:09<07:09,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The old, adult elephant stands near a wire fence.'\n",
            "```\n",
            "Step 1: An elephant standing near a fence.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  72%|███████▏  | 2230/3114 [17:11<06:35,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The huge boat is sailing beside an island with a light house.'\n",
            "```\n",
            "Step 1: A large boat sailing near an island with a lighthouse.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  72%|███████▏  | 2235/3114 [17:14<07:26,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A yellow row boat rests on a ramp going to a lighthouse.'\n",
            "```\n",
            "Step 1: A yellow boat on a ramp leading to a lighthouse.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  72%|███████▏  | 2240/3114 [17:17<07:29,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of people standing next to each other near a ground of people on a green patch fo grass.'\n",
            "```\n",
            "Step 1: A group of people standing on grass.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  72%|███████▏  | 2245/3114 [17:19<07:03,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A green coat flipped upside down on top of a beach.'\n",
            "```\n",
            "Step 1: A green coat on a beach.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  72%|███████▏  | 2250/3114 [17:20<06:16,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man wearing glasses pouring something into a cup being held by a blonde   woman. '\n",
            "```\n",
            "Step 1: A man pouring into a cup held by a woman.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  72%|███████▏  | 2256/3114 [17:22<05:24,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An Asian man wearing a suit with a yellow and blue tie is talking and sitting at a table with a binder of papers in front of him.'\n",
            "```\n",
            "Step 1: A man in a suit sitting at a table with a binder of papers.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  73%|███████▎  | 2261/3114 [17:24<05:33,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a man talking to a group of people and standing in front of a screen'\n",
            "```\n",
            "Step 1: A man speaking to a group of people in front of a screen.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  73%|███████▎  | 2266/3114 [17:26<05:15,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Man standing next to an elephant with chains around his front ankles.'\n",
            "```\n",
            "Step 1: A man standing next to an elephant.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  73%|███████▎  | 2271/3114 [17:27<04:54,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='This is a photo of a boat floating on the water in front of a huge mountain. '\n",
            "```\n",
            "Step 1: A boat on the water in front of a mountain.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  73%|███████▎  | 2276/3114 [17:29<04:53,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man wearing a red neck tie on top of a dirt field.'\n",
            "```\n",
            "Step 1: A man in a red tie on a dirt field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  73%|███████▎  | 2281/3114 [17:33<07:07,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man wearing a green sweatshirt with a tie around his neck.'\n",
            "```\n",
            "Step 1: A man wearing a green sweatshirt and a tie.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  73%|███████▎  | 2286/3114 [17:35<06:35,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Lady bent over with red polka dot umbrella inside a brick building.'\n",
            "```\n",
            "Step 1: A lady with a red umbrella inside a brick building.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  74%|███████▎  | 2291/3114 [17:38<06:47,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A shopkeeper preparing various colored umbrellas in front of her shop.'\n",
            "```\n",
            "Step 1: A shopkeeper preparing umbrellas in front of her shop.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  74%|███████▎  | 2296/3114 [17:41<07:06,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Pedestrians carrying unfolded umbrellas cross a busy urban street corner in the rain.'\n",
            "```\n",
            "Step 1: People with umbrellas crossing a street in the rain.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  74%|███████▍  | 2301/3114 [17:43<06:34,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A couple of men standing next to each other holding a ring box.'\n",
            "```\n",
            "Step 1: Two men holding a ring box\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  74%|███████▍  | 2306/3114 [17:45<05:48,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A picture in black and white of a person holding a blue umbrella next to a river.'\n",
            "```\n",
            "Step 1: A person with a blue umbrella next to a river\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  74%|███████▍  | 2311/3114 [17:49<07:28,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman helping clean an elephants foot with some water.'\n",
            "```\n",
            "Step 1: A woman cleaning an elephant's foot with water.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  74%|███████▍  | 2316/3114 [17:52<07:47,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='People walk on a sidewalk below many multicolored umbrellas.'\n",
            "```\n",
            "Step 1: People walking under colorful umbrellas.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  75%|███████▍  | 2321/3114 [17:54<07:14,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two men wearing business suits shake hands under a canopy.'\n",
            "```\n",
            "Step 1: Two men in suits shaking hands\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  75%|███████▍  | 2326/3114 [17:57<07:09,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An elephant with various blankets and a seat on its back.'\n",
            "```\n",
            "Step 1: An elephant with a seat on its back.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  75%|███████▍  | 2331/3114 [17:59<06:44,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A small herd of elephants with saddles walk through a door in a city.'\n",
            "```\n",
            "Step 1: A small herd of elephants walking through a door\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  75%|███████▌  | 2336/3114 [18:01<05:48,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bike with a basket sitting on snow covered ground.'\n",
            "```\n",
            "Step 1: A bike with a basket on snow.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  75%|███████▌  | 2341/3114 [18:03<05:32,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a womans legs wearing black shoes standing on a green and white suitcase'\n",
            "```\n",
            "Step 1: A woman's legs standing on a suitcase\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  75%|███████▌  | 2346/3114 [18:04<05:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A young man stands by a gate, holding an umbrella, nearby to a stream.'\n",
            "```\n",
            "Step 1: A young man holding an umbrella by a gate near a stream.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  75%|███████▌  | 2351/3114 [18:07<05:20,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The woman kneels beside a building with an open suitcase and other bags.'\n",
            "```\n",
            "Step 1: A woman kneeling beside a building with a suitcase and bags.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  76%|███████▌  | 2356/3114 [18:09<05:24,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Leader of elephant herd heading into the brush after crossing a road.'\n",
            "```\n",
            "Step 1: An elephant leading its herd into the brush.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  76%|███████▌  | 2361/3114 [18:11<05:10,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An elephant taking shade beneath a very small tree.'\n",
            "```\n",
            "Step 1: An elephant standing under a small tree.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  76%|███████▌  | 2366/3114 [18:13<05:11,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A fancy house before a reflecting pool, and a person standing by it.'\n",
            "```\n",
            "Step 1: A house by a reflecting pool with a person standing nearby.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  76%|███████▌  | 2371/3114 [18:15<05:09,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a crowd of people sitting and standing around a bunch of bags.'\n",
            "```\n",
            "Step 1: A group of people around some bags.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  76%|███████▋  | 2376/3114 [18:18<05:52,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two women, one with an umbrella, stand at a street corner next to the stoplight.'\n",
            "```\n",
            "Step 1: Two women at a street corner, one with an umbrella.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  76%|███████▋  | 2381/3114 [18:21<06:05,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman is holding a child in the water with another child nearby.'\n",
            "```\n",
            "Step 1: A woman holding a child in water with another child nearby.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  77%|███████▋  | 2386/3114 [18:23<05:40,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two people in a long kayak, and a man and a dog standing on some kind of small boat.'\n",
            "```\n",
            "Step 1: Two people in a kayak and a man with a dog on a small boat.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  77%|███████▋  | 2391/3114 [18:24<04:57,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bunch of people at the water swimming, canoeing, and boating. '\n",
            "```\n",
            "Step 1: A group of people swimming and canoeing in the water.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  77%|███████▋  | 2396/3114 [18:26<04:36,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two cardboard boxes stack on top of each other next to a metal box.'\n",
            "```\n",
            "Step 1: Two stacked cardboard boxes next to a metal box.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  77%|███████▋  | 2401/3114 [18:28<04:45,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A couple of elephants standing next to each other.'\n",
            "```\n",
            "Step 1: Two elephants standing together.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  77%|███████▋  | 2406/3114 [18:30<04:31,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A number of people exiting an airport terminal with luggage.'\n",
            "```\n",
            "Step 1: A group of people exiting an airport with luggage.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  77%|███████▋  | 2411/3114 [18:32<04:40,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two pieces of luggage sitting on top of a carpeted floor.'\n",
            "```\n",
            "Step 1: Two pieces of luggage on a carpet\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  78%|███████▊  | 2416/3114 [18:34<04:36,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A dog pokes its head between a table with utensils and a plate of mostly finished food and the arm and chest of a person, probably a man, with a hand resting on his chest. '\n",
            "```\n",
            "Step 1: A dog between a table with food and a person's arm.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  78%|███████▊  | 2421/3114 [18:35<04:12,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='There are several people walking down the street holding umbrellas'\n",
            "```\n",
            "Step 1: Several people walking with umbrellas\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  78%|███████▊  | 2426/3114 [18:37<04:10,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption=\"Cute little dog poses for a picture with the top of it's head dyed\"\n",
            "```\n",
            "Step 1: A dog poses for a picture with dyed fur.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  78%|███████▊  | 2431/3114 [18:39<04:00,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption=\"A person's feet on the side of an upended skateboard.\"\n",
            "```\n",
            "Step 1: A person's feet next to an upended skateboard.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  78%|███████▊  | 2436/3114 [18:41<04:10,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='This is an interesting view of someone riding a skateboard.'\n",
            "```\n",
            "Step 1: A person riding a skateboard.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  78%|███████▊  | 2441/3114 [18:43<04:21,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A garage with the door open to show a group of people sitting in chairs and a dog.'\n",
            "```\n",
            "Step 1: A garage with people sitting and a dog\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  79%|███████▊  | 2446/3114 [18:45<04:21,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man riding a skate board down the middle of a street.'\n",
            "```\n",
            "Step 1: A man skateboarding in the street.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  79%|███████▊  | 2451/3114 [18:47<04:26,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A closeup of a skateboard wheel sits next to a shadow cast by a person standing on the skateboard'\n",
            "```\n",
            "Step 1: A closeup of a skateboard wheel and a person's shadow.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  79%|███████▉  | 2456/3114 [18:49<04:12,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A partially eaten banana face down on cement about to be stepped on by a shoe.'\n",
            "```\n",
            "Step 1: A partially eaten banana on the ground\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  79%|███████▉  | 2461/3114 [18:52<04:56,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A dog curled up on a couch between a sleeping girl and a boy playing computer games. '\n",
            "```\n",
            "Step 1: A dog curled up on a couch with a girl sleeping and a boy playing games.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  79%|███████▉  | 2466/3114 [18:54<04:31,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A couple of men playing a game of frisbee in a park.'\n",
            "```\n",
            "Step 1: Two men playing frisbee in a park.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  79%|███████▉  | 2471/3114 [18:55<04:16,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A little baby boy playing with a frisbee in the park.'\n",
            "```\n",
            "Step 1: A baby boy playing with a frisbee\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  80%|███████▉  | 2476/3114 [18:57<04:18,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a big brown bear standing in an open field next to some rocks'\n",
            "```\n",
            "Step 1: A brown bear in an open field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  80%|███████▉  | 2481/3114 [18:59<04:17,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A young child in swimwear walking towards the water.'\n",
            "```\n",
            "Step 1: A child walking towards the water.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  80%|███████▉  | 2486/3114 [19:01<04:02,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bear with a flat head stands in an enclosure. '\n",
            "```\n",
            "Step 1: A bear in an enclosure\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  80%|███████▉  | 2491/3114 [19:06<05:31,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman taking a picture of her rear view mirror with a dog sitting next to her.'\n",
            "```\n",
            "Step 1: A woman taking a picture with a dog next to her.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  80%|████████  | 2496/3114 [19:07<04:59,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A little white dog looking out into a parking lot from a window.'\n",
            "```\n",
            "Step 1: A little white dog looking out a window\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  80%|████████  | 2501/3114 [19:09<04:35,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Toy animals displayed with small trees in outdoor setting.'\n",
            "```\n",
            "Step 1: Toy animals and small trees in an outdoor setting.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  80%|████████  | 2506/3114 [19:12<05:02,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man in red shirt playing a game with frisbee.'\n",
            "```\n",
            "Step 1: A man playing frisbee\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  81%|████████  | 2511/3114 [19:14<04:28,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A Frisbee golf net in a park with several Frisbee in it.'\n",
            "```\n",
            "Step 1: A Frisbee golf net in a park with Frisbees in it.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  81%|████████  | 2516/3114 [19:16<04:27,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A dog is investigating a box of dog biscuits.'\n",
            "```\n",
            "Step 1: A dog investigating a box\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  81%|████████  | 2521/3114 [19:18<04:21,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Several people are running in a grassy field playing with a frisbee.'\n",
            "```\n",
            "Step 1: Several people running in a field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  81%|████████  | 2526/3114 [19:20<03:59,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A spaniel type dog being petted next to a bookshelf.'\n",
            "```\n",
            "Step 1: A dog being petted next to a bookshelf.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  81%|████████▏ | 2531/3114 [19:22<03:46,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman standing next to a man while throwing a Frisbee.'\n",
            "```\n",
            "Step 1: A woman and a man throwing a Frisbee.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  81%|████████▏ | 2536/3114 [19:24<04:14,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The black and white dog lays on the floor in front of the chair.'\n",
            "```\n",
            "Step 1: A dog laying on the floor in front of a chair.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  82%|████████▏ | 2541/3114 [19:26<03:48,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A black dog attempts to pick up a Frisbee with its mouth.'\n",
            "```\n",
            "Step 1: A black dog trying to catch a Frisbee.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  82%|████████▏ | 2546/3114 [19:28<03:33,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man is going after a freebie while someone is lying down next to a bicycle reading the newspapers on the lawn  in front of a house.'\n",
            "```\n",
            "Step 1: A man reaching for something while another person is lying on the grass reading a newspaper next to a bicycle.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  82%|████████▏ | 2551/3114 [19:29<03:22,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A young person with a disc in a big grassy field.'\n",
            "```\n",
            "Step 1: A person with a disc in a grassy field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  82%|████████▏ | 2556/3114 [19:31<03:33,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A lot of zebras in the grass grazing and one zebra just looking.'\n",
            "```\n",
            "Step 1: A group of zebras grazing in the grass\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  82%|████████▏ | 2561/3114 [19:35<04:14,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of people standing beside a bench with frisbees.'\n",
            "```\n",
            "Step 1: A group of people beside a bench with frisbees.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  82%|████████▏ | 2566/3114 [19:37<04:00,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The man is poised to throw a Frisbee across the park.'\n",
            "```\n",
            "Step 1: A man throwing a Frisbee in a park.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  83%|████████▎ | 2571/3114 [19:38<03:44,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two zebras standing together on a gravel area in front of a stone wall.'\n",
            "```\n",
            "Step 1: Two zebras standing on gravel in front of a wall.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  83%|████████▎ | 2576/3114 [19:40<03:31,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A lot of zebras are walking around on a grass field.'\n",
            "```\n",
            "Step 1: A group of zebras walking on a grass field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  83%|████████▎ | 2581/3114 [19:42<03:29,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A zebra staring back at its hind legs in the wild.'\n",
            "```\n",
            "Step 1: A zebra looking at its hind legs in the wild.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  83%|████████▎ | 2586/3114 [19:45<04:00,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Three zebras standing near each other in a penned in area.'\n",
            "```\n",
            "Step 1: Three zebras standing together in an enclosure.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  83%|████████▎ | 2591/3114 [19:46<03:32,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A herd of zebra standing next to each other drinking from a river.'\n",
            "```\n",
            "Step 1: A herd of zebras drinking from a river.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  83%|████████▎ | 2596/3114 [19:48<03:14,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Man jumping a horse over a competitive horse jumping run.'\n",
            "```\n",
            "Step 1: A man jumping a horse\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  84%|████████▎ | 2601/3114 [19:50<03:22,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A zebra standing on the grass holding its head near the ground.'\n",
            "```\n",
            "Step 1: A zebra standing on grass with its head down.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  84%|████████▎ | 2606/3114 [19:52<03:22,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A very tall building with people walking around below it.'\n",
            "```\n",
            "Step 1: A tall building with people below.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  84%|████████▍ | 2611/3114 [19:54<03:05,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Three zebras gathered together in a field looking at something.'\n",
            "```\n",
            "Step 1: Three zebras in a field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  84%|████████▍ | 2616/3114 [19:55<02:55,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='four zebras standing in a straw field next to shrubbery.'\n",
            "```\n",
            "Step 1: Four zebras in a field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  84%|████████▍ | 2621/3114 [19:58<03:11,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A small girl rides a horse through a crowded street.'\n",
            "```\n",
            "Step 1: A small girl rides a horse on a street.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  84%|████████▍ | 2626/3114 [19:59<02:54,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a small brown pony eating grass next to bushes'\n",
            "```\n",
            "Step 1: A small pony eating grass\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  84%|████████▍ | 2631/3114 [20:01<03:07,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a brown and black horse with long hair standing by some bushes and trees'\n",
            "```\n",
            "Step 1: A horse standing by some bushes.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  85%|████████▍ | 2636/3114 [20:04<03:13,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The large black horse is seen through the leaves of a tree.'\n",
            "```\n",
            "Step 1: A black horse seen through tree leaves.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  85%|████████▍ | 2641/3114 [20:06<03:13,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A large black horse standing on a field filled with green and brown grass.'\n",
            "```\n",
            "Step 1: A black horse standing in a grassy field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  85%|████████▍ | 2646/3114 [20:07<02:54,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='two young men on horseback at a gas station near some gas pumps and trucks'\n",
            "```\n",
            "Step 1: Two young men on horseback at a gas station\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  85%|████████▌ | 2651/3114 [20:09<02:53,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man is sitting on farming equipment pulled by horses.'\n",
            "```\n",
            "Step 1: A man sitting on farming equipment pulled by horses.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  85%|████████▌ | 2656/3114 [20:11<02:42,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two irking horses pulling a piece of equipment guided by a man.'\n",
            "```\n",
            "Step 1: Two horses pulling equipment guided by a man.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  85%|████████▌ | 2661/3114 [20:12<02:37,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two clydsdale horses being trained by a man and a woman.'\n",
            "```\n",
            "Step 1: Two Clydesdale horses being trained by a man and a woman.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  86%|████████▌ | 2666/3114 [20:14<02:42,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two draft horses pulling plow, color, under cloudy skies with trees and other horses in background.'\n",
            "```\n",
            "Step 1: Two draft horses pulling a plow\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  86%|████████▌ | 2671/3114 [20:17<03:03,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The small horse is standing all alone on the grassy field. '\n",
            "```\n",
            "Step 1: A small horse standing in a grassy field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  86%|████████▌ | 2676/3114 [20:18<02:45,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A white horse with black spots leaning down to eat grass.'\n",
            "```\n",
            "Step 1: A horse eating grass\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  86%|████████▌ | 2681/3114 [20:20<02:47,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person riding on a horse while jumping it over an obstacle.'\n",
            "```\n",
            "Step 1: A person jumping on a horse.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  86%|████████▋ | 2686/3114 [20:22<02:45,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An adult and young horse interacting in a field of grass.'\n",
            "```\n",
            "Step 1: An adult horse and a young horse in a field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  86%|████████▋ | 2691/3114 [20:24<02:37,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A black and white image of men dressed in chain mail riding horses. '\n",
            "```\n",
            "Step 1: Men in chain mail riding horses\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  87%|████████▋ | 2696/3114 [20:26<02:44,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a mamma horse and her baby standing in a field of grass'\n",
            "```\n",
            "Step 1: A horse and her baby standing in a grassy field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  87%|████████▋ | 2701/3114 [20:29<02:59,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man helping a lady onto a horse with another lady watching.'\n",
            "```\n",
            "Step 1: A man assisting a woman onto a horse with another woman watching.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  87%|████████▋ | 2706/3114 [20:30<02:42,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='there is a horse and a jockey jumping over a obstacle '\n",
            "```\n",
            "Step 1: A horse and jockey jumping over an obstacle\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  87%|████████▋ | 2711/3114 [20:33<02:45,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A female equestrian on a brown horse, jumping over a double hurdle.'\n",
            "```\n",
            "Step 1: A woman jumping on a brown horse\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  87%|████████▋ | 2716/3114 [20:35<02:55,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Equestrian riders on grassy field during outdoor event.'\n",
            "```\n",
            "Step 1: Riders on a grassy field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  87%|████████▋ | 2721/3114 [20:37<02:46,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person sitting on a horse in air over gate in grass with people and trees in background.'\n",
            "```\n",
            "Step 1: A person sitting on a horse over grass with people and trees in the background.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  88%|████████▊ | 2726/3114 [20:39<02:39,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man riding a horse next to another man on a horse.'\n",
            "```\n",
            "Step 1: Two men riding horses\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  88%|████████▊ | 2731/3114 [20:42<03:01,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A woman jumping a horse over an obstacle on a course.'\n",
            "```\n",
            "Step 1: A woman jumping a horse over an obstacle.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  88%|████████▊ | 2736/3114 [20:44<02:41,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person riding a horse as it jumps a barrier in a course.'\n",
            "```\n",
            "Step 1: A person riding a horse jumping over a barrier.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  88%|████████▊ | 2741/3114 [20:46<02:54,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A brown horse being jumped over a fence rail in a competition.'\n",
            "```\n",
            "Step 1: A brown horse jumping over a fence\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  88%|████████▊ | 2746/3114 [20:48<02:31,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Equestrian jumping a horse over a rail with spectators looking on.'\n",
            "```\n",
            "Step 1: A horse jumping over a rail with spectators watching.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  88%|████████▊ | 2751/3114 [20:52<03:22,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A young female equestrian jumps a hurdle on her horse. '\n",
            "```\n",
            "Step 1: A young woman jumping a hurdle on a horse.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  89%|████████▊ | 2756/3114 [20:54<02:51,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a small child riding a horse in the grassy field'\n",
            "```\n",
            "Step 1: A child riding a horse in a field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  89%|████████▊ | 2761/3114 [20:57<03:08,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Shows a professional photo with watermarks of  a horse and jockey.'\n",
            "```\n",
            "Step 1: A horse and jockey in a photo\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  89%|████████▉ | 2766/3114 [20:59<02:53,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A young girl rides her horse in the middle of a course.'\n",
            "```\n",
            "Step 1: A girl riding her horse in a course.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  89%|████████▉ | 2771/3114 [21:01<02:43,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An equestrian riding a brown horse during a horse show'\n",
            "```\n",
            "Step 1: A rider on a brown horse\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  89%|████████▉ | 2776/3114 [21:04<02:39,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person riding on the back of a horse walking across a field.'\n",
            "```\n",
            "Step 1: A person riding a horse in a field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  89%|████████▉ | 2781/3114 [21:06<02:27,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Female equestrian taking a show horse through its paces.'\n",
            "```\n",
            "Step 1: A woman riding a show horse.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  89%|████████▉ | 2786/3114 [21:08<02:31,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The man is on the horse and is racing to jump over the barrier. '\n",
            "```\n",
            "Step 1: A man on a horse jumping over a barrier.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  90%|████████▉ | 2791/3114 [21:11<02:39,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An equestrian is guiding a horse around the grass field.'\n",
            "```\n",
            "Step 1: A person guiding a horse in a field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  90%|████████▉ | 2796/3114 [21:14<02:41,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A large horse eating grass next to a significantly smaller horse.'\n",
            "```\n",
            "Step 1: A large horse eating grass next to a smaller horse.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  90%|████████▉ | 2801/3114 [21:15<02:24,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An adult horse stands in the field for the picture'\n",
            "```\n",
            "Step 1: An adult horse in a field\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  90%|█████████ | 2806/3114 [21:17<02:12,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Skier with a red jacket on going down the side of a mountain. '\n",
            "```\n",
            "Step 1: A skier in a red jacket going down a mountain.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  90%|█████████ | 2811/3114 [21:19<02:07,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Several people on skis either standing, walking or skiing down the slope. '\n",
            "```\n",
            "Step 1: Several people skiing down a slope\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  90%|█████████ | 2816/3114 [21:21<01:54,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An orange filed with purple flowers and a heart shape cut.'\n",
            "```\n",
            "Step 1: An orange with purple flowers and a heart shape cutout.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  91%|█████████ | 2821/3114 [21:23<02:00,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Large variety of fruits and vegetables on display at a market. '\n",
            "```\n",
            "Step 1: A variety of fruits and vegetables at a market.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  91%|█████████ | 2826/3114 [21:25<01:58,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of workers washing and cleaning fruits and vegetables.'\n",
            "```\n",
            "Step 1: Workers washing fruits and vegetables.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  91%|█████████ | 2831/3114 [21:27<01:53,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of skiers gathered on the ski slope getting ready to ski.'\n",
            "```\n",
            "Step 1: A group of skiers on the slope\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  91%|█████████ | 2836/3114 [21:29<01:56,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A piece of bread with peanut butter on it and bananas cut and made to look like a face.'\n",
            "```\n",
            "Step 1: A piece of bread with peanut butter and banana slices made to look like a face.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  91%|█████████ | 2841/3114 [21:31<01:56,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A male getting ready to throw a pitch at a baseball game.'\n",
            "```\n",
            "Step 1: A person preparing to pitch at a baseball game.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  91%|█████████▏| 2846/3114 [21:33<01:43,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Large bunch of bananas hanging from tree in a jungle.'\n",
            "```\n",
            "Step 1: A bunch of bananas hanging from a tree\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  92%|█████████▏| 2851/3114 [21:35<01:41,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of men standing on top of a baseball field playing a game of baseball.'\n",
            "```\n",
            "Step 1: A group of men playing baseball on a field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  92%|█████████▏| 2856/3114 [21:37<01:45,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A large display of fresh fruits Apples, oranges and mellon.'\n",
            "```\n",
            "Step 1: A display of fresh fruits: apples, oranges, and melon.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  92%|█████████▏| 2861/3114 [21:39<01:39,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A plate with salad and a cut of meat and silverware laid on top.'\n",
            "```\n",
            "Step 1: A plate with salad and meat\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  92%|█████████▏| 2866/3114 [21:41<01:41,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A fork laying on a glass plate next to a half eaten slice of cake.'\n",
            "```\n",
            "Step 1: A fork on a plate next to a slice of cake.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  92%|█████████▏| 2871/3114 [21:44<01:48,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A table has bananas and corn and other items in plastic bags on it.'\n",
            "```\n",
            "Step 1: A table with bananas and corn in bags\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  92%|█████████▏| 2876/3114 [21:48<02:10,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='This is a baseball player getting ready to run and a stadium with half the seats full.'\n",
            "```\n",
            "Step 1: A baseball player getting ready to run in a stadium.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  93%|█████████▎| 2881/3114 [21:50<01:53,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A player batting at a baseball game with lots of spectators.'\n",
            "```\n",
            "Step 1: A player batting at a baseball game\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  93%|█████████▎| 2886/3114 [21:52<01:47,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A shiny metal pan filled with some bananas and brown sauce.'\n",
            "```\n",
            "Step 1: A metal pan with bananas and sauce\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  93%|█████████▎| 2891/3114 [21:53<01:33,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a tray full of assorted vegetables and a small package of meat'\n",
            "```\n",
            "Step 1: A tray of vegetables and meat\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  93%|█████████▎| 2896/3114 [21:55<01:31,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A rear view of a snow boarder and a skier going down a snowy mountain.  '\n",
            "```\n",
            "Step 1: A snowboarder and a skier going down a snowy mountain.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  93%|█████████▎| 2901/3114 [21:57<01:29,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='The pitcher throws the ball as the batter waits to swing while the catcher and umpire watch.'\n",
            "```\n",
            "Step 1: A pitcher throws a ball while a batter waits to swing.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  93%|█████████▎| 2906/3114 [22:00<01:29,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A pair of chopsticks sit on a plate next to rice and vegetables.'\n",
            "```\n",
            "Step 1: A pair of chopsticks on a plate with rice and vegetables.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  93%|█████████▎| 2911/3114 [22:03<01:40,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Group of people laying down next to each other on top of the bed. '\n",
            "```\n",
            "Step 1: Group of people laying on a bed.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  94%|█████████▎| 2916/3114 [22:05<01:34,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A baseball player wearing sunglasses and a New York Yankees hat standing in a baseball field.'\n",
            "```\n",
            "Step 1: A baseball player in sunglasses standing on a field.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  94%|█████████▍| 2921/3114 [22:07<01:28,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two people are at the counter making ice cream sundaes.'\n",
            "```\n",
            "Step 1: Two people making ice cream sundaes at a counter.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  94%|█████████▍| 2926/3114 [22:10<01:27,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Multiple chopped up vegetables with seasoning in a jar ready to cooking.'\n",
            "```\n",
            "Step 1: Chopped vegetables with seasoning in a jar\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  94%|█████████▍| 2931/3114 [22:14<01:47,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A table with broccoli, peas, carrots and strawberries on it. '\n",
            "```\n",
            "Step 1: A table with vegetables and strawberries\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  94%|█████████▍| 2936/3114 [22:16<01:35,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A display of strawberries, peas, broccoli, carrots, radishes and potatoes. '\n",
            "```\n",
            "Step 1: A display of vegetables and strawberries\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  94%|█████████▍| 2941/3114 [22:20<01:47,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Two baskets of strawberries, cucumbers, broccoli, carrots and potatoes gathered togethered.'\n",
            "```\n",
            "Step 1: Two baskets of fruits and vegetables\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  95%|█████████▍| 2946/3114 [22:23<01:43,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A table is covered with fresh produce, fruits and eggs. '\n",
            "```\n",
            "Step 1: A table covered with fruits, vegetables, and eggs.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  95%|█████████▍| 2951/3114 [22:25<01:28,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Banana connected to plastic device shown producing electricity.'\n",
            "```\n",
            "Step 1: A banana connected to a device producing electricity.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  95%|█████████▍| 2956/3114 [22:27<01:18,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Large rectangular dough being topped with vegetable and sauce prior to baking.'\n",
            "```\n",
            "Step 1: A large dough being topped with vegetables and sauce.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  95%|█████████▌| 2961/3114 [22:29<01:12,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A cooking pot with stir fried vegetables in a brown liquid.'\n",
            "```\n",
            "Step 1: A cooking pot with stir fried vegetables.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  95%|█████████▌| 2966/3114 [22:31<01:04,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A young baseball player swings his bat at the incoming pitch.'\n",
            "```\n",
            "Step 1: A young baseball player swings a bat at a pitch.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  95%|█████████▌| 2971/3114 [22:32<00:57,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of skiers adjusts their gear during a heavy snow.'\n",
            "```\n",
            "Step 1: A group of skiers adjusting their gear in the snow.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  96%|█████████▌| 2976/3114 [22:34<00:52,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A young man in a pair of jeans doing skateboard tricks.'\n",
            "```\n",
            "Step 1: A young man skateboarding\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  96%|█████████▌| 2981/3114 [22:36<00:53,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a person jumping in the air while standing on a skateboard in a skate park.'\n",
            "```\n",
            "Step 1: A person jumping on a skateboard in a skate park.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  96%|█████████▌| 2986/3114 [22:38<00:48,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man riding a skateboard on top of a street.'\n",
            "```\n",
            "Step 1: A man skateboarding on a street.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  96%|█████████▌| 2991/3114 [22:40<00:47,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a couple of boys at a skateboard rink attempting tricks'\n",
            "```\n",
            "Step 1: A couple of boys at a skateboard park trying tricks.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  96%|█████████▌| 2996/3114 [22:42<00:46,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person with a backpack and snow suit, jumping from a high snow powdered cliff and in the air.'\n",
            "```\n",
            "Step 1: A person in a snow suit jumping off a cliff.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  96%|█████████▋| 3001/3114 [22:44<00:45,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A skier coming over the crest of a hill while holding ski poles and wearing a helmet and goggles'\n",
            "```\n",
            "Step 1: A skier coming over a hill\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  97%|█████████▋| 3006/3114 [22:47<00:50,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='Bottom half of a person on a skateboard with sky in background. '\n",
            "```\n",
            "Step 1: Bottom half of a person on a skateboard\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  97%|█████████▋| 3011/3114 [22:50<00:49,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption=\"A close up view of a man's legs and feet on a skateboard.\"\n",
            "```\n",
            "Step 1: A close-up of a skateboarder's legs and feet.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  97%|█████████▋| 3016/3114 [22:52<00:43,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A white bowl of soup containing broccoli is near some French bread.'\n",
            "```\n",
            "Step 1: A bowl of broccoli soup with bread\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  97%|█████████▋| 3021/3114 [22:56<00:51,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A little boy is standing on a skate board as he skates along a path.'\n",
            "```\n",
            "Step 1: A boy standing on a skateboard\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  97%|█████████▋| 3026/3114 [22:57<00:42,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A group of women are smiling while toasting with wine glasses.'\n",
            "```\n",
            "Step 1: A group of women toasting with wine glasses.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  97%|█████████▋| 3031/3114 [23:04<00:59,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A boy on an off road skateboard coming down a green grass hill with trees behind him.'\n",
            "```\n",
            "Step 1: A boy on a skateboard going down a grassy hill.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  97%|█████████▋| 3036/3114 [23:05<00:46,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A young man skateboarding casts a shadow on the concrete.'\n",
            "```\n",
            "Step 1: A young man skateboarding on concrete.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  98%|█████████▊| 3041/3114 [23:07<00:39,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption=\"A child's meal in plastic containers with a few side items.\"\n",
            "```\n",
            "Step 1: A child's meal in plastic containers\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  98%|█████████▊| 3046/3114 [23:09<00:34,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A reuben sandwich with cheese melting down it and a bitten pickle.'\n",
            "```\n",
            "Step 1: A reuben sandwich with melted cheese and a pickle.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  98%|█████████▊| 3051/3114 [23:11<00:30,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person and skateboard in the air in an indoor area with posts and graffiti.'\n",
            "```\n",
            "Step 1: A person with a skateboard in the air in an indoor area.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  98%|█████████▊| 3056/3114 [23:14<00:26,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A hamburger sitting on a table with a knife stuck in the top of it.'\n",
            "```\n",
            "Step 1: A hamburger on a table with a knife in it.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  98%|█████████▊| 3061/3114 [23:16<00:24,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A BIG HAMBURGER SITTING ON TOP OF A COUNTER AND A GLASS OF WINE '\n",
            "```\n",
            "Step 1: A hamburger on a counter with a glass of wine\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  98%|█████████▊| 3066/3114 [23:20<00:28,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A blue and white plate with a chocolate dessert on the plate and powdered sugar on top.'\n",
            "```\n",
            "Step 1: A plate with a chocolate dessert and powdered sugar on top.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  99%|█████████▊| 3071/3114 [23:22<00:21,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='a fisheye lens photograph of a man sitting in a chair holding a skateboard.'\n",
            "```\n",
            "Step 1: A man sitting in a chair holding a skateboard.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  99%|█████████▉| 3076/3114 [23:23<00:16,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A skateboarder balances on his skateboard, then balances on the board at the edge of a low wall.'\n",
            "```\n",
            "Step 1: A skateboarder balancing on a low wall.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  99%|█████████▉| 3081/3114 [23:25<00:14,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A guy skateboarding indoors in front of a crowd of people.'\n",
            "```\n",
            "Step 1: A guy skateboarding indoors\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  99%|█████████▉| 3086/3114 [23:27<00:11,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person doing tricks on a skateboard while people watch from the stand.'\n",
            "```\n",
            "Step 1: A person performing tricks on a skateboard with spectators in the background.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  99%|█████████▉| 3091/3114 [23:29<00:09,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A man skateboards on the rim of a skate pipe in front of a crowd. '\n",
            "```\n",
            "Step 1: A man skateboarding in front of a crowd.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  99%|█████████▉| 3096/3114 [23:32<00:08,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='An audience watches a skateboarder jump during competition.'\n",
            "```\n",
            "Step 1: An audience watches a skateboarder during a competition.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing: 100%|█████████▉| 3101/3114 [23:34<00:05,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A skier on skies and a snowboarder carrying a snowboard on a mountain slope.'\n",
            "```\n",
            "Step 1: A skier and a snowboarder on a mountain slope.\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing: 100%|█████████▉| 3106/3114 [23:36<00:03,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A bearded skateboarder rolls down a slope at night'\n",
            "```\n",
            "Step 1: A skateboarder rolling down a slope\n",
            "```\n",
            "\n",
            "running generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 3114/3114 [23:38<00:00,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_caption='A person is standing alongside a deep pathway through a meadow with trees.'\n",
            "```\n",
            "Step 1: A person standing by a pathway in a meadow.\n",
            "```\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_responses))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUIeS-ZRH7XB",
        "outputId": "c45c77d7-0b81-4379-a654-5e1ad22ceabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Assuming all_responses is a list of tuples [(caption, response), ...]\n",
        "# Extract both caption and response\n",
        "all_responses_processed = [(caption, response.strip('`\\n.').split(\": \", 1)[-1].lower())\n",
        "                           for caption, response in all_responses]\n",
        "\n",
        "# Create DataFrame with both \"Caption\" and \"Response\" columns\n",
        "df = pd.DataFrame(all_responses_processed, columns=[\"Caption\", \"Response\"])\n",
        "\n",
        "# Specify the directory where you want to save the file\n",
        "directory = \"/content/drive/MyDrive/excel_result_simplified_only/excel_captions\"\n",
        "os.makedirs(directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# Save the file in the specified directory\n",
        "file_path = os.path.join(directory, \"train-00011-of-00182-f499a31d286235db.parquet.xlsx\")\n",
        "df.to_excel(file_path, index=False)\n",
        "\n",
        "print(f\"Excel file saved to: {file_path}\")"
      ],
      "metadata": {
        "id": "Awty3GsO8N5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3594779-cd76-42a9-a484-f0e305f08a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excel file saved to: /content/drive/MyDrive/excel_result_simplified_only/excel_captions/train-00011-of-00182-f499a31d286235db.parquet.xlsx\n"
          ]
        }
      ]
    }
  ]
}